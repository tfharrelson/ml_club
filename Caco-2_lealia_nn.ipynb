{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02190e19-cbfc-4892-a124-ad11ebfd021c",
   "metadata": {},
   "source": [
    "# Drug absorption\n",
    "## Caco-2 cell effective permeability\n",
    "\n",
    "https://tdcommons.ai/single_pred_tasks/adme/#caco-2-cell-effective-permeability-wang-et-al\n",
    "\n",
    "Task: Regression. Given a drug SMILES string, predict the Caco-2 cell effective permeability.\n",
    "\n",
    "Dataset split: scaffold split -- forces training and test set to have distant molecular structures. This is to help with generalizability, since drug structures of interest evolve over time.\n",
    "\n",
    "Dataset reference: [Wang, NN et al, ADME Properties Evaluation in Drug Discovery: Prediction of Caco-2 Cell Permeability Using a Combination of NSGA-II and Boosting, Journal of Chemical Information and Modeling 2016 56 (4), 763-773](https://pubmed.ncbi.nlm.nih.gov/27018227/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a39ab7c-16f4-4bbe-b886-fd78aa17cefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "  var py_version = '3.3.0'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  var reloading = false;\n",
       "  var Bokeh = root.Bokeh;\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    if (!reloading) {\n",
       "      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n",
       "      require([\"jspanel\"], function(jsPanel) {\n",
       "\twindow.jsPanel = jsPanel\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-modal\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-tooltip\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-hint\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-layout\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-contextmenu\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-dock\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"gridstack\"], function(GridStack) {\n",
       "\twindow.GridStack = GridStack\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"notyf\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      root._bokeh_is_loading = css_urls.length + 9;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    var existing_stylesheets = []\n",
       "    var links = document.getElementsByTagName('link')\n",
       "    for (var i = 0; i < links.length; i++) {\n",
       "      var link = links[i]\n",
       "      if (link.href != null) {\n",
       "\texisting_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      if (existing_stylesheets.indexOf(url) !== -1) {\n",
       "\ton_load()\n",
       "\tcontinue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    var existing_scripts = []\n",
       "    var scripts = document.getElementsByTagName('script')\n",
       "    for (var i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "\texisting_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      var url = js_exports[name];\n",
       "      if (skip.indexOf(url) >= 0 || root[name] != null) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.0.min.js\", \"https://cdn.holoviz.org/panel/1.3.8/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var js_exports = {};\n",
       "  var css_urls = [];\n",
       "  var inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "\ttry {\n",
       "          inline_js[i].call(root, root.Bokeh);\n",
       "\t} catch(e) {\n",
       "\t  if (!reloading) {\n",
       "\t    throw e;\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "\tvar NewBokeh = root.Bokeh;\n",
       "\tif (Bokeh.versions === undefined) {\n",
       "\t  Bokeh.versions = new Map();\n",
       "\t}\n",
       "\tif (NewBokeh.version !== Bokeh.version) {\n",
       "\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "\t}\n",
       "\troot.Bokeh = Bokeh;\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "      if (!reloading && !bokeh_loaded) {\n",
       "\troot.Bokeh = undefined;\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "\trun_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.3.0'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.0.min.js\", \"https://cdn.holoviz.org/panel/1.3.8/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='p1002'>\n",
       "  <div id=\"f7dba0ec-2ec7-474b-b2e2-aff6155e9c61\" data-root-id=\"p1002\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"afbec87e-89b0-4967-b394-1116d7d07644\":{\"version\":\"3.3.0\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"p1002\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"p1003\",\"attributes\":{\"plot_id\":\"p1002\",\"comm_id\":\"ff3a34768a9d4ffcbf94616144c2b5ea\",\"client_comm_id\":\"16500ed8276c416d89156b82c8d7fb14\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"afbec87e-89b0-4967-b394-1116d7d07644\",\"roots\":{\"p1002\":\"f7dba0ec-2ec7-474b-b2e2-aff6155e9c61\"},\"root_ids\":[\"p1002\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "p1002"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"logo-block\">\n",
       "<img src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAYAAACqaXHeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAAB+wAAAfsBxc2miwAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAA6zSURB\n",
       "VHic7ZtpeFRVmsf/5966taWqUlUJ2UioBBJiIBAwCZtog9IOgjqACsogKtqirT2ttt069nQ/zDzt\n",
       "tI4+CrJIREFaFgWhBXpUNhHZQoKBkIUASchWla1S+3ar7r1nPkDaCAnZKoQP/D7mnPOe9/xy76n3\n",
       "nFSAW9ziFoPFNED2LLK5wcyBDObkb8ZkxuaoSYlI6ZcOKq1eWFdedqNzGHQBk9RMEwFAASkk0Xw3\n",
       "ETacDNi2vtvc7L0ROdw0AjoSotQVkKSvHQz/wRO1lScGModBFbDMaNRN1A4tUBCS3lk7BWhQkgpD\n",
       "lG4852/+7DWr1R3uHAZVQDsbh6ZPN7CyxUrCzJMRouusj0ipRwD2uKm0Zn5d2dFwzX1TCGhnmdGo\n",
       "G62Nna+isiUqhkzuKrkQaJlPEv5mFl2fvGg2t/VnzkEV8F5ioioOEWkLG86fvbpthynjdhXYZziQ\n",
       "x1hC9J2NFyi8vCTt91Fh04KGip0AaG9zuCk2wQCVyoNU3Hjezee9bq92duzzTmxsRJoy+jEZZZYo\n",
       "GTKJ6SJngdJqAfRzpze0+jHreUtPc7gpBLQnIYK6BYp/uGhw9YK688eu7v95ysgshcg9qSLMo3JC\n",
       "4jqLKQFBgdKDPoQ+Pltb8dUyQLpeDjeVgI6EgLIQFT5tEl3rn2losHVsexbZ3EyT9wE1uGdkIPcy\n",
       "BGxn8QUq1QrA5nqW5i2tLqvrrM9NK6AdkVIvL9E9bZL/oyfMVd/jqvc8LylzRBKDJSzIExwhQzuL\n",
       "QYGQj4rHfFTc8mUdu3E7yoLtbTe9gI4EqVgVkug2i5+uXGo919ixbRog+3fTbQ8qJe4ZOYNfMoTI\n",
       "OoshUNosgO60AisX15aeI2PSIp5KiFLI9ubb1vV3Qb2ltwLakUCDAkWX7/nHKRmmGIl9VgYsUhJm\n",
       "2NXjKYADtM1ygne9QQDIXlk49FBstMKx66D1v4+XuQr7vqTe0VcBHQlRWiOCbmmSYe2SqtL6q5rJ\n",
       "zsTb7lKx3FKOYC4DoqyS/B5bvLPxvD9Qtf6saxYLQGJErmDOdOMr/zo96km1nElr8bmPOBwI9COv\n",
       "HnFPRIwmkSOv9kcAS4heRsidOkpeWBgZM+UBrTFAXNYL5Vf2ii9c1trNzpYdaoVil3WIc+wdk+gQ\n",
       "noie3ecCcxt9ITcLAPWt/laGEO/9U6PmzZkenTtsSMQ8uYywJVW+grCstAvCIaAdArAsIWkRDDs/\n",
       "KzLm2YcjY1Lv0UdW73HabE9n6V66cxSzfEmuJssTpKGVp+0vHq73FwL46eOjpMpbRAnNmJFrGJNu\n",
       "Ukf9Yrz+3rghiumCKNXXWPhLYcjxGsIpoCMsIRoFITkW8AuyM8jC1+/QLx4bozCEJIq38+1rtpR6\n",
       "V/yzb8eBlRb3fo5l783N0CWolAzJHaVNzkrTzlEp2bQ2q3TC5gn6wpnoQAmwSiGh2GitnTmVMc5O\n",
       "UyfKWUKCIsU7+fZDKwqdT6DDpvkzAX4/+AMFjk0tDp5GRXLpQ2MUmhgDp5gxQT8+Y7hyPsMi8uxF\n",
       "71H0oebujHALECjFKaW9Lm68n18wXp2kVzIcABytD5iXFzg+WVXkegpAsOOYziqo0OkK76GyquC3\n",
       "ltZAzMhhqlSNmmWTE5T6e3IN05ITFLM4GdN0vtZ3ob8Jh1NAKXFbm5PtLU/eqTSlGjkNAJjdgn/N\n",
       "aedXa0tdi7+t9G0FIF49rtMSEgAs1kDLkTPO7ebm4IUWeyh1bKomXqlgMG6kJmHcSM0clYLJ8XtR\n",
       "1GTnbV3F6I5wCGikAb402npp1h1s7LQUZZSMIfALFOuL3UUrfnS8+rez7v9qcold5tilgHbO1fjK\n",
       "9ubb17u9oshxzMiUBKXWqJNxd+fqb0tLVs4lILFnK71H0Ind7uiPgACVcFJlrb0tV6DzxqqTIhUM\n",
       "CwDf1/rrVhTa33/3pGPxJYdQ2l2cbgVcQSosdx8uqnDtbGjh9SlDVSMNWhlnilfqZk42Th2ZpLpf\n",
       "xrHec5e815zrr0dfBZSwzkZfqsv+1FS1KUknUwPARVvItfKUY+cn57yP7qv07UE3p8B2uhUwLk09\n",
       "e0SCOrK+hbdYHYLjRIl71wWzv9jpEoeOHhGRrJAzyEyNiJuUqX0g2sBN5kGK6y2Blp5M3lsB9Qh4\n",
       "y2Ja6x6+i0ucmKgwMATwhSjdUu49tKrQ/pvN5d53ml2CGwCmJipmKjgmyuaXzNeL2a0AkQ01Th5j\n",
       "2DktO3Jyk8f9vcOBQHV94OK+fPumJmvQHxJoWkaKWq9Vs+yUsbq0zGT1I4RgeH2b5wef7+c7bl8F\n",
       "eKgoHVVZa8ZPEORzR6sT1BzDUAD/d9F78e2Tzv99v8D+fLVTqAKAsbGamKey1Mt9Ann4eH3gTXTz\n",
       "idWtAJ8PQWOk7NzSeQn/OTHDuEikVF1R4z8BQCy+6D1aWRfY0tTGG2OM8rRoPaeIj5ZHzJxszElN\n",
       "VM8K8JS5WOfv8mzRnQAKoEhmt8gyPM4lU9SmBK1MCQBnW4KONT86v1hZ1PbwSXPw4JWussVjtH9Y\n",
       "NCoiL9UoH/6PSu8jFrfY2t36erQHXLIEakMi1SydmzB31h3GGXFDFNPaK8Rme9B79Ixrd0WN+1ij\n",
       "NRQ/doRmuFLBkHSTOm5GruG+pFjFdAmorG4IXH1Qua6ASniclfFtDYt+oUjKipPrCQB7QBQ2lrgP\n",
       "fFzm+9XWUtcqJ3/5vDLDpJ79XHZk3u8nGZ42qlj1+ydtbxysCezrydp6ugmipNJ7WBPB5tydY0jP\n",
       "HaVNzs3QzeE4ZpTbI+ZbnSFPbVOw9vsfnVvqWnirPyCNGD08IlqtYkh2hjZ5dErEQzoNm+6ykyOt\n",
       "Lt5/PQEuSRRKo22VkydK+vvS1XEKlhCJAnsqvcVvH7f/ZU2R67eXbMEGAMiIV5oWZWiWvz5Fv2xG\n",
       "sjqNJQRvn3Rs2lji/lNP19VjAQDgD7FHhujZB9OGqYxRkZxixgRDVlqS6uEOFaJUVu0rPFzctrnF\n",
       "JqijImVp8dEKVWyUXDk92zAuMZ6bFwpBU1HrOw6AdhQgUooChb0+ItMbWJitSo5Ws3IAOGEOtL53\n",
       "0vHZih9sC4vtofZ7Qu6523V/fmGcds1TY3V36pUsBwAbSlxnVh2xLfAD/IAIMDf7XYIkNmXfpp2l\n",
       "18rkAJAy9HKFaIr/qULkeQQKy9zf1JgDB2uaeFNGijo5QsUyacNUUTOnGO42xSnv4oOwpDi1zYkc\n",
       "efUc3I5Gk6PhyTuVKaOGyLUAYPGIoY9Pu/atL/L92+4q9wbflRJ2Trpm/jPjdBtfnqB/dIThcl8A\n",
       "KG7hbRuKnb8qsQsVvVlTrwQAQMUlf3kwJI24Z4JhPMtcfng5GcH49GsrxJpGvvHIaeem2ma+KSjQ\n",
       "lIwUdYyCY8j4dE1KzijNnIP2llF2wcXNnsoapw9XxsgYAl6k+KzUXbi2yP3KR2ecf6z3BFsBICdW\n",
       "nvnIaG3eHybqX7vbpEqUMT+9OL4Qpe8VON7dXuFd39v19FoAABRVePbGGuXTszO0P7tu6lghUonE\n",
       "llRdrhArLvmKdh9u29jcFiRRkfLUxBiFNiqSU9icoZQHo5mYBI1MBgBH6wMNb+U7Pnw337H4gi1Y\n",
       "ciWs+uks3Z9fztUvfzxTm9Ne8XXkvQLHNytOOZeiD4e0PgkAIAYCYknKUNUDSXEKzdWNpnil7r4p\n",
       "xqkjTarZMtk/K8TQ6Qve78qqvXurGwIJqcOUKfUWHsm8KGvxSP68YudXq4pcj39X49uOK2X142O0\n",
       "Tz5/u/7TVybqH0rSya6ZBwD21/gubbrgWdDgEOx9WUhfBaC2ibcEBYm7a7x+ukrBMNcEZggyR0TE\n",
       "T8zUPjikQ4VosQZbTpS4vqizBKvqmvjsqnpfzaZyx9JPiz1/bfGKdgD45XB1zoIMzYbfTdS/NClB\n",
       "Gct0USiY3YL/g0LHy/uq/Ef6uo5+n0R/vyhp17Klpge763f8rMu6YU/zrn2nml+2WtH+Z+5IAAFc\n",
       "2bUTdTDOSNa9+cQY7YLsOIXhevEkCvzph7a8laecz/Un/z4/Ae04XeL3UQb57IwU9ZDr9UuKVajv\n",
       "nxp1+1UVIo/LjztZkKH59fO3G/JemqCfmaCRqbqbd90ZZ8FfjtkfAyD0J/9+C2h1hDwsSxvGjNDc\n",
       "b4zk5NfrSwiQblLHzZhg+Jf4aPlUwpDqkQqa9nimbt1/TDH8OitGMaQnj+RJS6B1fbF7SY1TqO5v\n",
       "/v0WAADl1f7zokgS7s7VT2DZ7pegUjBM7mjtiDZbcN4j0YrHH0rXpCtY0qPX0cVL0rv5jv/ZXend\n",
       "0u/EESYBAFBU4T4Qa5TflZOhTe7pmKpaP8kCVUVw1+yhXfJWvn1P3hnXi33JsTN6PnP3hHZ8Z3/h\n",
       "aLHzmkNPuPj7Bc/F/Q38CwjTpSwQXgE4Vmwry9tpfq/ZFgqFMy4AVDtCvi8rvMvOmv0N4YwbVgEA\n",
       "sPM72/KVnzfspmH7HQGCRLG2yL1+z8XwvPcdCbsAANh+xPzstgMtxeGKt+6MK3/tacfvwhWvIwMi\n",
       "oKEBtm0H7W+UVfkc/Y1V0BhoPlDr/w1w/eu1vjIgAgDg22OtX6/eYfnEz/focrZTHAFR+PSs56/7\n",
       "q32nwpjazxgwAQCwcU/T62t3WL7r6/jVRa6/byp1rei+Z98ZUAEAhEPHPc8fKnTU9nbgtnOe8h0l\n",
       "9hcGIqmODLQAHCy2Xti6v/XNRivf43f4fFvIteu854+VHnR7q9tfBlwAAGz+pnndB9vM26UebAe8\n",
       "SLHujPOTPVW+rwY+sxskAAC2HrA8t2Vvc7ffP1r9o+vwR2dcr92InIAbKKC1FZ5tB1tf+/G8p8sv\n",
       "N/9Q5zd/XR34LYCwV5JdccMEAMDBk45DH243r/X4xGvqxFa/GNpS7n6rwOwNWwHVE26oAADYurf1\n",
       "zx/utOzt+DMKYM0p17YtZZ5VNzqfsB2HewG1WXE8PoZ7gOclbTIvynZf9JV+fqZtfgs/8F/Nu5rB\n",
       "EIBmJ+8QRMmpU7EzGRsf2FzuePqYRbzh/zE26EwdrT10f6r6o8HOYzCJB9Dpff8tbnGLG8L/A/WE\n",
       "roTBs2RqAAAAAElFTkSuQmCC'\n",
       "     style='height:25px; border-radius:12px; display: inline-block; float: left; vertical-align: middle'></img>\n",
       "\n",
       "\n",
       "  <img src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACMAAAAjCAYAAAAe2bNZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAK6wAACusBgosNWgAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAf9SURBVFiFvZh7cFTVHcc/59y7793sJiFAwkvAYDRqFWwdraLVlj61diRYsDjqCFbFKrYo0CltlSq1tLaC2GprGIriGwqjFu10OlrGv8RiK/IICYECSWBDkt3s695zTv9IAtlHeOn0O7Mzu797z+/3Ob/z+p0VfBq9doNFljuABwAXw2PcvGHt6bgwxhz7Ls4YZNVXxxANLENwE2D1W9PAGmAhszZ0/X9gll5yCbHoOirLzmaQs0F6F8QMZq1v/8xgNm7DYwwjgXJLYL4witQ16+sv/U9HdDmV4WrKw6B06cZC/RMrM4MZ7xz61DAbtzEXmAvUAX4pMOVecg9/MFFu3j3Gz7gQBLygS2RGumBkL0cubiFRsR3LzVBV1UMk3IrW73PT9C2lYOwhQB4ClhX1AuKpjLcV27oEjyUpNUJCg1CvcejykWTCXyQgzic2HIIBjg3pS6+uRLKAhumZvD4U+tq0jTrgkVKQQtLekfTtxIPAkhTNF6G7kZm7aPp6M9myKVQEoaYaIhEQYvD781DML/RfBGNZXAl4irJiwBa07e/y7cQnBaJghIX6ENl2GR/fGCBoz6cm5qeyEqQA5ZYA5x5eeiV0Qph4gjFAUSwAr6QllQgcxS/Jm25Cr2Tmpsk03XI9NfI31FTZBEOgVOk51adqDBNPCNPSRlkiDXbBEwOU2WxH+I7itQZ62g56OjM33suq1YsZHVtGZSUI2QdyYgkgOthQNIF7BIGDnRAJgJSgj69cUx1gB8PkOGwL4E1gPrM27gIg7NlGKLQApc7BmEnAxP5g/rw4YqBrCDB5xHkw5rdR/1qTrN/hKNo6YUwVDNpFsnjYS8RbidBPcPXFP6R6yfExuOXmN4A3jv1+8ZUwgY9D2OWjUZE6lO88jDwHI8ZixGiMKSeYTBamCoDk6kDAb6y1OcH1a6KpD/fZesoFw5FlIXAVCIiH4PxrV+p2npVDToTBmtjY8t1swh2V61E9KqWiyuPEjM8dbfxuvfa49Zayf9R136Wr8mBSf/T7bNteA8zwaGEUbFpckWwq95n59dUIywKl2fbOIS5e8bWSu0tJ1a5redAYfqkdjesodFajcgaVNWhXo1C9SrkN3Usmv3UMJrc6/DDwkwEntkEJLe67tSLhvyzK8rHDQWleve5CGk4VZEB1r+5bg2E2si+Y0QatDK6jUVkX5eg2YYlp++ZM+rfMNYamAj8Y7MAVWFqaR1f/t2xzU4IHjybBtthzuiAASqv7jTF7jOqDMAakFHgDNsFyP+FhwZHBmH9F7cutIYkQCylYYv1AZSqsn1/+bX51OMMjPSl2nAnM7hnjOx2v53YgNWAzHM9Q/9l0lQWPSCBSyokAtOBC1Rj+w/1Xs+STDp4/E5g7Rs2zm2+oeVd7PUuHKDf6A4r5EsPT5K3gfCnBXNUYnvGzb+KcCczYYWOnLpy4eOXuG2oec0PBN8XQQAnpvS35AvAykr56rWhPBiV4MvtceGLxk5Mr6A1O8IfK7rl7xJ0r9kyumuP4fa0lMqTBLJIAJqEf1J3qE92lMBndlyfRD2YBghHC4hlny7ASqCeWo5zaoDdIWfnIefNGTb9fC73QDfhyBUCNOxrGPSUBfPem9us253YTV+3mcBbdkUYfzmHiLqZbYdIGHHON2ZlemXouaJUOO6TqtdHEQuXYY8Yt+EbDgmlS6RdzkaDTv2P9A3gICiq93sWhb5mc5wVhuU3Y7m5hOc3So7qFT3SLgOXHb/cyOfMn7xROegoC/PTcn3v8gbKPgDopJFk3R/uBPWQiwQ+2/GJevRMObLUzqe/saJjQUQTTftEVMW9tWxPgAocwcj9abNcZe7s+6t2R2xXZG7zyYLp8Q1PiRBBHym5bYuXi8Qt+/LvGu9f/5YDAxABsaRNPH6Xr4D4Sk87a897SOy9v/fKwjoF2eQel95yDESGEF6gEMwKhLwKus3wOVjTtes7qzgLdXTMnNCNoEpbcrtNuq6N7Xh/+eqcbj94xQkp7mdKpW5XbtbR8Z26kgMCAf2UU5YEovRUVRHbu2b3vK1UdDFkDCyMRQxbpdv8nhKAGIa7QaQedzT07fFPny53R738JoVYBdVrnsNx9XZ9v33UeGO+AA2MMUkgqQ5UcdDLZSFeVgONnXeHqSAC5Ew1BXwko0D1Zct3dT1duOjS3MzZnEUJtBuoQAq3SGOLR4ekjn9NC5nVOaYXf9lETrUkmOJy3pOz8OKIb2A1cWhJCCEzOxU2mUPror+2/L3yyM3pkM7jTjr1nBOgkGeyQ7erxpdJsMAS9wb2F9rzMxNY1K2PMU0WtZV82VU8Wp6vbKJVo9Lx/+4cydORdxCCQ/kDGTZCWsRpLu7VD7bfKqL8V2orKTp/PtzaXy42jr6TwAuisi+7JolUG4wY+8vyrISCMtRrLKWpvjAOqx/QGhp0rjRo5xD3x98CWQuOQN8qumRMmI7jKZPUEpzNVZsj4Zbaq1to5tZZsKIydLWojhIXrJnES79EaOzv3du2NytKuxzJKAA6wF8xqEE8s2jo/1wd/khslQGxd81Zg62Bbp31XBH+iETt7Y3ELA0iU6iGDlQ5mexe0VEx4a3x8V1AaYwFJgTiwaOsDmeK2J8nMUOqsnB1A+dcA04ucCYt0urkjmflk9iT2v30q/gZn5rQPvor4n9Ou634PeBzoznes/iot/7WnClKoM/+zCIjH5kwT8ChQjTHPIPTjFV3PpU/Hx+DM/A9U3IXI4SPCYAAAAABJRU5ErkJggg=='\n",
       "       style='height:15px; border-radius:12px; display: inline-block; float: left'></img>\n",
       "  \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# cheminformatics\n",
    "import rdkit.Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "# logging\n",
    "import tqdm\n",
    "\n",
    "# data preprocessing\n",
    "import sklearn.impute\n",
    "import sklearn.preprocessing\n",
    "\n",
    "# modeling\n",
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "# plotting\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a46dcf-2436-4fe0-bdc2-10111e8ef931",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08fafae2-3d00-41cd-aa18-085907a5484d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from tdc.single_pred import ADME\n",
    "data = ADME(name = 'Caco2_Wang')\n",
    "split = data.get_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a103bd05-78bc-41a8-882f-239caca3d637",
   "metadata": {},
   "source": [
    "### Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8ed2d0e-b8bd-406f-a011-e8cbaa4120a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_descriptor_columns(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Use rdkit to get descriptors of each drug in the `data` df.\n",
    "    Return a Pandas DataFrame with the descriptors as columns in the df and .\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the Drug column\n",
    "    assert 'Drug' in data.columns, \"'Drug' must be a column in the input DataFrame.\"\n",
    "    drugs = data['Drug']\n",
    "    y = data['Y']\n",
    "    \n",
    "    # Get the descriptors for each drug\n",
    "    print(\"Calculating descriptors...\")\n",
    "    descriptors = []\n",
    "    for drug, target in tqdm.tqdm(zip(drugs, y)):\n",
    "        descriptor = Descriptors.CalcMolDescriptors(\n",
    "            rdkit.Chem.MolFromSmiles(drug)\n",
    "        )\n",
    "        descriptor['Drug'] = drug\n",
    "        descriptor['Y'] = target\n",
    "        descriptors.append(descriptor)\n",
    "\n",
    "    # Make a dataframe for the descriptors\n",
    "    df = pd.DataFrame(descriptors)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14c7960a-ea05-433a-98ab-a46c964cbd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "637it [00:28, 22.52it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df = add_descriptor_columns(split['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2c55427-7dde-42fb-b016-c40d3acb7d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91it [00:04, 20.04it/s]\n"
     ]
    }
   ],
   "source": [
    "val_df = add_descriptor_columns(split['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45dc03e2-3772-4607-b77a-7350973da8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "182it [00:07, 24.22it/s]\n"
     ]
    }
   ],
   "source": [
    "test_df = add_descriptor_columns(split['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84930f16-ee6a-4067-9921-1144b1fde264",
   "metadata": {},
   "source": [
    "### Construct DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4825aa3d-78ab-4e54-85df-6f4f3447f90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_dataloader(\n",
    "    data: pd.DataFrame,\n",
    "    imputer=sklearn.impute.SimpleImputer(missing_values=np.nan, strategy='mean'),\n",
    "    fit_imputer=True,\n",
    "    scaler=sklearn.preprocessing.RobustScaler(),\n",
    "    fit_scaler=True,\n",
    ") -> torch.utils.data.DataLoader:\n",
    "    \"\"\"\n",
    "    Make a PyTorch DataLoader from a Pandas DataFrame.\n",
    "\n",
    "    Optionally impute missing values and scale data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract target data\n",
    "    y = data['Y'].values.reshape(-1, 1)\n",
    "    \n",
    "    # Create target tensor\n",
    "    target = torch.tensor(y).to(torch.float32)\n",
    "    \n",
    "    # Extract just the feature data\n",
    "    col_array = np.array(data.columns)\n",
    "    X = data[col_array[~np.isin(col_array, ['Drug_ID', 'Drug', 'Y'])]].values\n",
    "\n",
    "    # Impute missing data\n",
    "    if imputer is not None:\n",
    "        if fit_imputer:\n",
    "            X = imputer.fit_transform(X)\n",
    "        else:\n",
    "            X = imputer.transform(X)\n",
    "\n",
    "    # Scale the feature data\n",
    "    if scaler is not None:\n",
    "        if fit_scaler:\n",
    "            X = scaler.fit_transform(X)\n",
    "        else:\n",
    "            X = scaler.transform(X)\n",
    "\n",
    "    # Create features tensor\n",
    "    features = torch.tensor(X).to(torch.float32)\n",
    "\n",
    "    # Pass to DataLoader\n",
    "    dataset = torch.utils.data.TensorDataset(features, target)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=16)\n",
    "\n",
    "    return dataloader, imputer, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db4de23b-d2d1-492b-a405-761b563e8d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, imputer, scaler = construct_dataloader(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fa91e46-8883-4658-89fa-a36d963c55de",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader, _, _ = construct_dataloader(\n",
    "    val_df,\n",
    "    imputer=imputer,\n",
    "    fit_imputer=False,\n",
    "    scaler=scaler,\n",
    "    fit_scaler=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbd11942-e1a2-4ab4-a5c4-1440f8b0c179",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader, _, _ = construct_dataloader(\n",
    "    test_df,\n",
    "    imputer=imputer,\n",
    "    fit_imputer=False,\n",
    "    scaler=scaler,\n",
    "    fit_scaler=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8caf122-63ba-4db3-8ffa-2c616eac9bef",
   "metadata": {},
   "source": [
    "### Construct NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91227df0-755b-4407-b328-049c3bd00c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffee6973-d1a1-4db9-bbd2-a2d1881fb335",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.stack = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Linear(210, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Linear(32, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Linear(16, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f3d8e4-b464-4412-9cf2-e0253d39c88b",
   "metadata": {},
   "source": [
    "### Train & test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed47614f-cba3-4f68-b534-09643dd138c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Print loss every 200 steps\n",
    "        if batch % 200 == 0 or batch == len(dataloader) - 1:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0d2e87d-edc9-4f7b-add9-850b764d7a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "    test_loss /= num_batches\n",
    "    \n",
    "    print(f\"Test Error: \\n Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad670832-a6fb-475d-bfb5-3d756bc8812e",
   "metadata": {},
   "source": [
    "### Train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb8890ba-3e21-4554-b3a2-ac8ee9f5b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "loss_fn = torch.nn.L1Loss() # MAE\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cea1605f-1cc2-414f-ad4b-37ed87e13966",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (stack): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=210, out_features=32, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Dropout(p=0.2, inplace=False)\n",
      "    (7): Linear(in_features=16, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0486b01a-a047-4082-b6e8-bfe9500c5de9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 4.948452  [   16/  637]\n",
      "loss: 5.052940  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 4.889187 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 4.208209  [   16/  637]\n",
      "loss: 2.845092  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 3.062905 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.673915  [   16/  637]\n",
      "loss: 1.772653  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 4.264842 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.925599  [   16/  637]\n",
      "loss: 1.318423  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 3.302973 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.683722  [   16/  637]\n",
      "loss: 1.734256  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 2.114633 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.459931  [   16/  637]\n",
      "loss: 1.652546  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 1.665875 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.270940  [   16/  637]\n",
      "loss: 1.485581  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.873332 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.432155  [   16/  637]\n",
      "loss: 1.244865  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.950415 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.186789  [   16/  637]\n",
      "loss: 1.607846  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.838893 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.813828  [   16/  637]\n",
      "loss: 1.472509  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.993482 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.682779  [   16/  637]\n",
      "loss: 1.750940  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.908898 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.244483  [   16/  637]\n",
      "loss: 1.870592  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.823043 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.453154  [   16/  637]\n",
      "loss: 1.533035  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 1.196580 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.459945  [   16/  637]\n",
      "loss: 1.482545  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.937283 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.210660  [   16/  637]\n",
      "loss: 1.214958  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.750904 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.492775  [   16/  637]\n",
      "loss: 1.600963  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.729685 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.128444  [   16/  637]\n",
      "loss: 1.253020  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.744592 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.548834  [   16/  637]\n",
      "loss: 1.684029  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.777049 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.216237  [   16/  637]\n",
      "loss: 1.179260  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.659650 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.402597  [   16/  637]\n",
      "loss: 1.009752  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.677164 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.451199  [   16/  637]\n",
      "loss: 1.135377  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.724130 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1.446056  [   16/  637]\n",
      "loss: 1.346225  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.636490 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1.041805  [   16/  637]\n",
      "loss: 1.331963  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.670281 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1.082504  [   16/  637]\n",
      "loss: 0.873531  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.692635 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1.184152  [   16/  637]\n",
      "loss: 1.343498  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.673858 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 1.290775  [   16/  637]\n",
      "loss: 1.008559  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.698051 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 1.198119  [   16/  637]\n",
      "loss: 1.101771  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.655637 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 1.189599  [   16/  637]\n",
      "loss: 1.319277  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.869789 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 1.124928  [   16/  637]\n",
      "loss: 1.267506  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.669757 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 1.055640  [   16/  637]\n",
      "loss: 1.113276  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.838444 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 1.386690  [   16/  637]\n",
      "loss: 1.505589  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.639432 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 1.122595  [   16/  637]\n",
      "loss: 1.072098  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.601613 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 1.011833  [   16/  637]\n",
      "loss: 1.719982  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.703726 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 1.202731  [   16/  637]\n",
      "loss: 1.463028  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.635188 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.911942  [   16/  637]\n",
      "loss: 1.080486  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.627724 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.847231  [   16/  637]\n",
      "loss: 1.597879  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.610471 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 1.520091  [   16/  637]\n",
      "loss: 1.269606  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.617790 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.812438  [   16/  637]\n",
      "loss: 0.955601  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.586492 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.970844  [   16/  637]\n",
      "loss: 1.306206  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.652549 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 1.049100  [   16/  637]\n",
      "loss: 1.314494  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.625903 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 1.193501  [   16/  637]\n",
      "loss: 0.842205  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.603390 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.990457  [   16/  637]\n",
      "loss: 1.528828  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.569080 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 1.058747  [   16/  637]\n",
      "loss: 1.012655  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.526537 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.711554  [   16/  637]\n",
      "loss: 0.865844  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.610404 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.917658  [   16/  637]\n",
      "loss: 0.741183  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.591899 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 1.644311  [   16/  637]\n",
      "loss: 1.056990  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.574012 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 1.045340  [   16/  637]\n",
      "loss: 0.926660  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.633556 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 1.081473  [   16/  637]\n",
      "loss: 1.145253  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.590245 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.733605  [   16/  637]\n",
      "loss: 1.314166  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.648894 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 1.049950  [   16/  637]\n",
      "loss: 1.123300  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.579130 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 1.021208  [   16/  637]\n",
      "loss: 0.788033  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.609922 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.930126  [   16/  637]\n",
      "loss: 1.402584  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.583956 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.923384  [   16/  637]\n",
      "loss: 1.014281  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.549066 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 1.068572  [   16/  637]\n",
      "loss: 0.971783  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.518055 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.996509  [   16/  637]\n",
      "loss: 1.298525  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.550986 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 1.074276  [   16/  637]\n",
      "loss: 1.084319  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.571873 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.895121  [   16/  637]\n",
      "loss: 1.162145  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.525334 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.754067  [   16/  637]\n",
      "loss: 1.168788  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.568945 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.859165  [   16/  637]\n",
      "loss: 1.048952  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.534456 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.926363  [   16/  637]\n",
      "loss: 0.922284  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.581598 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.812909  [   16/  637]\n",
      "loss: 0.966653  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.514215 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 1.090922  [   16/  637]\n",
      "loss: 1.219982  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.585148 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.823663  [   16/  637]\n",
      "loss: 0.803686  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.540341 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.877731  [   16/  637]\n",
      "loss: 0.943337  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.539463 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 1.132629  [   16/  637]\n",
      "loss: 0.988668  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.491127 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.687424  [   16/  637]\n",
      "loss: 0.963500  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.628288 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.937579  [   16/  637]\n",
      "loss: 0.900980  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.505447 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.905046  [   16/  637]\n",
      "loss: 1.083360  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.517449 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.927065  [   16/  637]\n",
      "loss: 0.911050  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.544669 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 1.019386  [   16/  637]\n",
      "loss: 1.021878  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.516295 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.490824  [   16/  637]\n",
      "loss: 1.003597  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.571896 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.456012  [   16/  637]\n",
      "loss: 1.057300  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.529874 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.895705  [   16/  637]\n",
      "loss: 1.079304  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.495712 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.738215  [   16/  637]\n",
      "loss: 1.004573  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.527368 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.753270  [   16/  637]\n",
      "loss: 1.015334  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.530240 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.626947  [   16/  637]\n",
      "loss: 0.549237  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.538267 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.638153  [   16/  637]\n",
      "loss: 0.804022  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.463975 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.878667  [   16/  637]\n",
      "loss: 0.419946  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.541259 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.785210  [   16/  637]\n",
      "loss: 1.003074  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.485706 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.744434  [   16/  637]\n",
      "loss: 0.763584  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.478342 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.859205  [   16/  637]\n",
      "loss: 0.918472  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.469447 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.758435  [   16/  637]\n",
      "loss: 0.824999  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.495855 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.656657  [   16/  637]\n",
      "loss: 0.811906  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.454843 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.756092  [   16/  637]\n",
      "loss: 0.548957  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.486124 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.527354  [   16/  637]\n",
      "loss: 0.740522  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.470117 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.577235  [   16/  637]\n",
      "loss: 0.685984  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.492178 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.665227  [   16/  637]\n",
      "loss: 0.995495  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.481946 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.552986  [   16/  637]\n",
      "loss: 0.767943  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.500936 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.677803  [   16/  637]\n",
      "loss: 0.714088  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.450222 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.588490  [   16/  637]\n",
      "loss: 0.908407  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.516433 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.737676  [   16/  637]\n",
      "loss: 0.803999  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.465236 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.706860  [   16/  637]\n",
      "loss: 0.526363  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.444719 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.626135  [   16/  637]\n",
      "loss: 0.844969  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.484688 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.666821  [   16/  637]\n",
      "loss: 0.850210  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.535778 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.490856  [   16/  637]\n",
      "loss: 0.887330  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.474765 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.760596  [   16/  637]\n",
      "loss: 0.828126  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.440014 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.791035  [   16/  637]\n",
      "loss: 0.674386  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.457939 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.606332  [   16/  637]\n",
      "loss: 0.800438  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.502392 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.625739  [   16/  637]\n",
      "loss: 0.750040  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.462266 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.597273  [   16/  637]\n",
      "loss: 0.794749  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.446620 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.574262  [   16/  637]\n",
      "loss: 0.603669  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.458506 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.772788  [   16/  637]\n",
      "loss: 0.700989  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.491706 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.622661  [   16/  637]\n",
      "loss: 0.779275  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.435236 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.649432  [   16/  637]\n",
      "loss: 0.899796  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.436127 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.630401  [   16/  637]\n",
      "loss: 0.825415  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.447426 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.505329  [   16/  637]\n",
      "loss: 0.836822  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.468593 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.538262  [   16/  637]\n",
      "loss: 0.371235  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.456704 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.583927  [   16/  637]\n",
      "loss: 0.619543  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.428278 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.554772  [   16/  637]\n",
      "loss: 0.454114  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.439536 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.659007  [   16/  637]\n",
      "loss: 0.961467  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.455489 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.675291  [   16/  637]\n",
      "loss: 0.517043  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.453072 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.724045  [   16/  637]\n",
      "loss: 0.531297  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.446145 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.645964  [   16/  637]\n",
      "loss: 0.803804  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.434316 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.564716  [   16/  637]\n",
      "loss: 0.507504  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.430642 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.632472  [   16/  637]\n",
      "loss: 0.701475  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.474025 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.705685  [   16/  637]\n",
      "loss: 0.502182  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.423946 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.601902  [   16/  637]\n",
      "loss: 0.667785  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.440418 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.678704  [   16/  637]\n",
      "loss: 0.645193  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.434095 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.425682  [   16/  637]\n",
      "loss: 0.697945  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.469652 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.757267  [   16/  637]\n",
      "loss: 0.442665  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.435581 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.507321  [   16/  637]\n",
      "loss: 0.371419  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.420929 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.549316  [   16/  637]\n",
      "loss: 0.812481  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.427609 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.484942  [   16/  637]\n",
      "loss: 0.532298  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.449105 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.609576  [   16/  637]\n",
      "loss: 0.375804  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.407480 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.524228  [   16/  637]\n",
      "loss: 0.650037  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.630691 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.504853  [   16/  637]\n",
      "loss: 0.442372  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.431037 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.568884  [   16/  637]\n",
      "loss: 0.804018  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.434041 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.590391  [   16/  637]\n",
      "loss: 0.478599  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.405759 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.441669  [   16/  637]\n",
      "loss: 0.541550  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.418762 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.506498  [   16/  637]\n",
      "loss: 0.622977  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.404918 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.514450  [   16/  637]\n",
      "loss: 0.660364  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.413311 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.483781  [   16/  637]\n",
      "loss: 0.406183  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.402994 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.532527  [   16/  637]\n",
      "loss: 0.426428  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.395910 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.640818  [   16/  637]\n",
      "loss: 0.477649  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.425562 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.512637  [   16/  637]\n",
      "loss: 0.719627  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.397806 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.566569  [   16/  637]\n",
      "loss: 0.356024  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.405642 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.413605  [   16/  637]\n",
      "loss: 0.560022  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.391789 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.428904  [   16/  637]\n",
      "loss: 0.472925  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.387062 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.377167  [   16/  637]\n",
      "loss: 0.310907  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.387854 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.639839  [   16/  637]\n",
      "loss: 0.531324  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.405597 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.588750  [   16/  637]\n",
      "loss: 0.635963  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.388850 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.424154  [   16/  637]\n",
      "loss: 0.494879  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.389748 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.506509  [   16/  637]\n",
      "loss: 0.410760  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.361693 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.540988  [   16/  637]\n",
      "loss: 0.475292  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.403348 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.484160  [   16/  637]\n",
      "loss: 0.307861  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.395670 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.500374  [   16/  637]\n",
      "loss: 0.526544  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.411735 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.584137  [   16/  637]\n",
      "loss: 0.641222  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.408708 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.488316  [   16/  637]\n",
      "loss: 0.777635  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.393169 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.368162  [   16/  637]\n",
      "loss: 0.588183  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.399615 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.529425  [   16/  637]\n",
      "loss: 0.372077  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.394918 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.336547  [   16/  637]\n",
      "loss: 0.269509  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.394512 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.461633  [   16/  637]\n",
      "loss: 0.604385  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.384818 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.491822  [   16/  637]\n",
      "loss: 0.469514  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.389288 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.528624  [   16/  637]\n",
      "loss: 0.499824  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.391450 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.496445  [   16/  637]\n",
      "loss: 0.453601  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.391215 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.488953  [   16/  637]\n",
      "loss: 0.392838  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.386324 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.406001  [   16/  637]\n",
      "loss: 0.332736  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.382729 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.414044  [   16/  637]\n",
      "loss: 0.265025  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.382711 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.647579  [   16/  637]\n",
      "loss: 0.433840  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.383085 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.513143  [   16/  637]\n",
      "loss: 0.512493  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.383496 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.409447  [   16/  637]\n",
      "loss: 0.356746  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.377232 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.534043  [   16/  637]\n",
      "loss: 0.523322  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.383481 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.382447  [   16/  637]\n",
      "loss: 0.423683  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.392144 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.475349  [   16/  637]\n",
      "loss: 0.258487  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.383992 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.458825  [   16/  637]\n",
      "loss: 0.445153  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.388696 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.599850  [   16/  637]\n",
      "loss: 0.417548  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.378729 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.440091  [   16/  637]\n",
      "loss: 0.490707  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.381246 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.402461  [   16/  637]\n",
      "loss: 0.490595  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.382263 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.553645  [   16/  637]\n",
      "loss: 0.452340  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.378132 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.351417  [   16/  637]\n",
      "loss: 0.393009  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.375169 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.505470  [   16/  637]\n",
      "loss: 0.453174  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.379449 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.442921  [   16/  637]\n",
      "loss: 0.607299  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.384308 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.381425  [   16/  637]\n",
      "loss: 0.309720  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.389555 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.530934  [   16/  637]\n",
      "loss: 0.408662  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.377050 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.506309  [   16/  637]\n",
      "loss: 0.425169  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.368803 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.363004  [   16/  637]\n",
      "loss: 0.497687  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.368653 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.462040  [   16/  637]\n",
      "loss: 0.268464  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.376104 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.418249  [   16/  637]\n",
      "loss: 0.346447  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.368272 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.501342  [   16/  637]\n",
      "loss: 0.483871  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.377690 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.409571  [   16/  637]\n",
      "loss: 0.492374  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.365170 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.396795  [   16/  637]\n",
      "loss: 0.369681  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.360553 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.474439  [   16/  637]\n",
      "loss: 0.253508  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.362760 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.428213  [   16/  637]\n",
      "loss: 0.389967  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.360096 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.410506  [   16/  637]\n",
      "loss: 0.420750  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.372027 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.412832  [   16/  637]\n",
      "loss: 0.337991  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.357345 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.481003  [   16/  637]\n",
      "loss: 0.373413  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.362188 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.377894  [   16/  637]\n",
      "loss: 0.516957  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.377513 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.433229  [   16/  637]\n",
      "loss: 0.460563  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.349945 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.385302  [   16/  637]\n",
      "loss: 0.392421  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.365929 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.456054  [   16/  637]\n",
      "loss: 0.423363  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.361208 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.406751  [   16/  637]\n",
      "loss: 0.438470  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.354316 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.577603  [   16/  637]\n",
      "loss: 0.374594  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.356083 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.298325  [   16/  637]\n",
      "loss: 0.354038  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.360263 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.469359  [   16/  637]\n",
      "loss: 0.591708  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.346328 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.437814  [   16/  637]\n",
      "loss: 0.427704  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.376315 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.477667  [   16/  637]\n",
      "loss: 0.385330  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.357506 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.473013  [   16/  637]\n",
      "loss: 0.364269  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.357889 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.392348  [   16/  637]\n",
      "loss: 0.500870  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.359183 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.428649  [   16/  637]\n",
      "loss: 0.462502  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.360311 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.414854  [   16/  637]\n",
      "loss: 0.440981  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.354437 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.420147  [   16/  637]\n",
      "loss: 0.407580  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.365302 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.353097  [   16/  637]\n",
      "loss: 0.305187  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.359986 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.516505  [   16/  637]\n",
      "loss: 0.455577  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.357021 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.289237  [   16/  637]\n",
      "loss: 0.423228  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.353373 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.469705  [   16/  637]\n",
      "loss: 0.402757  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.351044 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.470292  [   16/  637]\n",
      "loss: 0.303374  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.355502 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.364942  [   16/  637]\n",
      "loss: 0.478866  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.351245 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.344124  [   16/  637]\n",
      "loss: 0.356220  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.358873 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.462055  [   16/  637]\n",
      "loss: 0.551198  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.354018 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.439772  [   16/  637]\n",
      "loss: 0.360004  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.358757 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.425743  [   16/  637]\n",
      "loss: 0.287362  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.348760 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.410975  [   16/  637]\n",
      "loss: 0.376789  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.349236 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.400104  [   16/  637]\n",
      "loss: 0.354801  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.368051 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.327443  [   16/  637]\n",
      "loss: 0.301001  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.348258 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.331799  [   16/  637]\n",
      "loss: 0.390446  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.373825 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.477369  [   16/  637]\n",
      "loss: 0.217065  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.351688 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.373678  [   16/  637]\n",
      "loss: 0.278106  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.386039 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.451340  [   16/  637]\n",
      "loss: 0.461408  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.364539 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.423956  [   16/  637]\n",
      "loss: 0.386208  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.348005 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.433520  [   16/  637]\n",
      "loss: 0.457430  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.352548 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.343050  [   16/  637]\n",
      "loss: 0.352386  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.357082 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.339797  [   16/  637]\n",
      "loss: 0.260849  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.346004 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.475005  [   16/  637]\n",
      "loss: 0.354314  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.339656 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.323151  [   16/  637]\n",
      "loss: 0.516600  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.338857 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.382927  [   16/  637]\n",
      "loss: 0.580804  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.347869 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.472110  [   16/  637]\n",
      "loss: 0.473173  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.348011 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.382644  [   16/  637]\n",
      "loss: 0.297817  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.341785 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.395642  [   16/  637]\n",
      "loss: 0.416255  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.341234 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.410091  [   16/  637]\n",
      "loss: 0.408845  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.345578 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.341664  [   16/  637]\n",
      "loss: 0.439498  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.343396 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.400274  [   16/  637]\n",
      "loss: 0.316786  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.347918 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.371170  [   16/  637]\n",
      "loss: 0.344481  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.348596 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.519307  [   16/  637]\n",
      "loss: 0.476002  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.360716 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.350659  [   16/  637]\n",
      "loss: 0.369961  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.343555 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.409116  [   16/  637]\n",
      "loss: 0.439516  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.340714 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.280862  [   16/  637]\n",
      "loss: 0.340790  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.345617 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.377451  [   16/  637]\n",
      "loss: 0.349453  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.336070 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.367120  [   16/  637]\n",
      "loss: 0.396707  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.341060 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.406803  [   16/  637]\n",
      "loss: 0.326262  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.342441 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.439421  [   16/  637]\n",
      "loss: 0.342418  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.339084 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.413363  [   16/  637]\n",
      "loss: 0.389659  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.328876 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.367600  [   16/  637]\n",
      "loss: 0.293548  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.335500 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.349196  [   16/  637]\n",
      "loss: 0.599048  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.333277 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.371930  [   16/  637]\n",
      "loss: 0.332525  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.337898 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.407774  [   16/  637]\n",
      "loss: 0.276773  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.338506 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.382117  [   16/  637]\n",
      "loss: 0.402978  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.337435 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.332959  [   16/  637]\n",
      "loss: 0.375956  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.345124 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.409540  [   16/  637]\n",
      "loss: 0.378929  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.351701 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.384992  [   16/  637]\n",
      "loss: 0.365970  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.348191 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.274711  [   16/  637]\n",
      "loss: 0.343219  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.339744 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.332886  [   16/  637]\n",
      "loss: 0.408867  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.347147 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.427836  [   16/  637]\n",
      "loss: 0.356356  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.341471 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.332975  [   16/  637]\n",
      "loss: 0.280533  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.326110 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.428868  [   16/  637]\n",
      "loss: 0.240937  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.333235 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.420000  [   16/  637]\n",
      "loss: 0.310193  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.334066 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.387838  [   16/  637]\n",
      "loss: 0.314947  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.320986 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.405142  [   16/  637]\n",
      "loss: 0.220080  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.323851 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.412828  [   16/  637]\n",
      "loss: 0.143990  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.330518 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.344897  [   16/  637]\n",
      "loss: 0.359004  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.335229 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.366518  [   16/  637]\n",
      "loss: 0.376067  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.336856 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.362246  [   16/  637]\n",
      "loss: 0.361187  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.325974 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.440930  [   16/  637]\n",
      "loss: 0.360737  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.336848 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.394720  [   16/  637]\n",
      "loss: 0.496997  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.336078 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.304586  [   16/  637]\n",
      "loss: 0.263082  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.327378 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.320591  [   16/  637]\n",
      "loss: 0.190751  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.326101 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.307624  [   16/  637]\n",
      "loss: 0.341113  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.319553 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.409704  [   16/  637]\n",
      "loss: 0.377446  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.339019 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.331914  [   16/  637]\n",
      "loss: 0.282469  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.328493 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.385922  [   16/  637]\n",
      "loss: 0.309960  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.323764 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.442479  [   16/  637]\n",
      "loss: 0.324121  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.327319 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.322869  [   16/  637]\n",
      "loss: 0.324613  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.320089 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.361241  [   16/  637]\n",
      "loss: 0.348492  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.310952 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.409909  [   16/  637]\n",
      "loss: 0.271010  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.318775 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.304513  [   16/  637]\n",
      "loss: 0.189403  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.322184 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.357028  [   16/  637]\n",
      "loss: 0.308729  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.324345 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.385368  [   16/  637]\n",
      "loss: 0.370698  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.323506 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.411847  [   16/  637]\n",
      "loss: 0.298588  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.319914 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.388752  [   16/  637]\n",
      "loss: 0.291700  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.324341 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.310345  [   16/  637]\n",
      "loss: 0.242916  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.314967 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.383114  [   16/  637]\n",
      "loss: 0.338405  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.313510 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.457469  [   16/  637]\n",
      "loss: 0.237562  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.314812 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.341534  [   16/  637]\n",
      "loss: 0.360889  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.318769 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.357913  [   16/  637]\n",
      "loss: 0.331173  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.323111 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.304456  [   16/  637]\n",
      "loss: 0.234591  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.326748 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.394219  [   16/  637]\n",
      "loss: 0.279277  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.328246 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.349488  [   16/  637]\n",
      "loss: 0.268100  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.322902 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.346248  [   16/  637]\n",
      "loss: 0.252066  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.313127 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.450486  [   16/  637]\n",
      "loss: 0.232011  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.311842 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.325784  [   16/  637]\n",
      "loss: 0.278228  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.326987 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.415407  [   16/  637]\n",
      "loss: 0.266274  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.324998 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.382543  [   16/  637]\n",
      "loss: 0.171698  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.308903 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.380786  [   16/  637]\n",
      "loss: 0.342840  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.346286 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.357641  [   16/  637]\n",
      "loss: 0.498141  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.313207 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.280878  [   16/  637]\n",
      "loss: 0.371098  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.320424 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.313348  [   16/  637]\n",
      "loss: 0.374707  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.320254 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.392797  [   16/  637]\n",
      "loss: 0.245826  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.318183 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.407048  [   16/  637]\n",
      "loss: 0.339625  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.310161 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.404639  [   16/  637]\n",
      "loss: 0.183998  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.309836 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.337174  [   16/  637]\n",
      "loss: 0.240128  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.314711 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.377948  [   16/  637]\n",
      "loss: 0.500193  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.314280 \n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 0.384278  [   16/  637]\n",
      "loss: 0.244324  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.312036 \n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 0.276870  [   16/  637]\n",
      "loss: 0.260643  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.314515 \n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 0.313521  [   16/  637]\n",
      "loss: 0.337550  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.313736 \n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 0.332379  [   16/  637]\n",
      "loss: 0.259667  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.316965 \n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 0.434887  [   16/  637]\n",
      "loss: 0.427083  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.324982 \n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 0.310371  [   16/  637]\n",
      "loss: 0.208540  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.319427 \n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 0.291345  [   16/  637]\n",
      "loss: 0.207084  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.318004 \n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 0.319229  [   16/  637]\n",
      "loss: 0.350967  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.322832 \n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 0.310557  [   16/  637]\n",
      "loss: 0.242383  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.315503 \n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 0.472221  [   16/  637]\n",
      "loss: 0.287759  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.314421 \n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 0.400040  [   16/  637]\n",
      "loss: 0.297460  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.314783 \n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 0.309434  [   16/  637]\n",
      "loss: 0.333946  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.310554 \n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 0.320355  [   16/  637]\n",
      "loss: 0.364843  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.316722 \n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 0.422119  [   16/  637]\n",
      "loss: 0.265360  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.309411 \n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 0.400028  [   16/  637]\n",
      "loss: 0.336740  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.327297 \n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 0.335307  [   16/  637]\n",
      "loss: 0.271612  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.312362 \n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 0.373996  [   16/  637]\n",
      "loss: 0.319947  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.327524 \n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 0.301518  [   16/  637]\n",
      "loss: 0.289467  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.315461 \n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 0.325734  [   16/  637]\n",
      "loss: 0.345161  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.308666 \n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 0.351462  [   16/  637]\n",
      "loss: 0.352583  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.307091 \n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 0.402732  [   16/  637]\n",
      "loss: 0.266220  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.313256 \n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 0.317199  [   16/  637]\n",
      "loss: 0.305102  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.332442 \n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 0.347503  [   16/  637]\n",
      "loss: 0.249453  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.322890 \n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 0.337329  [   16/  637]\n",
      "loss: 0.242628  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.311224 \n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 0.252473  [   16/  637]\n",
      "loss: 0.173055  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.314585 \n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 0.341582  [   16/  637]\n",
      "loss: 0.268645  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.307551 \n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 0.352161  [   16/  637]\n",
      "loss: 0.346017  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.307274 \n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 0.431058  [   16/  637]\n",
      "loss: 0.272279  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.308658 \n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 0.375550  [   16/  637]\n",
      "loss: 0.273689  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.308265 \n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 0.378651  [   16/  637]\n",
      "loss: 0.297230  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.310712 \n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 0.297202  [   16/  637]\n",
      "loss: 0.277716  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.316265 \n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 0.411364  [   16/  637]\n",
      "loss: 0.287361  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.318916 \n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 0.296906  [   16/  637]\n",
      "loss: 0.216440  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.311547 \n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 0.358230  [   16/  637]\n",
      "loss: 0.189039  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.308167 \n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 0.434831  [   16/  637]\n",
      "loss: 0.290563  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.314645 \n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 0.423377  [   16/  637]\n",
      "loss: 0.168694  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.315745 \n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 0.393598  [   16/  637]\n",
      "loss: 0.349908  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.314284 \n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 0.343139  [   16/  637]\n",
      "loss: 0.314247  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.312536 \n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 0.348789  [   16/  637]\n",
      "loss: 0.275108  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.316708 \n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 0.342349  [   16/  637]\n",
      "loss: 0.158825  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.304171 \n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 0.346844  [   16/  637]\n",
      "loss: 0.272668  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.304182 \n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 0.339950  [   16/  637]\n",
      "loss: 0.242254  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.317691 \n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 0.275165  [   16/  637]\n",
      "loss: 0.261779  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.311247 \n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.279938  [   16/  637]\n",
      "loss: 0.326183  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.316969 \n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 0.320127  [   16/  637]\n",
      "loss: 0.294951  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.329460 \n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 0.358744  [   16/  637]\n",
      "loss: 0.319334  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.315186 \n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 0.319526  [   16/  637]\n",
      "loss: 0.413067  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.316730 \n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 0.290826  [   16/  637]\n",
      "loss: 0.318033  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.321837 \n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 0.331119  [   16/  637]\n",
      "loss: 0.223114  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.322755 \n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 0.212986  [   16/  637]\n",
      "loss: 0.192488  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.314733 \n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 0.350001  [   16/  637]\n",
      "loss: 0.355292  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.319189 \n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 0.349806  [   16/  637]\n",
      "loss: 0.278734  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.318690 \n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 0.292826  [   16/  637]\n",
      "loss: 0.247937  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.339866 \n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 0.306843  [   16/  637]\n",
      "loss: 0.266604  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.324346 \n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 0.392475  [   16/  637]\n",
      "loss: 0.351351  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.316254 \n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 0.279085  [   16/  637]\n",
      "loss: 0.330367  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.333978 \n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 0.424701  [   16/  637]\n",
      "loss: 0.356064  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.329626 \n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 0.420821  [   16/  637]\n",
      "loss: 0.278940  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.318148 \n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.292154  [   16/  637]\n",
      "loss: 0.269584  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.314992 \n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 0.329881  [   16/  637]\n",
      "loss: 0.233076  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.325089 \n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 0.276461  [   16/  637]\n",
      "loss: 0.331865  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.307734 \n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 0.390446  [   16/  637]\n",
      "loss: 0.233336  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.322095 \n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 0.342513  [   16/  637]\n",
      "loss: 0.198931  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.310119 \n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 0.332289  [   16/  637]\n",
      "loss: 0.356720  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.308634 \n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 0.423507  [   16/  637]\n",
      "loss: 0.246435  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.307467 \n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 0.385420  [   16/  637]\n",
      "loss: 0.307157  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.322430 \n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 0.467000  [   16/  637]\n",
      "loss: 0.234858  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.308640 \n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 0.293242  [   16/  637]\n",
      "loss: 0.320627  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.315215 \n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 0.403771  [   16/  637]\n",
      "loss: 0.386078  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.307824 \n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.440626  [   16/  637]\n",
      "loss: 0.243243  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.320584 \n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 0.346740  [   16/  637]\n",
      "loss: 0.326838  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.319832 \n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 0.373966  [   16/  637]\n",
      "loss: 0.292282  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.315994 \n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 0.297384  [   16/  637]\n",
      "loss: 0.364082  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.321558 \n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 0.431477  [   16/  637]\n",
      "loss: 0.350767  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.316824 \n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 0.360175  [   16/  637]\n",
      "loss: 0.222614  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.321534 \n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 0.365001  [   16/  637]\n",
      "loss: 0.302659  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.302600 \n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 0.323327  [   16/  637]\n",
      "loss: 0.313219  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.331922 \n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 0.308503  [   16/  637]\n",
      "loss: 0.275927  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.315530 \n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 0.329499  [   16/  637]\n",
      "loss: 0.221177  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.319126 \n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 0.311366  [   16/  637]\n",
      "loss: 0.412848  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.307202 \n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 0.273647  [   16/  637]\n",
      "loss: 0.263664  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.306186 \n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 0.309536  [   16/  637]\n",
      "loss: 0.246144  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.308871 \n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 0.316202  [   16/  637]\n",
      "loss: 0.279253  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.308479 \n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 0.242597  [   16/  637]\n",
      "loss: 0.228687  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.313835 \n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.433370  [   16/  637]\n",
      "loss: 0.346912  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.371841 \n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 0.419624  [   16/  637]\n",
      "loss: 0.274684  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.325025 \n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 0.363139  [   16/  637]\n",
      "loss: 0.256606  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.321562 \n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 0.305771  [   16/  637]\n",
      "loss: 0.271503  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.311141 \n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 0.353792  [   16/  637]\n",
      "loss: 0.371686  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.311732 \n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 0.304284  [   16/  637]\n",
      "loss: 0.273988  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.328712 \n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 0.377261  [   16/  637]\n",
      "loss: 0.330204  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.327833 \n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 0.328815  [   16/  637]\n",
      "loss: 0.369549  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.307989 \n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 0.319531  [   16/  637]\n",
      "loss: 0.280772  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.326629 \n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 0.417375  [   16/  637]\n",
      "loss: 0.502234  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.384408 \n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 0.410379  [   16/  637]\n",
      "loss: 0.341831  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.320867 \n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 0.288346  [   16/  637]\n",
      "loss: 0.320507  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.329042 \n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 0.350933  [   16/  637]\n",
      "loss: 0.411115  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.326211 \n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 0.332528  [   16/  637]\n",
      "loss: 0.272273  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.315662 \n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 0.317866  [   16/  637]\n",
      "loss: 0.245922  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.306318 \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 0.312294  [   16/  637]\n",
      "loss: 0.400217  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.313511 \n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 0.377428  [   16/  637]\n",
      "loss: 0.254759  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.308155 \n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 0.268702  [   16/  637]\n",
      "loss: 0.232427  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.309171 \n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 0.393167  [   16/  637]\n",
      "loss: 0.356657  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.330521 \n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 0.381588  [   16/  637]\n",
      "loss: 0.269731  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.317111 \n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 0.311365  [   16/  637]\n",
      "loss: 0.296696  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.324891 \n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 0.316743  [   16/  637]\n",
      "loss: 0.505790  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.356147 \n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 0.345328  [   16/  637]\n",
      "loss: 0.242538  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.314651 \n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 0.333017  [   16/  637]\n",
      "loss: 0.170181  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.317862 \n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 0.351763  [   16/  637]\n",
      "loss: 0.371696  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.318087 \n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 0.419567  [   16/  637]\n",
      "loss: 0.246867  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.320096 \n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 0.379607  [   16/  637]\n",
      "loss: 0.296177  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.327620 \n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 0.294688  [   16/  637]\n",
      "loss: 0.273615  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.315473 \n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 0.301836  [   16/  637]\n",
      "loss: 0.321869  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.319717 \n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 0.372205  [   16/  637]\n",
      "loss: 0.238290  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.316998 \n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.413003  [   16/  637]\n",
      "loss: 0.393615  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.308927 \n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 0.367064  [   16/  637]\n",
      "loss: 0.370786  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.316841 \n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 0.319871  [   16/  637]\n",
      "loss: 0.238065  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.308585 \n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 0.349096  [   16/  637]\n",
      "loss: 0.304353  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.314416 \n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 0.470769  [   16/  637]\n",
      "loss: 0.364475  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.312858 \n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 0.365134  [   16/  637]\n",
      "loss: 0.235097  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.313205 \n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 0.339618  [   16/  637]\n",
      "loss: 0.252065  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.312887 \n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 0.396031  [   16/  637]\n",
      "loss: 0.276502  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.312369 \n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 0.275753  [   16/  637]\n",
      "loss: 0.337909  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.313453 \n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 0.365163  [   16/  637]\n",
      "loss: 0.283208  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.309280 \n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 0.331821  [   16/  637]\n",
      "loss: 0.217615  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.300296 \n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 0.364670  [   16/  637]\n",
      "loss: 0.259708  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.310124 \n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 0.322008  [   16/  637]\n",
      "loss: 0.272986  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.297768 \n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 0.335435  [   16/  637]\n",
      "loss: 0.291663  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.306412 \n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 0.245175  [   16/  637]\n",
      "loss: 0.213365  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.309533 \n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 0.289994  [   16/  637]\n",
      "loss: 0.230552  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.308523 \n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 0.345127  [   16/  637]\n",
      "loss: 0.238627  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.308331 \n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 0.369072  [   16/  637]\n",
      "loss: 0.241584  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.304347 \n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 0.313091  [   16/  637]\n",
      "loss: 0.174578  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.306804 \n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 0.381329  [   16/  637]\n",
      "loss: 0.279037  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.313576 \n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 0.309468  [   16/  637]\n",
      "loss: 0.387279  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.310765 \n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 0.437605  [   16/  637]\n",
      "loss: 0.303959  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.311414 \n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 0.400789  [   16/  637]\n",
      "loss: 0.300227  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.307683 \n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 0.332916  [   16/  637]\n",
      "loss: 0.344699  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.305115 \n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 0.423437  [   16/  637]\n",
      "loss: 0.245719  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.312845 \n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 0.351111  [   16/  637]\n",
      "loss: 0.397922  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.300524 \n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 0.273981  [   16/  637]\n",
      "loss: 0.277922  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.319071 \n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 0.273507  [   16/  637]\n",
      "loss: 0.267449  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.306829 \n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 0.380784  [   16/  637]\n",
      "loss: 0.258943  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.304965 \n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 0.175037  [   16/  637]\n",
      "loss: 0.402475  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.321753 \n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 0.358279  [   16/  637]\n",
      "loss: 0.258996  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.308051 \n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 0.419932  [   16/  637]\n",
      "loss: 0.190983  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.312006 \n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 0.364234  [   16/  637]\n",
      "loss: 0.308086  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.312357 \n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 0.330450  [   16/  637]\n",
      "loss: 0.217863  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.308787 \n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 0.282251  [   16/  637]\n",
      "loss: 0.312350  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.308797 \n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 0.266590  [   16/  637]\n",
      "loss: 0.492648  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.415145 \n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 0.397436  [   16/  637]\n",
      "loss: 0.335646  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.338759 \n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 0.333591  [   16/  637]\n",
      "loss: 0.348429  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.317408 \n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 0.345147  [   16/  637]\n",
      "loss: 0.224780  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.313568 \n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 0.439737  [   16/  637]\n",
      "loss: 0.311583  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.309849 \n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 0.280531  [   16/  637]\n",
      "loss: 0.193145  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.305259 \n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 0.369427  [   16/  637]\n",
      "loss: 0.303378  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.332876 \n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 0.296370  [   16/  637]\n",
      "loss: 0.357149  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.314701 \n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 0.385494  [   16/  637]\n",
      "loss: 0.370098  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.300174 \n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 0.309443  [   16/  637]\n",
      "loss: 0.228188  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.324406 \n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 0.329189  [   16/  637]\n",
      "loss: 0.281824  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.302115 \n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 0.361408  [   16/  637]\n",
      "loss: 0.261077  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.303174 \n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 0.284454  [   16/  637]\n",
      "loss: 0.309127  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.304157 \n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 0.388582  [   16/  637]\n",
      "loss: 0.301419  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.302322 \n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 0.365251  [   16/  637]\n",
      "loss: 0.343448  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.331910 \n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 0.388730  [   16/  637]\n",
      "loss: 0.252245  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.309433 \n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 0.396404  [   16/  637]\n",
      "loss: 0.232851  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.317876 \n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.357992  [   16/  637]\n",
      "loss: 0.342737  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.312752 \n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.321269  [   16/  637]\n",
      "loss: 0.368743  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.313032 \n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 0.330723  [   16/  637]\n",
      "loss: 0.199984  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.308027 \n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 0.277997  [   16/  637]\n",
      "loss: 0.308271  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.315887 \n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 0.332499  [   16/  637]\n",
      "loss: 0.343657  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.311393 \n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.367803  [   16/  637]\n",
      "loss: 0.239852  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.300404 \n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 0.381245  [   16/  637]\n",
      "loss: 0.301521  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.293442 \n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 0.408782  [   16/  637]\n",
      "loss: 0.291898  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.312015 \n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 0.314600  [   16/  637]\n",
      "loss: 0.283185  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.308191 \n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 0.305699  [   16/  637]\n",
      "loss: 0.327864  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.309572 \n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 0.359908  [   16/  637]\n",
      "loss: 0.268669  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.302690 \n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 0.335766  [   16/  637]\n",
      "loss: 0.213601  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.303214 \n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 0.284591  [   16/  637]\n",
      "loss: 0.239949  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.307576 \n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 0.371218  [   16/  637]\n",
      "loss: 0.305550  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.310064 \n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.318304  [   16/  637]\n",
      "loss: 0.252840  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.305442 \n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 0.372671  [   16/  637]\n",
      "loss: 0.239097  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.301338 \n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 0.370726  [   16/  637]\n",
      "loss: 0.244580  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.301796 \n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 0.396217  [   16/  637]\n",
      "loss: 0.246531  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.312889 \n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 0.473967  [   16/  637]\n",
      "loss: 0.324885  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.308555 \n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 0.352240  [   16/  637]\n",
      "loss: 0.360501  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.297232 \n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 0.290340  [   16/  637]\n",
      "loss: 0.351973  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.303533 \n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.380345  [   16/  637]\n",
      "loss: 0.315048  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.306678 \n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 0.298859  [   16/  637]\n",
      "loss: 0.199015  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.298695 \n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 0.279492  [   16/  637]\n",
      "loss: 0.207733  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.311782 \n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 0.322903  [   16/  637]\n",
      "loss: 0.299124  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.306453 \n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 0.437109  [   16/  637]\n",
      "loss: 0.306318  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.305266 \n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 0.264683  [   16/  637]\n",
      "loss: 0.414208  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.302394 \n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 0.302835  [   16/  637]\n",
      "loss: 0.311673  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.310013 \n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 0.358440  [   16/  637]\n",
      "loss: 0.209155  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.325802 \n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 0.316233  [   16/  637]\n",
      "loss: 0.260175  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.307924 \n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 0.224684  [   16/  637]\n",
      "loss: 0.253236  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.310392 \n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 0.297253  [   16/  637]\n",
      "loss: 0.262657  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.302590 \n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 0.223910  [   16/  637]\n",
      "loss: 0.153295  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.329260 \n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.314133  [   16/  637]\n",
      "loss: 0.279857  [  520/  637]\n",
      "Test Error: \n",
      " Avg loss: 0.311476 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "training_losses = []\n",
    "test_losses = []\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    training_losses.append(train(train_dataloader, model, loss_fn, optimizer))\n",
    "    test_losses.append(test(test_dataloader, model, loss_fn))\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1638dabb-7605-4af9-a15c-91bea1f5320c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "  var py_version = '3.3.0'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  var reloading = false;\n",
       "  var Bokeh = root.Bokeh;\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    if (!reloading) {\n",
       "      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n",
       "      require([\"jspanel\"], function(jsPanel) {\n",
       "\twindow.jsPanel = jsPanel\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-modal\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-tooltip\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-hint\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-layout\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-contextmenu\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-dock\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"gridstack\"], function(GridStack) {\n",
       "\twindow.GridStack = GridStack\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"notyf\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      root._bokeh_is_loading = css_urls.length + 9;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    var existing_stylesheets = []\n",
       "    var links = document.getElementsByTagName('link')\n",
       "    for (var i = 0; i < links.length; i++) {\n",
       "      var link = links[i]\n",
       "      if (link.href != null) {\n",
       "\texisting_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      if (existing_stylesheets.indexOf(url) !== -1) {\n",
       "\ton_load()\n",
       "\tcontinue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    var existing_scripts = []\n",
       "    var scripts = document.getElementsByTagName('script')\n",
       "    for (var i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "\texisting_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      var url = js_exports[name];\n",
       "      if (skip.indexOf(url) >= 0 || root[name] != null) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.0.min.js\", \"https://cdn.holoviz.org/panel/1.3.8/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var js_exports = {};\n",
       "  var css_urls = [];\n",
       "  var inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "\ttry {\n",
       "          inline_js[i].call(root, root.Bokeh);\n",
       "\t} catch(e) {\n",
       "\t  if (!reloading) {\n",
       "\t    throw e;\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "\tvar NewBokeh = root.Bokeh;\n",
       "\tif (Bokeh.versions === undefined) {\n",
       "\t  Bokeh.versions = new Map();\n",
       "\t}\n",
       "\tif (NewBokeh.version !== Bokeh.version) {\n",
       "\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "\t}\n",
       "\troot.Bokeh = Bokeh;\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "      if (!reloading && !bokeh_loaded) {\n",
       "\troot.Bokeh = undefined;\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "\trun_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.3.0'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.0.min.js\", \"https://cdn.holoviz.org/panel/1.3.8/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='p1082'>\n",
       "  <div id=\"ee19cbe6-9c09-4cbf-9c7a-689c14b7badb\" data-root-id=\"p1082\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"2397e308-5f5f-48e9-976b-d7a0362e824e\":{\"version\":\"3.3.0\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"p1082\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"p1083\",\"attributes\":{\"plot_id\":\"p1082\",\"comm_id\":\"437579ea3a37440a8f5a87176e3cd3ae\",\"client_comm_id\":\"faec8e2d4cb0435489c9aa405b37f132\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"2397e308-5f5f-48e9-976b-d7a0362e824e\",\"roots\":{\"p1082\":\"ee19cbe6-9c09-4cbf-9c7a-689c14b7badb\"},\"root_ids\":[\"p1082\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "p1082"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"logo-block\">\n",
       "<img src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAYAAACqaXHeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAAB+wAAAfsBxc2miwAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAA6zSURB\n",
       "VHic7ZtpeFRVmsf/5966taWqUlUJ2UioBBJiIBAwCZtog9IOgjqACsogKtqirT2ttt069nQ/zDzt\n",
       "tI4+CrJIREFaFgWhBXpUNhHZQoKBkIUASchWla1S+3ar7r1nPkDaCAnZKoQP/D7mnPOe9/xy76n3\n",
       "nFSAW9ziFoPFNED2LLK5wcyBDObkb8ZkxuaoSYlI6ZcOKq1eWFdedqNzGHQBk9RMEwFAASkk0Xw3\n",
       "ETacDNi2vtvc7L0ROdw0AjoSotQVkKSvHQz/wRO1lScGModBFbDMaNRN1A4tUBCS3lk7BWhQkgpD\n",
       "lG4852/+7DWr1R3uHAZVQDsbh6ZPN7CyxUrCzJMRouusj0ipRwD2uKm0Zn5d2dFwzX1TCGhnmdGo\n",
       "G62Nna+isiUqhkzuKrkQaJlPEv5mFl2fvGg2t/VnzkEV8F5ioioOEWkLG86fvbpthynjdhXYZziQ\n",
       "x1hC9J2NFyi8vCTt91Fh04KGip0AaG9zuCk2wQCVyoNU3Hjezee9bq92duzzTmxsRJoy+jEZZZYo\n",
       "GTKJ6SJngdJqAfRzpze0+jHreUtPc7gpBLQnIYK6BYp/uGhw9YK688eu7v95ysgshcg9qSLMo3JC\n",
       "4jqLKQFBgdKDPoQ+Pltb8dUyQLpeDjeVgI6EgLIQFT5tEl3rn2losHVsexbZ3EyT9wE1uGdkIPcy\n",
       "BGxn8QUq1QrA5nqW5i2tLqvrrM9NK6AdkVIvL9E9bZL/oyfMVd/jqvc8LylzRBKDJSzIExwhQzuL\n",
       "QYGQj4rHfFTc8mUdu3E7yoLtbTe9gI4EqVgVkug2i5+uXGo919ixbRog+3fTbQ8qJe4ZOYNfMoTI\n",
       "OoshUNosgO60AisX15aeI2PSIp5KiFLI9ubb1vV3Qb2ltwLakUCDAkWX7/nHKRmmGIl9VgYsUhJm\n",
       "2NXjKYADtM1ygne9QQDIXlk49FBstMKx66D1v4+XuQr7vqTe0VcBHQlRWiOCbmmSYe2SqtL6q5rJ\n",
       "zsTb7lKx3FKOYC4DoqyS/B5bvLPxvD9Qtf6saxYLQGJErmDOdOMr/zo96km1nElr8bmPOBwI9COv\n",
       "HnFPRIwmkSOv9kcAS4heRsidOkpeWBgZM+UBrTFAXNYL5Vf2ii9c1trNzpYdaoVil3WIc+wdk+gQ\n",
       "noie3ecCcxt9ITcLAPWt/laGEO/9U6PmzZkenTtsSMQ8uYywJVW+grCstAvCIaAdArAsIWkRDDs/\n",
       "KzLm2YcjY1Lv0UdW73HabE9n6V66cxSzfEmuJssTpKGVp+0vHq73FwL46eOjpMpbRAnNmJFrGJNu\n",
       "Ukf9Yrz+3rghiumCKNXXWPhLYcjxGsIpoCMsIRoFITkW8AuyM8jC1+/QLx4bozCEJIq38+1rtpR6\n",
       "V/yzb8eBlRb3fo5l783N0CWolAzJHaVNzkrTzlEp2bQ2q3TC5gn6wpnoQAmwSiGh2GitnTmVMc5O\n",
       "UyfKWUKCIsU7+fZDKwqdT6DDpvkzAX4/+AMFjk0tDp5GRXLpQ2MUmhgDp5gxQT8+Y7hyPsMi8uxF\n",
       "71H0oebujHALECjFKaW9Lm68n18wXp2kVzIcABytD5iXFzg+WVXkegpAsOOYziqo0OkK76GyquC3\n",
       "ltZAzMhhqlSNmmWTE5T6e3IN05ITFLM4GdN0vtZ3ob8Jh1NAKXFbm5PtLU/eqTSlGjkNAJjdgn/N\n",
       "aedXa0tdi7+t9G0FIF49rtMSEgAs1kDLkTPO7ebm4IUWeyh1bKomXqlgMG6kJmHcSM0clYLJ8XtR\n",
       "1GTnbV3F6I5wCGikAb402npp1h1s7LQUZZSMIfALFOuL3UUrfnS8+rez7v9qcold5tilgHbO1fjK\n",
       "9ubb17u9oshxzMiUBKXWqJNxd+fqb0tLVs4lILFnK71H0Ind7uiPgACVcFJlrb0tV6DzxqqTIhUM\n",
       "CwDf1/rrVhTa33/3pGPxJYdQ2l2cbgVcQSosdx8uqnDtbGjh9SlDVSMNWhlnilfqZk42Th2ZpLpf\n",
       "xrHec5e815zrr0dfBZSwzkZfqsv+1FS1KUknUwPARVvItfKUY+cn57yP7qv07UE3p8B2uhUwLk09\n",
       "e0SCOrK+hbdYHYLjRIl71wWzv9jpEoeOHhGRrJAzyEyNiJuUqX0g2sBN5kGK6y2Blp5M3lsB9Qh4\n",
       "y2Ja6x6+i0ucmKgwMATwhSjdUu49tKrQ/pvN5d53ml2CGwCmJipmKjgmyuaXzNeL2a0AkQ01Th5j\n",
       "2DktO3Jyk8f9vcOBQHV94OK+fPumJmvQHxJoWkaKWq9Vs+yUsbq0zGT1I4RgeH2b5wef7+c7bl8F\n",
       "eKgoHVVZa8ZPEORzR6sT1BzDUAD/d9F78e2Tzv99v8D+fLVTqAKAsbGamKey1Mt9Ann4eH3gTXTz\n",
       "idWtAJ8PQWOk7NzSeQn/OTHDuEikVF1R4z8BQCy+6D1aWRfY0tTGG2OM8rRoPaeIj5ZHzJxszElN\n",
       "VM8K8JS5WOfv8mzRnQAKoEhmt8gyPM4lU9SmBK1MCQBnW4KONT86v1hZ1PbwSXPw4JWussVjtH9Y\n",
       "NCoiL9UoH/6PSu8jFrfY2t36erQHXLIEakMi1SydmzB31h3GGXFDFNPaK8Rme9B79Ixrd0WN+1ij\n",
       "NRQ/doRmuFLBkHSTOm5GruG+pFjFdAmorG4IXH1Qua6ASniclfFtDYt+oUjKipPrCQB7QBQ2lrgP\n",
       "fFzm+9XWUtcqJ3/5vDLDpJ79XHZk3u8nGZ42qlj1+ydtbxysCezrydp6ugmipNJ7WBPB5tydY0jP\n",
       "HaVNzs3QzeE4ZpTbI+ZbnSFPbVOw9vsfnVvqWnirPyCNGD08IlqtYkh2hjZ5dErEQzoNm+6ykyOt\n",
       "Lt5/PQEuSRRKo22VkydK+vvS1XEKlhCJAnsqvcVvH7f/ZU2R67eXbMEGAMiIV5oWZWiWvz5Fv2xG\n",
       "sjqNJQRvn3Rs2lji/lNP19VjAQDgD7FHhujZB9OGqYxRkZxixgRDVlqS6uEOFaJUVu0rPFzctrnF\n",
       "JqijImVp8dEKVWyUXDk92zAuMZ6bFwpBU1HrOw6AdhQgUooChb0+ItMbWJitSo5Ws3IAOGEOtL53\n",
       "0vHZih9sC4vtofZ7Qu6523V/fmGcds1TY3V36pUsBwAbSlxnVh2xLfAD/IAIMDf7XYIkNmXfpp2l\n",
       "18rkAJAy9HKFaIr/qULkeQQKy9zf1JgDB2uaeFNGijo5QsUyacNUUTOnGO42xSnv4oOwpDi1zYkc\n",
       "efUc3I5Gk6PhyTuVKaOGyLUAYPGIoY9Pu/atL/L92+4q9wbflRJ2Trpm/jPjdBtfnqB/dIThcl8A\n",
       "KG7hbRuKnb8qsQsVvVlTrwQAQMUlf3kwJI24Z4JhPMtcfng5GcH49GsrxJpGvvHIaeem2ma+KSjQ\n",
       "lIwUdYyCY8j4dE1KzijNnIP2llF2wcXNnsoapw9XxsgYAl6k+KzUXbi2yP3KR2ecf6z3BFsBICdW\n",
       "nvnIaG3eHybqX7vbpEqUMT+9OL4Qpe8VON7dXuFd39v19FoAABRVePbGGuXTszO0P7tu6lghUonE\n",
       "llRdrhArLvmKdh9u29jcFiRRkfLUxBiFNiqSU9icoZQHo5mYBI1MBgBH6wMNb+U7Pnw337H4gi1Y\n",
       "ciWs+uks3Z9fztUvfzxTm9Ne8XXkvQLHNytOOZeiD4e0PgkAIAYCYknKUNUDSXEKzdWNpnil7r4p\n",
       "xqkjTarZMtk/K8TQ6Qve78qqvXurGwIJqcOUKfUWHsm8KGvxSP68YudXq4pcj39X49uOK2X142O0\n",
       "Tz5/u/7TVybqH0rSya6ZBwD21/gubbrgWdDgEOx9WUhfBaC2ibcEBYm7a7x+ukrBMNcEZggyR0TE\n",
       "T8zUPjikQ4VosQZbTpS4vqizBKvqmvjsqnpfzaZyx9JPiz1/bfGKdgD45XB1zoIMzYbfTdS/NClB\n",
       "Gct0USiY3YL/g0LHy/uq/Ef6uo5+n0R/vyhp17Klpge763f8rMu6YU/zrn2nml+2WtH+Z+5IAAFc\n",
       "2bUTdTDOSNa9+cQY7YLsOIXhevEkCvzph7a8laecz/Un/z4/Ae04XeL3UQb57IwU9ZDr9UuKVajv\n",
       "nxp1+1UVIo/LjztZkKH59fO3G/JemqCfmaCRqbqbd90ZZ8FfjtkfAyD0J/9+C2h1hDwsSxvGjNDc\n",
       "b4zk5NfrSwiQblLHzZhg+Jf4aPlUwpDqkQqa9nimbt1/TDH8OitGMaQnj+RJS6B1fbF7SY1TqO5v\n",
       "/v0WAADl1f7zokgS7s7VT2DZ7pegUjBM7mjtiDZbcN4j0YrHH0rXpCtY0qPX0cVL0rv5jv/ZXend\n",
       "0u/EESYBAFBU4T4Qa5TflZOhTe7pmKpaP8kCVUVw1+yhXfJWvn1P3hnXi33JsTN6PnP3hHZ8Z3/h\n",
       "aLHzmkNPuPj7Bc/F/Q38CwjTpSwQXgE4Vmwry9tpfq/ZFgqFMy4AVDtCvi8rvMvOmv0N4YwbVgEA\n",
       "sPM72/KVnzfspmH7HQGCRLG2yL1+z8XwvPcdCbsAANh+xPzstgMtxeGKt+6MK3/tacfvwhWvIwMi\n",
       "oKEBtm0H7W+UVfkc/Y1V0BhoPlDr/w1w/eu1vjIgAgDg22OtX6/eYfnEz/focrZTHAFR+PSs56/7\n",
       "q32nwpjazxgwAQCwcU/T62t3WL7r6/jVRa6/byp1rei+Z98ZUAEAhEPHPc8fKnTU9nbgtnOe8h0l\n",
       "9hcGIqmODLQAHCy2Xti6v/XNRivf43f4fFvIteu854+VHnR7q9tfBlwAAGz+pnndB9vM26UebAe8\n",
       "SLHujPOTPVW+rwY+sxskAAC2HrA8t2Vvc7ffP1r9o+vwR2dcr92InIAbKKC1FZ5tB1tf+/G8p8sv\n",
       "N/9Q5zd/XR34LYCwV5JdccMEAMDBk45DH243r/X4xGvqxFa/GNpS7n6rwOwNWwHVE26oAADYurf1\n",
       "zx/utOzt+DMKYM0p17YtZZ5VNzqfsB2HewG1WXE8PoZ7gOclbTIvynZf9JV+fqZtfgs/8F/Nu5rB\n",
       "EIBmJ+8QRMmpU7EzGRsf2FzuePqYRbzh/zE26EwdrT10f6r6o8HOYzCJB9Dpff8tbnGLG8L/A/WE\n",
       "roTBs2RqAAAAAElFTkSuQmCC'\n",
       "     style='height:25px; border-radius:12px; display: inline-block; float: left; vertical-align: middle'></img>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <img src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAAFMAAABTABZarKtgAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAArNSURB\n",
       "VFiFnVd5VFNXGv/ee0kgGyQhbFoXIKCFYEXEDVErTucMoKUOWA/VLsNSLPQgFTOdyrHPiIp1lFIQ\n",
       "OlaPShEG3EpPcQmISCuV1bQ1CLKIULeQhJA9JO+9+UMT0x5aPfOdc895373f/e7v/t537/ddBF5Q\n",
       "JBIJl81mJwCACEVRQBCEQhAEAQCgnghCURRCkmS7Wq2+WlJSYn0Rv8jzDHAcD0EQJIVGo5mFQuGF\n",
       "jIyMu39kq1KpkOrq6gU6nS6aIAiGzWY7VVBQ0P9/AcjNzWXy+fxcOp2uiY+Przm0d6+n8dblv/Fo\n",
       "kzM4SzYfPlRePvFnjnt6ehh1dXVv2mw2nlar/byoqMj8wgBwHBchCJIZEhJSeu1yHVi7vtu02t8+\n",
       "NykQ7BMWoOUMhXQsXLv5IQAwSJJEEASxcDicoeTk5DtCoZBy9XX69Gnv3t7ebJIky3EcH3guAKlU\n",
       "GoGiaOKWLVsOvhs7/9XXPMde3/IyIFbMnaPDuD5AUdQuOf2XlD0npTExMWYAgNbWVpZcLg8xGAzB\n",
       "JEnSvby82tPT052LaTQatLy8fBtJkt/s3Lnz5h8CwHFcRKPRNu/YsePAjh072KTs0IGCxRg8RgUB\n",
       "TGpSx6cmHgMAfNqN6Xa1GvJ/D35gYAAViURkcXHxUrPZHDRv3rxv4uLiDI7xPXv2bLdYLBUFBQWD\n",
       "jj7M8ZGbm8tkMpmSrKysQiaTScXGxtpqL7dManT6tcu5mgEWWJyOhicozpk+c3NsbKzNFcBbWWEf\n",
       "1Td9/upA30i3ZJv0h8bGxiSFQmFcuHDhOACAWCy+0d3dvX3lypUtzc3N9t8AiIuLk4SEhByLiooy\n",
       "AgAcO3ZsNlPgH3Cttb35JZo+bCYXIQAA9MDiUW7sWS1KN687w6Mera2twa2trfMvXboUOS28Pyb1\n",
       "U08McRtf/sXBSmt5cc35pqamVQqFwhoZGallMpnU/fv3e7RaberVq1d/AABAn1IfQqfTNRs3blQB\n",
       "AFy+fJk7Nja2XCKRnD3dNSorusPq6NfTPR+gPiEEoLRFXO1tS2+zavv27ReftjNttyr0S1/j0rUP\n",
       "PEJQwNwQYGgAACQSyXmNRhMtk8lYAAApKSlKDMP0+fn5QU4ACIKkxMfH1zjYuHnz5uspKSlOfdX7\n",
       "u68fvOePcCzKQR4YVCgATGfa/F3pnzaHWOAXSDyaMCqH2+r8VXErP3D+snXr1tV2dXW94dATExOr\n",
       "6XT6JgAAVCKRcDEMM4WHh9sAAHJyUqNu//wDymKx7AAAVVVVPiaTKXxByrYMvBsxEMSTwPXhuL+8\n",
       "e/fu9fv371+flvbemogYNz+TnsBOFEwMFO8/KzEYDKFVVVX+AAChoaGT7u7ud48ePRro0DEMs+bl\n",
       "5bFRNpud4O3tfdGBzq5uy/5wTUPM/q2zC9atmbVqeHg4Pi0t7WxGRoZFH5rw76I7LI8HqHfwPL7d\n",
       "rfVagzw1NfW81t4ePUfsP/OrnWZ6fPSuUqFQSEkkkrOjo6OvuQR5q0ajiXLoPj4+lzgcTjwKACLH\n",
       "9SqXy2kzhBO8haGo+UA2wZW+p880DxeveGt9aHx9fT09ctlq3sC0NT9e6xsbjuZblSxl7wKtVotM\n",
       "m6PnXvlmZJBtX91CEMQsxyJsNlteXl4udugIghAajQYFAEhPTx9AEGQOimGY8y4oLt63KlJkdB4t\n",
       "P282Z/c/dPrDH04ktJ9P2tfWXP3+2o1vHzunEp6Xq0lsGt08KzUrcSGTQ3n3XeefLCs5UqnT6Rap\n",
       "VCoEACA7O/snvV4f5gJooLa2NsihoygKKEVRzquTND2OCpttGXdG1tOxwOlgzdvE9v30rV+m3W5I\n",
       "2jfJNQmLH85QUUzPNTwvkAx0+vVGhq2/VV9fT+dyuZ01NTXOXQOA3fGxevXq2waDYY5r8KIoij5b\n",
       "jzB5Cz2oKdOo0erOm+1tVuVtBMZXElNMRJR1fvvjx9iPLQ/RjpuB0Xu/Vp7YmH1864YNG3oNBkPw\n",
       "VD7mzp1rJUnSzZUBmqsBggAgGFC/n6jVA+3WoN3tu1Gg39cg2tEx1Cg3CIJHsclxnl2HRorMN8Z0\n",
       "fRW+vr7GJ36Q56Z5h9BIknzGAMJWtvdQYs0EZe3/FSwqk5tpXEMb1JoYD+n8xRdQJl/fMPEgzKhS\n",
       "L40KCD7lGzg92qIyovpb3y/msT2un2psvFpWVvYyl8vtc1nDSXFXV5c7iqLOtEyS5LNBAADfWeKm\n",
       "Ly4uuvR1++sfv51/P5sfnHm2/Iy+mBmwsaHJbpt+Q0jHSS7TZ/PSNVkNJ/973OxtemD1s91CPb12\n",
       "h9MfvZsk5meo1eqo5ORkxTNWn7HR1tY2l8PhOAsUiqIolCRJcETtv/61qzNySYK5trZ2TCgUUiwW\n",
       "S1FSUhLR+bA/kAzwXcAbHa/cFhrTXrJ/v+7IkSPu3Je4Xm5eboJv2wba5QbO5fQwxhsP679Y+nFO\n",
       "jgAAoKSkJILFYjnBGI1G0YYNGwYBnqRoiqIQlKKojurq6gUAAAKBgKQoiuGYkJWVpTCZTOKmI1Xd\n",
       "HwnDcm+cOnOMw+H0FxYWbqpvqv/r9EV+bky+O+/QoUPiqJRt9JphTLFHbKBCR87tWL9EPN9oNIZn\n",
       "ZWUpXHaMCQQCEgCgsrIyEgBuoGq1+qpOp4t2GPH5/BvFxcVLHXpgYGDD8ePH/56Xl2cCAMjMzOxP\n",
       "S0s7pWfow4RCbz/fAF9RT0+P9yeffHJySSqev+9nxLD1FaAlTR8vlJ8vxxzsFhUVLRMIBB0OvwaD\n",
       "YRlFUdfQkpISK0EQ9J6eHgYAQEZGxl2z2Rw0MjJCBwBITk5+xOVyfzpw4ECSw5lQKKQIbxtJm4EN\n",
       "8eZ7jPz0oNv+dK5FG/jq54eH+IFr/S1KabBy0UerAvI+++wzD4vFEpCWljYEACCTyVh2ux3FcXwS\n",
       "BQCw2WxVdXV1bzrQRURE1FVVVTn1zMzM/pkzZ35/9OjRd0pLS19RqVQIy4/tCwDgOcPTQvFQEQBA\n",
       "aWnpK0ERK2LbyVllN341GUJ4YDu8zD5bKyur7O+85tx9Z2fnO1ar9QjA04KkpaVFs2LFir8olcq7\n",
       "YWFhJpFINNnX16drbGyMjY6Ovg0AIBaLjcuXL5d3d3d7XbhwIW704b3F479MeD1qVfJ5Og/bvb4R\n",
       "LwaDMZabm9uwflNa/z/3HOIv5NsDEK7XS7FeevXPvYNLvm5S/GglCK5KpZorlUobXE8g5ObmMqVS\n",
       "6UG1Wu1BURSHoijOiRMnwgoLC7coFAqBo+9Fm0KhEKStmvvto3TeucFN7pVJYbytarXaQyqVHsRx\n",
       "3N15TF1BuBaljr4rV66wOzo63mAymXdzcnKuwwtIUVHRMqvVGkgQxMV7NXvyJijGvcNXB/7z5Zdf\n",
       "bicI4gSO40NTAgD4bVnuODIAT2pElUq1FEEQO4fD6QsPD++fqixHEATj8/ntjoCrqKhwS0hIsJWV\n",
       "leURBHEOx3G563pT3tn5+flBDAbjg6CgoMMpKSlK17GhoSFMJpMFPk04DJIkEQzDzCwW6+5UD5Oa\n",
       "mhrfO3fufECS5GHXnf8pAAAAHMfdURTdimGYPjExsTo0NHTyj2ynEplMxurs7HyHIAiKJMlSHMct\n",
       "U9k9N2vl5+cH0en0TRiGWX18fC65vnh+LxqNBq2oqFhgMpmi7XY7arVaj+zdu/fxn/l/4bSZl5fH\n",
       "5nK5CQAQMtXznCRJePpEbwOAZhzHX4ix/wHzzC/tu64gcwAAAABJRU5ErkJggg=='\n",
       "       style='height:15px; border-radius:12px; display: inline-block; float: left'></img>\n",
       "  \n",
       "\n",
       "\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hv.extension('matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f1a82a9-fe27-4321-a6a2-8248880c93f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='data:image/png;base64,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' style='max-width:100%; margin: auto; display: block; '/>"
      ],
      "text/plain": [
       ":NdOverlay   [Default]\n",
       "   :Curve   [x]   (y)"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {}
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hv.HoloMap(\n",
    "    {\n",
    "        'training': hv.Curve(training_losses),\n",
    "        'test': hv.Curve(test_losses)\n",
    "    }\n",
    ").overlay(\n",
    "    \n",
    ").opts(\n",
    "    ylabel='MAE',\n",
    "    xlabel='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e34c95-1ee1-4955-b8e7-36cdcb7057c3",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09cd2d41-97c3-494b-ade0-f8a878c10aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_imputer, fit_scaler = False, False\n",
    "\n",
    "# Extract just the feature data\n",
    "col_array = np.array(train_df.columns)\n",
    "X = train_df[col_array[~np.isin(col_array, ['Drug_ID', 'Drug', 'Y'])]].values\n",
    "\n",
    "# Impute missing data\n",
    "if imputer is not None:\n",
    "    if fit_imputer:\n",
    "        X = imputer.fit_transform(X)\n",
    "    else:\n",
    "        X = imputer.transform(X)\n",
    "\n",
    "# Scale the feature data\n",
    "if scaler is not None:\n",
    "    if fit_scaler:\n",
    "        X = scaler.fit_transform(X)\n",
    "    else:\n",
    "        X = scaler.transform(X)\n",
    "\n",
    "# Create features tensor\n",
    "features = torch.tensor(X).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e69da00-99e5-46cd-a4ba-f22350d25ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['Y'].values.reshape(-1, 1)\n",
    "target = torch.tensor(y).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4768c103-bd80-430a-ac5e-7428bd086959",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.forward(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e846695e-53b1-406b-a2d4-4076118a898b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1979, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE = torch.nn.L1Loss()\n",
    "MAE(pred, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ce7525e-d39b-473d-91bf-fca34b1c26a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_imputer, fit_scaler = False, False\n",
    "\n",
    "# Extract just the feature data\n",
    "col_array = np.array(val_df.columns)\n",
    "X = val_df[col_array[~np.isin(col_array, ['Drug_ID', 'Drug', 'Y'])]].values\n",
    "\n",
    "# Impute missing data\n",
    "if imputer is not None:\n",
    "    if fit_imputer:\n",
    "        X = imputer.fit_transform(X)\n",
    "    else:\n",
    "        X = imputer.transform(X)\n",
    "\n",
    "# Scale the feature data\n",
    "if scaler is not None:\n",
    "    if fit_scaler:\n",
    "        X = scaler.fit_transform(X)\n",
    "    else:\n",
    "        X = scaler.transform(X)\n",
    "\n",
    "# Create features tensor\n",
    "features = torch.tensor(X).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99ad6502-366a-4915-9337-be04caca57b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = val_df['Y'].values.reshape(-1, 1)\n",
    "target = torch.tensor(y).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eeb5159e-a8f2-403e-903b-d3f80d831291",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.forward(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2307bd91-14e6-4263-a68a-ae732422b8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3359, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE = torch.nn.L1Loss()\n",
    "MAE(pred, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c63a56d1-2392-47a4-aafd-487d0df821c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_imputer, fit_scaler = False, False\n",
    "\n",
    "# Extract just the feature data\n",
    "col_array = np.array(test_df.columns)\n",
    "X = test_df[col_array[~np.isin(col_array, ['Drug_ID', 'Drug', 'Y'])]].values\n",
    "\n",
    "# Impute missing data\n",
    "if imputer is not None:\n",
    "    if fit_imputer:\n",
    "        X = imputer.fit_transform(X)\n",
    "    else:\n",
    "        X = imputer.transform(X)\n",
    "\n",
    "# Scale the feature data\n",
    "if scaler is not None:\n",
    "    if fit_scaler:\n",
    "        X = scaler.fit_transform(X)\n",
    "    else:\n",
    "        X = scaler.transform(X)\n",
    "\n",
    "# Create features tensor\n",
    "features = torch.tensor(X).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e256233-3f79-4eb2-b9ac-f1730d8cda89",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = test_df['Y'].values.reshape(-1, 1)\n",
    "target = torch.tensor(y).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1675e06a-1074-4a09-9bf5-7f9f4c84c653",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.forward(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b66358a7-38bf-4433-b47b-dd475a861637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3128, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE = torch.nn.L1Loss()\n",
    "MAE(pred, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7b3394-bb98-409f-8d78-82f470236953",
   "metadata": {},
   "source": [
    "### Leaderboard benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "efd17b56-61f0-4843-a6e9-edfe08a2264d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    }
   ],
   "source": [
    "from tdc.benchmark_group import admet_group\n",
    "group = admet_group(path = 'data/')\n",
    "benchmark = group.get('Caco2_Wang') \n",
    "# all benchmark names in a benchmark group are stored in group.dataset_names\n",
    "name = benchmark['name']\n",
    "train_data, test_data = benchmark['train_val'], benchmark['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c7eb07f-cb44-4a2e-838a-13471315e0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "728it [00:29, 24.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# make training dataloader\n",
    "train_dataloader, imputer, scaler = construct_dataloader(add_descriptor_columns(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f37acea-fc72-426e-a022-8e72612a5768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "182it [00:05, 32.98it/s]\n"
     ]
    }
   ],
   "source": [
    "# make test data into correct format\n",
    "fit_imputer, fit_scaler = False, False\n",
    "\n",
    "test_data = add_descriptor_columns(test_data)\n",
    "\n",
    "# Extract just the feature data\n",
    "col_array = np.array(test_data.columns)\n",
    "X_test = test_data[col_array[~np.isin(col_array, ['Drug_ID', 'Drug', 'Y'])]].values\n",
    "\n",
    "# Impute missing data\n",
    "if imputer is not None:\n",
    "    if fit_imputer:\n",
    "        X_test = imputer.fit_transform(X_test)\n",
    "    else:\n",
    "        X_test = imputer.transform(X_test)\n",
    "\n",
    "# Scale the feature data\n",
    "if scaler is not None:\n",
    "    if fit_scaler:\n",
    "        X_test = scaler.fit_transform(X_test)\n",
    "    else:\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create features tensor\n",
    "features_test = torch.tensor(X_test).to(torch.float32)\n",
    "\n",
    "# Create target tensor\n",
    "y_test = test_data['Y'].values.reshape(-1, 1)\n",
    "target = torch.tensor(y_test).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d87af82d-b005-4e38-a291-21b2f6b9656e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1:\n",
      "-------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 5.217315  [   16/  728]\n",
      "loss: 5.690672  [  368/  728]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 5.057850  [   16/  728]\n",
      "loss: 5.377912  [  368/  728]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 4.896375  [   16/  728]\n",
      "loss: 172.008224  [  368/  728]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 4.544419  [   16/  728]\n",
      "loss: 3.576785  [  368/  728]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 3.555260  [   16/  728]\n",
      "loss: 2.195665  [  368/  728]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.984303  [   16/  728]\n",
      "loss: 1.757985  [  368/  728]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.370661  [   16/  728]\n",
      "loss: 1.705336  [  368/  728]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.877199  [   16/  728]\n",
      "loss: 1.966394  [  368/  728]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.864912  [   16/  728]\n",
      "loss: 2.525105  [  368/  728]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.895245  [   16/  728]\n",
      "loss: 1.946384  [  368/  728]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.169490  [   16/  728]\n",
      "loss: 1.935887  [  368/  728]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.055200  [   16/  728]\n",
      "loss: 1.310996  [  368/  728]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.092487  [   16/  728]\n",
      "loss: 2.318545  [  368/  728]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.323447  [   16/  728]\n",
      "loss: 1.539033  [  368/  728]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.174743  [   16/  728]\n",
      "loss: 1.856585  [  368/  728]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.205799  [   16/  728]\n",
      "loss: 1.887673  [  368/  728]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.338882  [   16/  728]\n",
      "loss: 1.347894  [  368/  728]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.152571  [   16/  728]\n",
      "loss: 1.567367  [  368/  728]\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.690372  [   16/  728]\n",
      "loss: 1.979086  [  368/  728]\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.609036  [   16/  728]\n",
      "loss: 1.764616  [  368/  728]\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.893480  [   16/  728]\n",
      "loss: 1.611442  [  368/  728]\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1.015886  [   16/  728]\n",
      "loss: 10.520844  [  368/  728]\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1.154426  [   16/  728]\n",
      "loss: 1.934718  [  368/  728]\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1.233749  [   16/  728]\n",
      "loss: 276.699860  [  368/  728]\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1.333783  [   16/  728]\n",
      "loss: 1.049303  [  368/  728]\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.872447  [   16/  728]\n",
      "loss: 1.972972  [  368/  728]\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 1.116844  [   16/  728]\n",
      "loss: 2.334116  [  368/  728]\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.826629  [   16/  728]\n",
      "loss: 1.693419  [  368/  728]\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.893927  [   16/  728]\n",
      "loss: 1.970490  [  368/  728]\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 1.117567  [   16/  728]\n",
      "loss: 1.980527  [  368/  728]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 1.078705  [   16/  728]\n",
      "loss: 1.639053  [  368/  728]\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.850209  [   16/  728]\n",
      "loss: 1.913540  [  368/  728]\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 1.307987  [   16/  728]\n",
      "loss: 5.280814  [  368/  728]\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.644433  [   16/  728]\n",
      "loss: 1.140639  [  368/  728]\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.946764  [   16/  728]\n",
      "loss: 1.234242  [  368/  728]\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.917262  [   16/  728]\n",
      "loss: 1.436396  [  368/  728]\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 1.266515  [   16/  728]\n",
      "loss: 1.436571  [  368/  728]\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 1.043427  [   16/  728]\n",
      "loss: 1.622786  [  368/  728]\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.896094  [   16/  728]\n",
      "loss: 1.370562  [  368/  728]\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 1.171250  [   16/  728]\n",
      "loss: 1.526693  [  368/  728]\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 1.318071  [   16/  728]\n",
      "loss: 1.840756  [  368/  728]\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 1.069733  [   16/  728]\n",
      "loss: 0.949083  [  368/  728]\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.883906  [   16/  728]\n",
      "loss: 1.273525  [  368/  728]\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.951648  [   16/  728]\n",
      "loss: 1.958073  [  368/  728]\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.872853  [   16/  728]\n",
      "loss: 0.966523  [  368/  728]\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 1.078124  [   16/  728]\n",
      "loss: 1.474143  [  368/  728]\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.645617  [   16/  728]\n",
      "loss: 1.396137  [  368/  728]\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.926785  [   16/  728]\n",
      "loss: 1.341069  [  368/  728]\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.975805  [   16/  728]\n",
      "loss: 1.573253  [  368/  728]\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.864813  [   16/  728]\n",
      "loss: 1.114198  [  368/  728]\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 1.042110  [   16/  728]\n",
      "loss: 0.977149  [  368/  728]\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 1.160643  [   16/  728]\n",
      "loss: 1.177057  [  368/  728]\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.942821  [   16/  728]\n",
      "loss: 1.455812  [  368/  728]\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.662193  [   16/  728]\n",
      "loss: 1.293835  [  368/  728]\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.948259  [   16/  728]\n",
      "loss: 1.195755  [  368/  728]\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.661338  [   16/  728]\n",
      "loss: 1.180398  [  368/  728]\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.974738  [   16/  728]\n",
      "loss: 1.896533  [  368/  728]\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 1.079624  [   16/  728]\n",
      "loss: 1.195701  [  368/  728]\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.914364  [   16/  728]\n",
      "loss: 1.430975  [  368/  728]\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.882276  [   16/  728]\n",
      "loss: 1.696756  [  368/  728]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 1.194077  [   16/  728]\n",
      "loss: 1.254912  [  368/  728]\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.728130  [   16/  728]\n",
      "loss: 1.059247  [  368/  728]\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 1.016147  [   16/  728]\n",
      "loss: 1.109752  [  368/  728]\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.735978  [   16/  728]\n",
      "loss: 1.594652  [  368/  728]\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 1.011193  [   16/  728]\n",
      "loss: 1.136458  [  368/  728]\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.740213  [   16/  728]\n",
      "loss: 1.280973  [  368/  728]\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.737562  [   16/  728]\n",
      "loss: 1.432493  [  368/  728]\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.759238  [   16/  728]\n",
      "loss: 1.239615  [  368/  728]\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.579381  [   16/  728]\n",
      "loss: 1.535335  [  368/  728]\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.912086  [   16/  728]\n",
      "loss: 1.639395  [  368/  728]\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.654411  [   16/  728]\n",
      "loss: 0.917128  [  368/  728]\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.635891  [   16/  728]\n",
      "loss: 1.221208  [  368/  728]\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.768632  [   16/  728]\n",
      "loss: 1.000479  [  368/  728]\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.758180  [   16/  728]\n",
      "loss: 102.101723  [  368/  728]\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.600396  [   16/  728]\n",
      "loss: 1.061015  [  368/  728]\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.846122  [   16/  728]\n",
      "loss: 1.177374  [  368/  728]\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.692018  [   16/  728]\n",
      "loss: 1.314906  [  368/  728]\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.800308  [   16/  728]\n",
      "loss: 0.963025  [  368/  728]\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.842031  [   16/  728]\n",
      "loss: 1.090990  [  368/  728]\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.573478  [   16/  728]\n",
      "loss: 0.770427  [  368/  728]\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.599020  [   16/  728]\n",
      "loss: 1.288825  [  368/  728]\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.566510  [   16/  728]\n",
      "loss: 0.825923  [  368/  728]\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.762690  [   16/  728]\n",
      "loss: 0.986686  [  368/  728]\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.836717  [   16/  728]\n",
      "loss: 0.801002  [  368/  728]\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.697676  [   16/  728]\n",
      "loss: 0.558348  [  368/  728]\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.484501  [   16/  728]\n",
      "loss: 1.057428  [  368/  728]\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.512740  [   16/  728]\n",
      "loss: 1.110026  [  368/  728]\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.636049  [   16/  728]\n",
      "loss: 0.856690  [  368/  728]\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.593911  [   16/  728]\n",
      "loss: 0.778708  [  368/  728]\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.744040  [   16/  728]\n",
      "loss: 0.899755  [  368/  728]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.733523  [   16/  728]\n",
      "loss: 0.828373  [  368/  728]\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.692676  [   16/  728]\n",
      "loss: 0.696530  [  368/  728]\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.703825  [   16/  728]\n",
      "loss: 1.017916  [  368/  728]\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.449324  [   16/  728]\n",
      "loss: 0.984331  [  368/  728]\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.608802  [   16/  728]\n",
      "loss: 0.971014  [  368/  728]\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.562107  [   16/  728]\n",
      "loss: 0.916373  [  368/  728]\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.636206  [   16/  728]\n",
      "loss: 1.037754  [  368/  728]\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.514763  [   16/  728]\n",
      "loss: 0.682310  [  368/  728]\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.401084  [   16/  728]\n",
      "loss: 1.170409  [  368/  728]\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.570810  [   16/  728]\n",
      "loss: 1.107970  [  368/  728]\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.586022  [   16/  728]\n",
      "loss: 1.117891  [  368/  728]\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.491648  [   16/  728]\n",
      "loss: 1.496903  [  368/  728]\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.384074  [   16/  728]\n",
      "loss: 0.528741  [  368/  728]\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.481775  [   16/  728]\n",
      "loss: 0.684635  [  368/  728]\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.353159  [   16/  728]\n",
      "loss: 0.926650  [  368/  728]\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.675245  [   16/  728]\n",
      "loss: 0.813830  [  368/  728]\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.471398  [   16/  728]\n",
      "loss: 0.723562  [  368/  728]\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.510702  [   16/  728]\n",
      "loss: 0.927418  [  368/  728]\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.505977  [   16/  728]\n",
      "loss: 0.557224  [  368/  728]\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.447952  [   16/  728]\n",
      "loss: 0.982831  [  368/  728]\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.416607  [   16/  728]\n",
      "loss: 0.592115  [  368/  728]\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.427118  [   16/  728]\n",
      "loss: 0.704253  [  368/  728]\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.347890  [   16/  728]\n",
      "loss: 0.938708  [  368/  728]\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.388917  [   16/  728]\n",
      "loss: 0.546824  [  368/  728]\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.500299  [   16/  728]\n",
      "loss: 0.937531  [  368/  728]\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.434865  [   16/  728]\n",
      "loss: 0.882056  [  368/  728]\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.369517  [   16/  728]\n",
      "loss: 0.829405  [  368/  728]\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.579767  [   16/  728]\n",
      "loss: 0.638092  [  368/  728]\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.478977  [   16/  728]\n",
      "loss: 0.583702  [  368/  728]\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.363634  [   16/  728]\n",
      "loss: 1.012141  [  368/  728]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.406219  [   16/  728]\n",
      "loss: 0.636578  [  368/  728]\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.418119  [   16/  728]\n",
      "loss: 0.710409  [  368/  728]\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.365839  [   16/  728]\n",
      "loss: 0.784626  [  368/  728]\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.408443  [   16/  728]\n",
      "loss: 0.668573  [  368/  728]\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.388666  [   16/  728]\n",
      "loss: 0.764383  [  368/  728]\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.382382  [   16/  728]\n",
      "loss: 0.617149  [  368/  728]\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.523442  [   16/  728]\n",
      "loss: 0.789298  [  368/  728]\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.476394  [   16/  728]\n",
      "loss: 0.921648  [  368/  728]\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.343447  [   16/  728]\n",
      "loss: 0.872361  [  368/  728]\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.389031  [   16/  728]\n",
      "loss: 0.906355  [  368/  728]\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.439861  [   16/  728]\n",
      "loss: 0.838775  [  368/  728]\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.319069  [   16/  728]\n",
      "loss: 0.634670  [  368/  728]\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.432056  [   16/  728]\n",
      "loss: 0.565449  [  368/  728]\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.421091  [   16/  728]\n",
      "loss: 0.891898  [  368/  728]\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.461093  [   16/  728]\n",
      "loss: 0.554827  [  368/  728]\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.411972  [   16/  728]\n",
      "loss: 0.559398  [  368/  728]\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.402033  [   16/  728]\n",
      "loss: 0.743583  [  368/  728]\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.286757  [   16/  728]\n",
      "loss: 0.534911  [  368/  728]\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.272641  [   16/  728]\n",
      "loss: 0.945263  [  368/  728]\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.257122  [   16/  728]\n",
      "loss: 0.658292  [  368/  728]\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.414624  [   16/  728]\n",
      "loss: 0.666766  [  368/  728]\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.375672  [   16/  728]\n",
      "loss: 0.786084  [  368/  728]\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.346917  [   16/  728]\n",
      "loss: 0.594610  [  368/  728]\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.595237  [   16/  728]\n",
      "loss: 0.427249  [  368/  728]\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.347707  [   16/  728]\n",
      "loss: 0.531810  [  368/  728]\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.358264  [   16/  728]\n",
      "loss: 0.548045  [  368/  728]\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.311631  [   16/  728]\n",
      "loss: 0.535274  [  368/  728]\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.426937  [   16/  728]\n",
      "loss: 0.675578  [  368/  728]\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.332587  [   16/  728]\n",
      "loss: 0.462705  [  368/  728]\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.336089  [   16/  728]\n",
      "loss: 0.703561  [  368/  728]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.295603  [   16/  728]\n",
      "loss: 0.689987  [  368/  728]\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.304986  [   16/  728]\n",
      "loss: 0.670893  [  368/  728]\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.375085  [   16/  728]\n",
      "loss: 0.626816  [  368/  728]\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.363130  [   16/  728]\n",
      "loss: 0.634706  [  368/  728]\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.310865  [   16/  728]\n",
      "loss: 0.668863  [  368/  728]\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.377499  [   16/  728]\n",
      "loss: 0.533162  [  368/  728]\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.403391  [   16/  728]\n",
      "loss: 0.658625  [  368/  728]\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.275566  [   16/  728]\n",
      "loss: 0.387658  [  368/  728]\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.282996  [   16/  728]\n",
      "loss: 0.574330  [  368/  728]\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.235600  [   16/  728]\n",
      "loss: 0.450454  [  368/  728]\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.303043  [   16/  728]\n",
      "loss: 0.546105  [  368/  728]\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.308193  [   16/  728]\n",
      "loss: 0.504934  [  368/  728]\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.248466  [   16/  728]\n",
      "loss: 0.860772  [  368/  728]\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.235387  [   16/  728]\n",
      "loss: 0.361638  [  368/  728]\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.297139  [   16/  728]\n",
      "loss: 0.643670  [  368/  728]\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.282152  [   16/  728]\n",
      "loss: 0.430609  [  368/  728]\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.276847  [   16/  728]\n",
      "loss: 0.580941  [  368/  728]\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.331288  [   16/  728]\n",
      "loss: 0.622194  [  368/  728]\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.221624  [   16/  728]\n",
      "loss: 0.597225  [  368/  728]\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.299942  [   16/  728]\n",
      "loss: 0.464782  [  368/  728]\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.264427  [   16/  728]\n",
      "loss: 0.586008  [  368/  728]\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.221544  [   16/  728]\n",
      "loss: 0.464340  [  368/  728]\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.245756  [   16/  728]\n",
      "loss: 0.757755  [  368/  728]\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.260626  [   16/  728]\n",
      "loss: 0.488065  [  368/  728]\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.307239  [   16/  728]\n",
      "loss: 0.391009  [  368/  728]\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.261764  [   16/  728]\n",
      "loss: 0.547821  [  368/  728]\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.209670  [   16/  728]\n",
      "loss: 0.687951  [  368/  728]\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.182850  [   16/  728]\n",
      "loss: 0.306959  [  368/  728]\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.406592  [   16/  728]\n",
      "loss: 0.593418  [  368/  728]\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.224993  [   16/  728]\n",
      "loss: 0.479596  [  368/  728]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.282009  [   16/  728]\n",
      "loss: 0.445891  [  368/  728]\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.189504  [   16/  728]\n",
      "loss: 5.830806  [  368/  728]\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.274748  [   16/  728]\n",
      "loss: 0.391724  [  368/  728]\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.292292  [   16/  728]\n",
      "loss: 0.522745  [  368/  728]\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.296870  [   16/  728]\n",
      "loss: 0.238890  [  368/  728]\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.268967  [   16/  728]\n",
      "loss: 0.444481  [  368/  728]\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.247171  [   16/  728]\n",
      "loss: 0.530055  [  368/  728]\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.173387  [   16/  728]\n",
      "loss: 0.391111  [  368/  728]\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.253183  [   16/  728]\n",
      "loss: 0.351701  [  368/  728]\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.222041  [   16/  728]\n",
      "loss: 0.729538  [  368/  728]\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.199633  [   16/  728]\n",
      "loss: 0.315849  [  368/  728]\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.290283  [   16/  728]\n",
      "loss: 0.533823  [  368/  728]\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.177588  [   16/  728]\n",
      "loss: 0.455959  [  368/  728]\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.281899  [   16/  728]\n",
      "loss: 0.679878  [  368/  728]\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.221959  [   16/  728]\n",
      "loss: 0.331262  [  368/  728]\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.276688  [   16/  728]\n",
      "loss: 0.476092  [  368/  728]\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.248976  [   16/  728]\n",
      "loss: 0.483496  [  368/  728]\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.331747  [   16/  728]\n",
      "loss: 0.350463  [  368/  728]\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.331271  [   16/  728]\n",
      "loss: 0.393288  [  368/  728]\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.315780  [   16/  728]\n",
      "loss: 0.415271  [  368/  728]\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.222292  [   16/  728]\n",
      "loss: 0.490911  [  368/  728]\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.300372  [   16/  728]\n",
      "loss: 0.368241  [  368/  728]\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.252929  [   16/  728]\n",
      "loss: 0.477768  [  368/  728]\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.184258  [   16/  728]\n",
      "loss: 0.586239  [  368/  728]\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.307291  [   16/  728]\n",
      "loss: 0.416089  [  368/  728]\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.213033  [   16/  728]\n",
      "loss: 0.513864  [  368/  728]\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.341288  [   16/  728]\n",
      "loss: 0.452999  [  368/  728]\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.231845  [   16/  728]\n",
      "loss: 0.471809  [  368/  728]\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.220710  [   16/  728]\n",
      "loss: 0.635377  [  368/  728]\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.211384  [   16/  728]\n",
      "loss: 0.359091  [  368/  728]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.266750  [   16/  728]\n",
      "loss: 0.608039  [  368/  728]\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.197799  [   16/  728]\n",
      "loss: 0.722950  [  368/  728]\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.268174  [   16/  728]\n",
      "loss: 0.300725  [  368/  728]\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.251309  [   16/  728]\n",
      "loss: 0.364648  [  368/  728]\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.287563  [   16/  728]\n",
      "loss: 0.451939  [  368/  728]\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.254222  [   16/  728]\n",
      "loss: 0.441644  [  368/  728]\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.250297  [   16/  728]\n",
      "loss: 0.350767  [  368/  728]\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.325606  [   16/  728]\n",
      "loss: 0.616899  [  368/  728]\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.214688  [   16/  728]\n",
      "loss: 0.327557  [  368/  728]\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.203498  [   16/  728]\n",
      "loss: 0.575414  [  368/  728]\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.226761  [   16/  728]\n",
      "loss: 0.384861  [  368/  728]\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.242195  [   16/  728]\n",
      "loss: 0.544254  [  368/  728]\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.342082  [   16/  728]\n",
      "loss: 0.406876  [  368/  728]\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.224907  [   16/  728]\n",
      "loss: 0.583865  [  368/  728]\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.275021  [   16/  728]\n",
      "loss: 0.573166  [  368/  728]\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.223504  [   16/  728]\n",
      "loss: 0.415409  [  368/  728]\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.285091  [   16/  728]\n",
      "loss: 0.320892  [  368/  728]\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.297566  [   16/  728]\n",
      "loss: 0.330762  [  368/  728]\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.247020  [   16/  728]\n",
      "loss: 0.351659  [  368/  728]\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.274432  [   16/  728]\n",
      "loss: 0.420517  [  368/  728]\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.280396  [   16/  728]\n",
      "loss: 0.431773  [  368/  728]\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.287864  [   16/  728]\n",
      "loss: 0.314094  [  368/  728]\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.217976  [   16/  728]\n",
      "loss: 0.431150  [  368/  728]\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.257911  [   16/  728]\n",
      "loss: 0.371595  [  368/  728]\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.265434  [   16/  728]\n",
      "loss: 0.428527  [  368/  728]\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.265497  [   16/  728]\n",
      "loss: 0.337161  [  368/  728]\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.285566  [   16/  728]\n",
      "loss: 0.289795  [  368/  728]\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.276802  [   16/  728]\n",
      "loss: 0.488309  [  368/  728]\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.203913  [   16/  728]\n",
      "loss: 0.411820  [  368/  728]\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.301534  [   16/  728]\n",
      "loss: 0.347213  [  368/  728]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.308268  [   16/  728]\n",
      "loss: 0.381221  [  368/  728]\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.249458  [   16/  728]\n",
      "loss: 0.546336  [  368/  728]\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.238725  [   16/  728]\n",
      "loss: 0.284063  [  368/  728]\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.320387  [   16/  728]\n",
      "loss: 0.288611  [  368/  728]\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.231068  [   16/  728]\n",
      "loss: 0.327702  [  368/  728]\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.319284  [   16/  728]\n",
      "loss: 0.438148  [  368/  728]\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.252073  [   16/  728]\n",
      "loss: 0.387553  [  368/  728]\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.279288  [   16/  728]\n",
      "loss: 0.450599  [  368/  728]\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.252317  [   16/  728]\n",
      "loss: 0.278340  [  368/  728]\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.244999  [   16/  728]\n",
      "loss: 0.338169  [  368/  728]\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.222005  [   16/  728]\n",
      "loss: 0.414776  [  368/  728]\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.280271  [   16/  728]\n",
      "loss: 0.386423  [  368/  728]\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.315358  [   16/  728]\n",
      "loss: 0.402156  [  368/  728]\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.273161  [   16/  728]\n",
      "loss: 87.509300  [  368/  728]\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.288434  [   16/  728]\n",
      "loss: 0.235602  [  368/  728]\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.260326  [   16/  728]\n",
      "loss: 0.315360  [  368/  728]\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.307515  [   16/  728]\n",
      "loss: 0.397982  [  368/  728]\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.273491  [   16/  728]\n",
      "loss: 0.424457  [  368/  728]\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.287838  [   16/  728]\n",
      "loss: 0.217006  [  368/  728]\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.206554  [   16/  728]\n",
      "loss: 0.580272  [  368/  728]\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.253049  [   16/  728]\n",
      "loss: 0.316252  [  368/  728]\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.352617  [   16/  728]\n",
      "loss: 0.613630  [  368/  728]\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.306337  [   16/  728]\n",
      "loss: 0.420756  [  368/  728]\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.270572  [   16/  728]\n",
      "loss: 0.214437  [  368/  728]\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.318911  [   16/  728]\n",
      "loss: 0.450930  [  368/  728]\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.235453  [   16/  728]\n",
      "loss: 0.312783  [  368/  728]\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.262446  [   16/  728]\n",
      "loss: 0.402955  [  368/  728]\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.262151  [   16/  728]\n",
      "loss: 0.343769  [  368/  728]\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.265101  [   16/  728]\n",
      "loss: 0.230046  [  368/  728]\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.237109  [   16/  728]\n",
      "loss: 0.398548  [  368/  728]\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.272871  [   16/  728]\n",
      "loss: 0.293248  [  368/  728]\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.303498  [   16/  728]\n",
      "loss: 0.306198  [  368/  728]\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.258390  [   16/  728]\n",
      "loss: 0.292980  [  368/  728]\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.237535  [   16/  728]\n",
      "loss: 0.268717  [  368/  728]\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.354530  [   16/  728]\n",
      "loss: 0.455535  [  368/  728]\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.255482  [   16/  728]\n",
      "loss: 0.344944  [  368/  728]\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.277273  [   16/  728]\n",
      "loss: 0.195081  [  368/  728]\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.183074  [   16/  728]\n",
      "loss: 0.356441  [  368/  728]\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.220637  [   16/  728]\n",
      "loss: 0.367791  [  368/  728]\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.213200  [   16/  728]\n",
      "loss: 0.342034  [  368/  728]\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.179772  [   16/  728]\n",
      "loss: 0.537629  [  368/  728]\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.244625  [   16/  728]\n",
      "loss: 0.334984  [  368/  728]\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.256707  [   16/  728]\n",
      "loss: 0.391232  [  368/  728]\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.285066  [   16/  728]\n",
      "loss: 0.498961  [  368/  728]\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.244063  [   16/  728]\n",
      "loss: 0.373746  [  368/  728]\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.287534  [   16/  728]\n",
      "loss: 0.321101  [  368/  728]\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.305911  [   16/  728]\n",
      "loss: 0.446943  [  368/  728]\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.232436  [   16/  728]\n",
      "loss: 0.543835  [  368/  728]\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.187100  [   16/  728]\n",
      "loss: 0.382290  [  368/  728]\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.342574  [   16/  728]\n",
      "loss: 0.338369  [  368/  728]\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.247293  [   16/  728]\n",
      "loss: 0.500659  [  368/  728]\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.237860  [   16/  728]\n",
      "loss: 0.266012  [  368/  728]\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.242573  [   16/  728]\n",
      "loss: 0.349635  [  368/  728]\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.298659  [   16/  728]\n",
      "loss: 151.956482  [  368/  728]\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.272881  [   16/  728]\n",
      "loss: 0.306878  [  368/  728]\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.266925  [   16/  728]\n",
      "loss: 0.214902  [  368/  728]\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.286857  [   16/  728]\n",
      "loss: 0.320186  [  368/  728]\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.201852  [   16/  728]\n",
      "loss: 0.325777  [  368/  728]\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.226714  [   16/  728]\n",
      "loss: 0.418503  [  368/  728]\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.250630  [   16/  728]\n",
      "loss: 0.250595  [  368/  728]\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 0.189735  [   16/  728]\n",
      "loss: 0.314398  [  368/  728]\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 0.199515  [   16/  728]\n",
      "loss: 0.244931  [  368/  728]\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 0.271157  [   16/  728]\n",
      "loss: 0.212644  [  368/  728]\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 0.254088  [   16/  728]\n",
      "loss: 0.633563  [  368/  728]\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 0.263607  [   16/  728]\n",
      "loss: 0.262989  [  368/  728]\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 0.252916  [   16/  728]\n",
      "loss: 0.427113  [  368/  728]\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 0.262877  [   16/  728]\n",
      "loss: 0.292374  [  368/  728]\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 0.153262  [   16/  728]\n",
      "loss: 0.317023  [  368/  728]\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 0.254928  [   16/  728]\n",
      "loss: 0.358892  [  368/  728]\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 0.285880  [   16/  728]\n",
      "loss: 0.446209  [  368/  728]\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 0.215913  [   16/  728]\n",
      "loss: 0.244277  [  368/  728]\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 0.263159  [   16/  728]\n",
      "loss: 0.346971  [  368/  728]\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 0.245597  [   16/  728]\n",
      "loss: 0.341151  [  368/  728]\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 0.238512  [   16/  728]\n",
      "loss: 0.378991  [  368/  728]\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 0.296044  [   16/  728]\n",
      "loss: 0.300946  [  368/  728]\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 0.235614  [   16/  728]\n",
      "loss: 0.417596  [  368/  728]\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 0.227332  [   16/  728]\n",
      "loss: 0.265507  [  368/  728]\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 0.229245  [   16/  728]\n",
      "loss: 0.238769  [  368/  728]\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 0.238888  [   16/  728]\n",
      "loss: 0.402790  [  368/  728]\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 0.182716  [   16/  728]\n",
      "loss: 0.256025  [  368/  728]\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 0.225091  [   16/  728]\n",
      "loss: 0.265315  [  368/  728]\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 0.189888  [   16/  728]\n",
      "loss: 0.361066  [  368/  728]\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 0.214713  [   16/  728]\n",
      "loss: 0.295274  [  368/  728]\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 0.240414  [   16/  728]\n",
      "loss: 0.286332  [  368/  728]\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 0.213179  [   16/  728]\n",
      "loss: 0.324408  [  368/  728]\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 0.289827  [   16/  728]\n",
      "loss: 0.396265  [  368/  728]\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 0.199715  [   16/  728]\n",
      "loss: 0.275594  [  368/  728]\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 0.324657  [   16/  728]\n",
      "loss: 0.301221  [  368/  728]\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 0.300627  [   16/  728]\n",
      "loss: 0.329574  [  368/  728]\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 0.330597  [   16/  728]\n",
      "loss: 0.367163  [  368/  728]\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 0.306544  [   16/  728]\n",
      "loss: 0.482084  [  368/  728]\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 0.277702  [   16/  728]\n",
      "loss: 0.349332  [  368/  728]\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 0.286372  [   16/  728]\n",
      "loss: 0.194346  [  368/  728]\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 0.274648  [   16/  728]\n",
      "loss: 0.323996  [  368/  728]\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 0.244250  [   16/  728]\n",
      "loss: 0.282816  [  368/  728]\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 0.192730  [   16/  728]\n",
      "loss: 0.520499  [  368/  728]\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 0.202638  [   16/  728]\n",
      "loss: 0.285808  [  368/  728]\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 0.246658  [   16/  728]\n",
      "loss: 0.248277  [  368/  728]\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 0.305616  [   16/  728]\n",
      "loss: 0.319521  [  368/  728]\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 0.192439  [   16/  728]\n",
      "loss: 0.207117  [  368/  728]\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 0.263179  [   16/  728]\n",
      "loss: 0.250351  [  368/  728]\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 0.254078  [   16/  728]\n",
      "loss: 0.354484  [  368/  728]\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 0.193099  [   16/  728]\n",
      "loss: 0.414153  [  368/  728]\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.272965  [   16/  728]\n",
      "loss: 0.376567  [  368/  728]\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 0.247443  [   16/  728]\n",
      "loss: 0.443519  [  368/  728]\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 0.243237  [   16/  728]\n",
      "loss: 0.294450  [  368/  728]\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 0.239143  [   16/  728]\n",
      "loss: 0.362419  [  368/  728]\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 0.213412  [   16/  728]\n",
      "loss: 0.335721  [  368/  728]\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 0.276732  [   16/  728]\n",
      "loss: 0.246391  [  368/  728]\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 0.263193  [   16/  728]\n",
      "loss: 0.210273  [  368/  728]\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 0.210198  [   16/  728]\n",
      "loss: 0.429323  [  368/  728]\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 0.229444  [   16/  728]\n",
      "loss: 0.246535  [  368/  728]\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 0.239555  [   16/  728]\n",
      "loss: 0.400296  [  368/  728]\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 0.211527  [   16/  728]\n",
      "loss: 0.410519  [  368/  728]\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 0.183030  [   16/  728]\n",
      "loss: 0.284582  [  368/  728]\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 0.289476  [   16/  728]\n",
      "loss: 0.363618  [  368/  728]\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 0.198042  [   16/  728]\n",
      "loss: 0.191110  [  368/  728]\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 0.304852  [   16/  728]\n",
      "loss: 0.373439  [  368/  728]\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.219180  [   16/  728]\n",
      "loss: 0.321519  [  368/  728]\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 0.292669  [   16/  728]\n",
      "loss: 0.235574  [  368/  728]\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 0.300424  [   16/  728]\n",
      "loss: 0.195998  [  368/  728]\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 0.309809  [   16/  728]\n",
      "loss: 0.586598  [  368/  728]\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 0.224287  [   16/  728]\n",
      "loss: 0.408669  [  368/  728]\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 0.251335  [   16/  728]\n",
      "loss: 0.308191  [  368/  728]\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 0.252970  [   16/  728]\n",
      "loss: 0.297130  [  368/  728]\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 0.263048  [   16/  728]\n",
      "loss: 0.366220  [  368/  728]\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 0.241746  [   16/  728]\n",
      "loss: 0.336247  [  368/  728]\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 0.232797  [   16/  728]\n",
      "loss: 0.312455  [  368/  728]\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 0.261658  [   16/  728]\n",
      "loss: 0.335099  [  368/  728]\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.254911  [   16/  728]\n",
      "loss: 0.334775  [  368/  728]\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 0.236739  [   16/  728]\n",
      "loss: 0.435200  [  368/  728]\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 0.222799  [   16/  728]\n",
      "loss: 0.345724  [  368/  728]\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 0.212091  [   16/  728]\n",
      "loss: 0.341064  [  368/  728]\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 0.284920  [   16/  728]\n",
      "loss: 0.344000  [  368/  728]\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 0.219462  [   16/  728]\n",
      "loss: 0.360649  [  368/  728]\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 0.191721  [   16/  728]\n",
      "loss: 0.344089  [  368/  728]\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 0.226276  [   16/  728]\n",
      "loss: 0.365247  [  368/  728]\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 0.246662  [   16/  728]\n",
      "loss: 0.364211  [  368/  728]\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 0.215421  [   16/  728]\n",
      "loss: 0.485913  [  368/  728]\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 0.240528  [   16/  728]\n",
      "loss: 0.465152  [  368/  728]\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 0.210242  [   16/  728]\n",
      "loss: 0.254738  [  368/  728]\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 0.254378  [   16/  728]\n",
      "loss: 0.385163  [  368/  728]\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 0.275962  [   16/  728]\n",
      "loss: 0.263162  [  368/  728]\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 0.269032  [   16/  728]\n",
      "loss: 0.270954  [  368/  728]\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.232998  [   16/  728]\n",
      "loss: 0.356915  [  368/  728]\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 0.211745  [   16/  728]\n",
      "loss: 0.340809  [  368/  728]\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 0.207424  [   16/  728]\n",
      "loss: 0.272897  [  368/  728]\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 0.249520  [   16/  728]\n",
      "loss: 0.306519  [  368/  728]\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 0.286100  [   16/  728]\n",
      "loss: 0.242883  [  368/  728]\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 0.251045  [   16/  728]\n",
      "loss: 0.248470  [  368/  728]\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 0.220237  [   16/  728]\n",
      "loss: 0.429746  [  368/  728]\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 0.213375  [   16/  728]\n",
      "loss: 0.384888  [  368/  728]\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 0.250094  [   16/  728]\n",
      "loss: 0.485552  [  368/  728]\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 0.264572  [   16/  728]\n",
      "loss: 0.413122  [  368/  728]\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 0.243311  [   16/  728]\n",
      "loss: 0.369512  [  368/  728]\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 0.186166  [   16/  728]\n",
      "loss: 0.264674  [  368/  728]\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 0.198320  [   16/  728]\n",
      "loss: 0.356099  [  368/  728]\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 0.117887  [   16/  728]\n",
      "loss: 0.222288  [  368/  728]\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 0.190562  [   16/  728]\n",
      "loss: 0.273712  [  368/  728]\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 0.223420  [   16/  728]\n",
      "loss: 0.345301  [  368/  728]\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 0.229569  [   16/  728]\n",
      "loss: 0.202324  [  368/  728]\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 0.174472  [   16/  728]\n",
      "loss: 0.353624  [  368/  728]\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 0.191203  [   16/  728]\n",
      "loss: 0.414433  [  368/  728]\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 0.197782  [   16/  728]\n",
      "loss: 0.276779  [  368/  728]\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 0.186350  [   16/  728]\n",
      "loss: 0.394860  [  368/  728]\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 0.232705  [   16/  728]\n",
      "loss: 0.264542  [  368/  728]\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 0.149891  [   16/  728]\n",
      "loss: 0.320338  [  368/  728]\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 0.248132  [   16/  728]\n",
      "loss: 0.533311  [  368/  728]\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 0.300488  [   16/  728]\n",
      "loss: 0.389228  [  368/  728]\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 0.240765  [   16/  728]\n",
      "loss: 0.192937  [  368/  728]\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 0.212257  [   16/  728]\n",
      "loss: 0.342776  [  368/  728]\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 0.221492  [   16/  728]\n",
      "loss: 0.267675  [  368/  728]\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 0.140493  [   16/  728]\n",
      "loss: 0.288859  [  368/  728]\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 0.269173  [   16/  728]\n",
      "loss: 0.178108  [  368/  728]\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.230703  [   16/  728]\n",
      "loss: 0.438424  [  368/  728]\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 0.194880  [   16/  728]\n",
      "loss: 0.268478  [  368/  728]\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 0.218342  [   16/  728]\n",
      "loss: 0.315002  [  368/  728]\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 0.202744  [   16/  728]\n",
      "loss: 0.305391  [  368/  728]\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 0.196146  [   16/  728]\n",
      "loss: 0.264042  [  368/  728]\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 0.229418  [   16/  728]\n",
      "loss: 0.414127  [  368/  728]\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 0.268072  [   16/  728]\n",
      "loss: 0.463642  [  368/  728]\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 0.176637  [   16/  728]\n",
      "loss: 0.308217  [  368/  728]\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 0.199839  [   16/  728]\n",
      "loss: 0.295831  [  368/  728]\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 0.222610  [   16/  728]\n",
      "loss: 0.442302  [  368/  728]\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 0.247707  [   16/  728]\n",
      "loss: 0.330964  [  368/  728]\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 0.253411  [   16/  728]\n",
      "loss: 0.301958  [  368/  728]\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 0.247139  [   16/  728]\n",
      "loss: 0.318508  [  368/  728]\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 0.198136  [   16/  728]\n",
      "loss: 0.310239  [  368/  728]\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 0.199844  [   16/  728]\n",
      "loss: 0.238793  [  368/  728]\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 0.200359  [   16/  728]\n",
      "loss: 0.317415  [  368/  728]\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 0.258457  [   16/  728]\n",
      "loss: 0.261783  [  368/  728]\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 0.134064  [   16/  728]\n",
      "loss: 0.460869  [  368/  728]\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 0.174960  [   16/  728]\n",
      "loss: 0.418450  [  368/  728]\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 0.288332  [   16/  728]\n",
      "loss: 0.242055  [  368/  728]\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 0.236727  [   16/  728]\n",
      "loss: 0.249801  [  368/  728]\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 0.243727  [   16/  728]\n",
      "loss: 0.564628  [  368/  728]\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 0.252863  [   16/  728]\n",
      "loss: 0.278481  [  368/  728]\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 0.228140  [   16/  728]\n",
      "loss: 0.347144  [  368/  728]\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 0.232702  [   16/  728]\n",
      "loss: 0.417458  [  368/  728]\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 0.188603  [   16/  728]\n",
      "loss: 0.353680  [  368/  728]\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 0.199529  [   16/  728]\n",
      "loss: 0.215464  [  368/  728]\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 0.204340  [   16/  728]\n",
      "loss: 0.539640  [  368/  728]\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 0.205999  [   16/  728]\n",
      "loss: 0.326606  [  368/  728]\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 0.179110  [   16/  728]\n",
      "loss: 0.237492  [  368/  728]\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 0.209174  [   16/  728]\n",
      "loss: 0.311621  [  368/  728]\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 0.308344  [   16/  728]\n",
      "loss: 0.431931  [  368/  728]\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 0.212967  [   16/  728]\n",
      "loss: 0.305218  [  368/  728]\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 0.193962  [   16/  728]\n",
      "loss: 0.294120  [  368/  728]\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 0.230420  [   16/  728]\n",
      "loss: 0.464737  [  368/  728]\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 0.306618  [   16/  728]\n",
      "loss: 0.586147  [  368/  728]\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 0.267421  [   16/  728]\n",
      "loss: 0.266902  [  368/  728]\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 0.249465  [   16/  728]\n",
      "loss: 0.340960  [  368/  728]\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 0.208888  [   16/  728]\n",
      "loss: 0.450981  [  368/  728]\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 0.256022  [   16/  728]\n",
      "loss: 0.456807  [  368/  728]\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 0.242667  [   16/  728]\n",
      "loss: 0.259419  [  368/  728]\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 0.268780  [   16/  728]\n",
      "loss: 0.452494  [  368/  728]\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 0.250620  [   16/  728]\n",
      "loss: 0.268892  [  368/  728]\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 0.249928  [   16/  728]\n",
      "loss: 0.332778  [  368/  728]\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 0.180791  [   16/  728]\n",
      "loss: 0.257318  [  368/  728]\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 0.160479  [   16/  728]\n",
      "loss: 0.314400  [  368/  728]\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 0.156838  [   16/  728]\n",
      "loss: 0.361026  [  368/  728]\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 0.229829  [   16/  728]\n",
      "loss: 0.387294  [  368/  728]\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 0.232557  [   16/  728]\n",
      "loss: 0.269877  [  368/  728]\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 0.189649  [   16/  728]\n",
      "loss: 0.194203  [  368/  728]\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 0.214055  [   16/  728]\n",
      "loss: 0.375431  [  368/  728]\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 0.217237  [   16/  728]\n",
      "loss: 0.181298  [  368/  728]\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.230928  [   16/  728]\n",
      "loss: 0.332539  [  368/  728]\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.248325  [   16/  728]\n",
      "loss: 238.924377  [  368/  728]\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 0.247344  [   16/  728]\n",
      "loss: 0.276338  [  368/  728]\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 0.213706  [   16/  728]\n",
      "loss: 0.216624  [  368/  728]\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 0.166859  [   16/  728]\n",
      "loss: 0.278781  [  368/  728]\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.311265  [   16/  728]\n",
      "loss: 0.408485  [  368/  728]\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 0.179748  [   16/  728]\n",
      "loss: 0.275266  [  368/  728]\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 0.187341  [   16/  728]\n",
      "loss: 0.521611  [  368/  728]\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 0.299590  [   16/  728]\n",
      "loss: 0.328614  [  368/  728]\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 0.174610  [   16/  728]\n",
      "loss: 0.439268  [  368/  728]\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 0.287453  [   16/  728]\n",
      "loss: 0.190750  [  368/  728]\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 0.219572  [   16/  728]\n",
      "loss: 0.283747  [  368/  728]\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 0.204568  [   16/  728]\n",
      "loss: 0.453813  [  368/  728]\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 0.257800  [   16/  728]\n",
      "loss: 0.402000  [  368/  728]\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.205864  [   16/  728]\n",
      "loss: 0.368270  [  368/  728]\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 0.294197  [   16/  728]\n",
      "loss: 0.237104  [  368/  728]\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 0.236505  [   16/  728]\n",
      "loss: 0.343855  [  368/  728]\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 0.214471  [   16/  728]\n",
      "loss: 0.353185  [  368/  728]\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 0.282708  [   16/  728]\n",
      "loss: 0.286816  [  368/  728]\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 0.169564  [   16/  728]\n",
      "loss: 0.255784  [  368/  728]\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 0.325648  [   16/  728]\n",
      "loss: 0.276061  [  368/  728]\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.216098  [   16/  728]\n",
      "loss: 0.315319  [  368/  728]\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 0.161614  [   16/  728]\n",
      "loss: 0.268048  [  368/  728]\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 0.154632  [   16/  728]\n",
      "loss: 0.192872  [  368/  728]\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 0.186960  [   16/  728]\n",
      "loss: 0.327831  [  368/  728]\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 0.196393  [   16/  728]\n",
      "loss: 0.437425  [  368/  728]\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 0.274824  [   16/  728]\n",
      "loss: 0.405489  [  368/  728]\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 0.274417  [   16/  728]\n",
      "loss: 0.312711  [  368/  728]\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 0.207081  [   16/  728]\n",
      "loss: 0.323978  [  368/  728]\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 0.273880  [   16/  728]\n",
      "loss: 0.379402  [  368/  728]\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 0.206374  [   16/  728]\n",
      "loss: 0.273718  [  368/  728]\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 0.220947  [   16/  728]\n",
      "loss: 0.166313  [  368/  728]\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 0.180129  [   16/  728]\n",
      "loss: 0.282940  [  368/  728]\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.187453  [   16/  728]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|                                    | 1/5 [00:19<01:16, 19.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.540964  [  368/  728]\n",
      "Done!\n",
      "Trial 2:\n",
      "-------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 4.896502  [   16/  728]\n",
      "loss: 187.760025  [  368/  728]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.635041  [   16/  728]\n",
      "loss: 1.886816  [  368/  728]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.304061  [   16/  728]\n",
      "loss: 324.559967  [  368/  728]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.769761  [   16/  728]\n",
      "loss: 1.880480  [  368/  728]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.365659  [   16/  728]\n",
      "loss: 1.221524  [  368/  728]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.574308  [   16/  728]\n",
      "loss: 698.633728  [  368/  728]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.481204  [   16/  728]\n",
      "loss: 1907.968872  [  368/  728]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.162121  [   16/  728]\n",
      "loss: 1.056444  [  368/  728]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.491834  [   16/  728]\n",
      "loss: 2982.411865  [  368/  728]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.198406  [   16/  728]\n",
      "loss: 162.966248  [  368/  728]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.011513  [   16/  728]\n",
      "loss: 2847.877197  [  368/  728]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.222391  [   16/  728]\n",
      "loss: 200.598083  [  368/  728]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.083040  [   16/  728]\n",
      "loss: 615.505981  [  368/  728]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.124374  [   16/  728]\n",
      "loss: 0.789021  [  368/  728]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.885788  [   16/  728]\n",
      "loss: 810.127747  [  368/  728]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.137884  [   16/  728]\n",
      "loss: 345.874725  [  368/  728]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.103203  [   16/  728]\n",
      "loss: 1.433354  [  368/  728]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.319000  [   16/  728]\n",
      "loss: 1.070873  [  368/  728]\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.842126  [   16/  728]\n",
      "loss: 18.306778  [  368/  728]\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.967261  [   16/  728]\n",
      "loss: 1.318100  [  368/  728]\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.716579  [   16/  728]\n",
      "loss: 317.454346  [  368/  728]\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.824358  [   16/  728]\n",
      "loss: 156.358231  [  368/  728]\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.961859  [   16/  728]\n",
      "loss: 157.788086  [  368/  728]\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1.072737  [   16/  728]\n",
      "loss: 224.903702  [  368/  728]\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.839996  [   16/  728]\n",
      "loss: 856.484863  [  368/  728]\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.886010  [   16/  728]\n",
      "loss: 75.311646  [  368/  728]\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 1.073769  [   16/  728]\n",
      "loss: 408.424011  [  368/  728]\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.696247  [   16/  728]\n",
      "loss: 1.771470  [  368/  728]\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.718815  [   16/  728]\n",
      "loss: 213.992355  [  368/  728]\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.622699  [   16/  728]\n",
      "loss: 292.672363  [  368/  728]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.760122  [   16/  728]\n",
      "loss: 165.942062  [  368/  728]\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.846284  [   16/  728]\n",
      "loss: 207.095718  [  368/  728]\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.926938  [   16/  728]\n",
      "loss: 1.235831  [  368/  728]\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.633919  [   16/  728]\n",
      "loss: 262.121979  [  368/  728]\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.804197  [   16/  728]\n",
      "loss: 141.032791  [  368/  728]\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 1.038630  [   16/  728]\n",
      "loss: 142.287430  [  368/  728]\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 1.034389  [   16/  728]\n",
      "loss: 19.360058  [  368/  728]\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 1.047922  [   16/  728]\n",
      "loss: 84.081322  [  368/  728]\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.871796  [   16/  728]\n",
      "loss: 92.550423  [  368/  728]\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.721049  [   16/  728]\n",
      "loss: 499.635010  [  368/  728]\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.699367  [   16/  728]\n",
      "loss: 1.283339  [  368/  728]\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 1.027612  [   16/  728]\n",
      "loss: 90.314362  [  368/  728]\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.787733  [   16/  728]\n",
      "loss: 18.404634  [  368/  728]\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.643046  [   16/  728]\n",
      "loss: 7.600943  [  368/  728]\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.439498  [   16/  728]\n",
      "loss: 1.207111  [  368/  728]\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.646865  [   16/  728]\n",
      "loss: 1.399559  [  368/  728]\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.668050  [   16/  728]\n",
      "loss: 0.994615  [  368/  728]\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.895732  [   16/  728]\n",
      "loss: 1.092440  [  368/  728]\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.722610  [   16/  728]\n",
      "loss: 12.500434  [  368/  728]\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.631176  [   16/  728]\n",
      "loss: 1.376031  [  368/  728]\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.583299  [   16/  728]\n",
      "loss: 1.488176  [  368/  728]\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.842785  [   16/  728]\n",
      "loss: 11.369756  [  368/  728]\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.561330  [   16/  728]\n",
      "loss: 1.904969  [  368/  728]\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.613134  [   16/  728]\n",
      "loss: 11.688766  [  368/  728]\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.598023  [   16/  728]\n",
      "loss: 1.102553  [  368/  728]\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.811106  [   16/  728]\n",
      "loss: 44.407570  [  368/  728]\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.808699  [   16/  728]\n",
      "loss: 1.015409  [  368/  728]\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.761668  [   16/  728]\n",
      "loss: 5.275423  [  368/  728]\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.535951  [   16/  728]\n",
      "loss: 0.959967  [  368/  728]\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.748690  [   16/  728]\n",
      "loss: 1.207531  [  368/  728]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.565777  [   16/  728]\n",
      "loss: 1.252200  [  368/  728]\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.996538  [   16/  728]\n",
      "loss: 0.962570  [  368/  728]\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.503946  [   16/  728]\n",
      "loss: 7.152609  [  368/  728]\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.519363  [   16/  728]\n",
      "loss: 0.894374  [  368/  728]\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.598297  [   16/  728]\n",
      "loss: 1.177910  [  368/  728]\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.641670  [   16/  728]\n",
      "loss: 1.161029  [  368/  728]\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.571983  [   16/  728]\n",
      "loss: 0.887416  [  368/  728]\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.651243  [   16/  728]\n",
      "loss: 1.104098  [  368/  728]\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.435989  [   16/  728]\n",
      "loss: 29.633217  [  368/  728]\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.558833  [   16/  728]\n",
      "loss: 1.377243  [  368/  728]\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.768210  [   16/  728]\n",
      "loss: 1.101296  [  368/  728]\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.593199  [   16/  728]\n",
      "loss: 126.628654  [  368/  728]\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.381558  [   16/  728]\n",
      "loss: 1.344019  [  368/  728]\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.731830  [   16/  728]\n",
      "loss: 165.841125  [  368/  728]\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.481690  [   16/  728]\n",
      "loss: 0.910171  [  368/  728]\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.596770  [   16/  728]\n",
      "loss: 1.288234  [  368/  728]\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.775007  [   16/  728]\n",
      "loss: 0.870174  [  368/  728]\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.608435  [   16/  728]\n",
      "loss: 0.965397  [  368/  728]\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.761112  [   16/  728]\n",
      "loss: 1.270185  [  368/  728]\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.576083  [   16/  728]\n",
      "loss: 0.959789  [  368/  728]\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.333402  [   16/  728]\n",
      "loss: 1.036541  [  368/  728]\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.426369  [   16/  728]\n",
      "loss: 0.701563  [  368/  728]\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.594318  [   16/  728]\n",
      "loss: 0.914991  [  368/  728]\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.482712  [   16/  728]\n",
      "loss: 1.175039  [  368/  728]\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.541080  [   16/  728]\n",
      "loss: 0.796593  [  368/  728]\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.411367  [   16/  728]\n",
      "loss: 0.929016  [  368/  728]\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.454493  [   16/  728]\n",
      "loss: 166.502518  [  368/  728]\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.486467  [   16/  728]\n",
      "loss: 0.799608  [  368/  728]\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.546937  [   16/  728]\n",
      "loss: 0.666415  [  368/  728]\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.485638  [   16/  728]\n",
      "loss: 1.048682  [  368/  728]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.383287  [   16/  728]\n",
      "loss: 0.878101  [  368/  728]\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.336308  [   16/  728]\n",
      "loss: 0.706122  [  368/  728]\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.535539  [   16/  728]\n",
      "loss: 29.580811  [  368/  728]\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.459925  [   16/  728]\n",
      "loss: 0.626319  [  368/  728]\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.424189  [   16/  728]\n",
      "loss: 0.854633  [  368/  728]\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.513052  [   16/  728]\n",
      "loss: 190.940781  [  368/  728]\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.497347  [   16/  728]\n",
      "loss: 0.709638  [  368/  728]\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.364444  [   16/  728]\n",
      "loss: 0.808965  [  368/  728]\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.604115  [   16/  728]\n",
      "loss: 1.013035  [  368/  728]\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.298508  [   16/  728]\n",
      "loss: 1.021067  [  368/  728]\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.316887  [   16/  728]\n",
      "loss: 0.698908  [  368/  728]\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.379907  [   16/  728]\n",
      "loss: 0.792896  [  368/  728]\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.367306  [   16/  728]\n",
      "loss: 0.779088  [  368/  728]\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.483607  [   16/  728]\n",
      "loss: 1.104370  [  368/  728]\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.354748  [   16/  728]\n",
      "loss: 0.723769  [  368/  728]\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.485933  [   16/  728]\n",
      "loss: 0.537400  [  368/  728]\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.446822  [   16/  728]\n",
      "loss: 0.577324  [  368/  728]\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.437781  [   16/  728]\n",
      "loss: 10.065782  [  368/  728]\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.481912  [   16/  728]\n",
      "loss: 0.682171  [  368/  728]\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.301433  [   16/  728]\n",
      "loss: 0.776380  [  368/  728]\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.373716  [   16/  728]\n",
      "loss: 0.726253  [  368/  728]\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.405939  [   16/  728]\n",
      "loss: 0.895817  [  368/  728]\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.481983  [   16/  728]\n",
      "loss: 0.666809  [  368/  728]\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.438823  [   16/  728]\n",
      "loss: 0.645377  [  368/  728]\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.367795  [   16/  728]\n",
      "loss: 0.548771  [  368/  728]\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.354791  [   16/  728]\n",
      "loss: 0.780959  [  368/  728]\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.381447  [   16/  728]\n",
      "loss: 0.687883  [  368/  728]\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.339755  [   16/  728]\n",
      "loss: 0.718070  [  368/  728]\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.464786  [   16/  728]\n",
      "loss: 0.654147  [  368/  728]\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.555763  [   16/  728]\n",
      "loss: 0.499900  [  368/  728]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.384406  [   16/  728]\n",
      "loss: 0.823134  [  368/  728]\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.405112  [   16/  728]\n",
      "loss: 4.742929  [  368/  728]\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.314298  [   16/  728]\n",
      "loss: 0.843396  [  368/  728]\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.273833  [   16/  728]\n",
      "loss: 0.608432  [  368/  728]\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.366382  [   16/  728]\n",
      "loss: 0.521222  [  368/  728]\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.292579  [   16/  728]\n",
      "loss: 0.637257  [  368/  728]\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.435750  [   16/  728]\n",
      "loss: 102.201195  [  368/  728]\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.375338  [   16/  728]\n",
      "loss: 0.380250  [  368/  728]\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.235336  [   16/  728]\n",
      "loss: 0.608098  [  368/  728]\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.383136  [   16/  728]\n",
      "loss: 0.418913  [  368/  728]\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.330428  [   16/  728]\n",
      "loss: 0.707025  [  368/  728]\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.258579  [   16/  728]\n",
      "loss: 0.666810  [  368/  728]\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.323503  [   16/  728]\n",
      "loss: 0.830869  [  368/  728]\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.414272  [   16/  728]\n",
      "loss: 0.525354  [  368/  728]\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.368045  [   16/  728]\n",
      "loss: 6.772625  [  368/  728]\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.267154  [   16/  728]\n",
      "loss: 0.784657  [  368/  728]\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.305729  [   16/  728]\n",
      "loss: 0.591541  [  368/  728]\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.392042  [   16/  728]\n",
      "loss: 0.874475  [  368/  728]\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.272212  [   16/  728]\n",
      "loss: 0.774760  [  368/  728]\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.382056  [   16/  728]\n",
      "loss: 0.520439  [  368/  728]\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.323297  [   16/  728]\n",
      "loss: 0.584960  [  368/  728]\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.273621  [   16/  728]\n",
      "loss: 0.697092  [  368/  728]\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.388479  [   16/  728]\n",
      "loss: 0.692763  [  368/  728]\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.369592  [   16/  728]\n",
      "loss: 0.358656  [  368/  728]\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.273525  [   16/  728]\n",
      "loss: 0.412589  [  368/  728]\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.346934  [   16/  728]\n",
      "loss: 0.378995  [  368/  728]\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.336419  [   16/  728]\n",
      "loss: 0.314783  [  368/  728]\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.350428  [   16/  728]\n",
      "loss: 0.393655  [  368/  728]\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.326229  [   16/  728]\n",
      "loss: 0.564057  [  368/  728]\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.367823  [   16/  728]\n",
      "loss: 0.668308  [  368/  728]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.357544  [   16/  728]\n",
      "loss: 127.836800  [  368/  728]\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.276243  [   16/  728]\n",
      "loss: 0.849235  [  368/  728]\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.306571  [   16/  728]\n",
      "loss: 0.553937  [  368/  728]\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.325377  [   16/  728]\n",
      "loss: 0.729793  [  368/  728]\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.287150  [   16/  728]\n",
      "loss: 0.551367  [  368/  728]\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.297304  [   16/  728]\n",
      "loss: 0.624949  [  368/  728]\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.263498  [   16/  728]\n",
      "loss: 0.598721  [  368/  728]\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.321664  [   16/  728]\n",
      "loss: 0.357064  [  368/  728]\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.301262  [   16/  728]\n",
      "loss: 0.527753  [  368/  728]\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.307216  [   16/  728]\n",
      "loss: 0.487873  [  368/  728]\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.220346  [   16/  728]\n",
      "loss: 0.632727  [  368/  728]\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.251699  [   16/  728]\n",
      "loss: 0.513412  [  368/  728]\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.256408  [   16/  728]\n",
      "loss: 0.454078  [  368/  728]\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.421722  [   16/  728]\n",
      "loss: 0.761290  [  368/  728]\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.414440  [   16/  728]\n",
      "loss: 0.630763  [  368/  728]\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.258562  [   16/  728]\n",
      "loss: 0.448387  [  368/  728]\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.266739  [   16/  728]\n",
      "loss: 0.483981  [  368/  728]\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.353729  [   16/  728]\n",
      "loss: 0.417142  [  368/  728]\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.276101  [   16/  728]\n",
      "loss: 0.450717  [  368/  728]\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.274569  [   16/  728]\n",
      "loss: 0.485109  [  368/  728]\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.307560  [   16/  728]\n",
      "loss: 0.522075  [  368/  728]\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.226202  [   16/  728]\n",
      "loss: 0.516661  [  368/  728]\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.275418  [   16/  728]\n",
      "loss: 0.570479  [  368/  728]\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.363978  [   16/  728]\n",
      "loss: 0.446548  [  368/  728]\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.310704  [   16/  728]\n",
      "loss: 0.718039  [  368/  728]\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.344796  [   16/  728]\n",
      "loss: 0.337060  [  368/  728]\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.297543  [   16/  728]\n",
      "loss: 0.544999  [  368/  728]\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.293951  [   16/  728]\n",
      "loss: 0.438929  [  368/  728]\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.231565  [   16/  728]\n",
      "loss: 0.497295  [  368/  728]\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.399085  [   16/  728]\n",
      "loss: 0.450755  [  368/  728]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.183311  [   16/  728]\n",
      "loss: 0.513683  [  368/  728]\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.338585  [   16/  728]\n",
      "loss: 0.474409  [  368/  728]\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.235157  [   16/  728]\n",
      "loss: 0.572095  [  368/  728]\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.294466  [   16/  728]\n",
      "loss: 0.536647  [  368/  728]\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.314443  [   16/  728]\n",
      "loss: 0.653892  [  368/  728]\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.257021  [   16/  728]\n",
      "loss: 0.443001  [  368/  728]\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.330528  [   16/  728]\n",
      "loss: 0.604729  [  368/  728]\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.255702  [   16/  728]\n",
      "loss: 0.567198  [  368/  728]\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.252687  [   16/  728]\n",
      "loss: 0.261781  [  368/  728]\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.314712  [   16/  728]\n",
      "loss: 0.421448  [  368/  728]\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.235015  [   16/  728]\n",
      "loss: 0.572924  [  368/  728]\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.278844  [   16/  728]\n",
      "loss: 0.602953  [  368/  728]\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.308972  [   16/  728]\n",
      "loss: 0.343871  [  368/  728]\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.276794  [   16/  728]\n",
      "loss: 0.538810  [  368/  728]\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.288393  [   16/  728]\n",
      "loss: 0.431007  [  368/  728]\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.238615  [   16/  728]\n",
      "loss: 0.358190  [  368/  728]\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.267313  [   16/  728]\n",
      "loss: 0.444537  [  368/  728]\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.315764  [   16/  728]\n",
      "loss: 0.437814  [  368/  728]\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.232157  [   16/  728]\n",
      "loss: 0.562423  [  368/  728]\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.256830  [   16/  728]\n",
      "loss: 0.525715  [  368/  728]\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.208764  [   16/  728]\n",
      "loss: 0.572448  [  368/  728]\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.212624  [   16/  728]\n",
      "loss: 0.622489  [  368/  728]\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.362270  [   16/  728]\n",
      "loss: 0.587241  [  368/  728]\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.237159  [   16/  728]\n",
      "loss: 0.483712  [  368/  728]\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.160615  [   16/  728]\n",
      "loss: 0.561393  [  368/  728]\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.370771  [   16/  728]\n",
      "loss: 0.417845  [  368/  728]\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.303731  [   16/  728]\n",
      "loss: 0.473973  [  368/  728]\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.296385  [   16/  728]\n",
      "loss: 0.442851  [  368/  728]\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.272603  [   16/  728]\n",
      "loss: 0.393844  [  368/  728]\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.229926  [   16/  728]\n",
      "loss: 0.434910  [  368/  728]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.238334  [   16/  728]\n",
      "loss: 0.461547  [  368/  728]\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.212851  [   16/  728]\n",
      "loss: 0.588727  [  368/  728]\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.322873  [   16/  728]\n",
      "loss: 0.472169  [  368/  728]\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.306866  [   16/  728]\n",
      "loss: 0.342816  [  368/  728]\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.276776  [   16/  728]\n",
      "loss: 0.422694  [  368/  728]\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.250429  [   16/  728]\n",
      "loss: 0.456574  [  368/  728]\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.246670  [   16/  728]\n",
      "loss: 0.538276  [  368/  728]\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.206286  [   16/  728]\n",
      "loss: 0.273611  [  368/  728]\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.212424  [   16/  728]\n",
      "loss: 0.460900  [  368/  728]\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.283746  [   16/  728]\n",
      "loss: 0.429596  [  368/  728]\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.235834  [   16/  728]\n",
      "loss: 0.376982  [  368/  728]\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.232223  [   16/  728]\n",
      "loss: 0.487441  [  368/  728]\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.230689  [   16/  728]\n",
      "loss: 0.390168  [  368/  728]\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.152054  [   16/  728]\n",
      "loss: 0.497085  [  368/  728]\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.197184  [   16/  728]\n",
      "loss: 0.383811  [  368/  728]\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.241510  [   16/  728]\n",
      "loss: 0.559221  [  368/  728]\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.285804  [   16/  728]\n",
      "loss: 0.503406  [  368/  728]\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.287179  [   16/  728]\n",
      "loss: 0.461576  [  368/  728]\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.242146  [   16/  728]\n",
      "loss: 0.343449  [  368/  728]\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.296377  [   16/  728]\n",
      "loss: 0.371405  [  368/  728]\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.273074  [   16/  728]\n",
      "loss: 0.382290  [  368/  728]\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.215710  [   16/  728]\n",
      "loss: 0.513583  [  368/  728]\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.240678  [   16/  728]\n",
      "loss: 0.375241  [  368/  728]\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.228337  [   16/  728]\n",
      "loss: 0.353787  [  368/  728]\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.275597  [   16/  728]\n",
      "loss: 0.337140  [  368/  728]\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.262989  [   16/  728]\n",
      "loss: 0.403732  [  368/  728]\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.246889  [   16/  728]\n",
      "loss: 0.330363  [  368/  728]\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.206831  [   16/  728]\n",
      "loss: 0.332034  [  368/  728]\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.245249  [   16/  728]\n",
      "loss: 0.395364  [  368/  728]\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.359795  [   16/  728]\n",
      "loss: 0.417928  [  368/  728]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.262237  [   16/  728]\n",
      "loss: 9.417376  [  368/  728]\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.223676  [   16/  728]\n",
      "loss: 0.222341  [  368/  728]\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.297096  [   16/  728]\n",
      "loss: 0.473488  [  368/  728]\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.237020  [   16/  728]\n",
      "loss: 0.516339  [  368/  728]\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.216999  [   16/  728]\n",
      "loss: 0.278525  [  368/  728]\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.279420  [   16/  728]\n",
      "loss: 0.342315  [  368/  728]\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.204924  [   16/  728]\n",
      "loss: 0.522894  [  368/  728]\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.327887  [   16/  728]\n",
      "loss: 0.327526  [  368/  728]\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.309775  [   16/  728]\n",
      "loss: 0.394177  [  368/  728]\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.207907  [   16/  728]\n",
      "loss: 0.327622  [  368/  728]\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.236002  [   16/  728]\n",
      "loss: 0.485229  [  368/  728]\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.293814  [   16/  728]\n",
      "loss: 0.284221  [  368/  728]\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.231853  [   16/  728]\n",
      "loss: 0.476895  [  368/  728]\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.292478  [   16/  728]\n",
      "loss: 0.324127  [  368/  728]\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.285804  [   16/  728]\n",
      "loss: 0.361375  [  368/  728]\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.235364  [   16/  728]\n",
      "loss: 0.378790  [  368/  728]\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.205904  [   16/  728]\n",
      "loss: 0.386483  [  368/  728]\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.281022  [   16/  728]\n",
      "loss: 0.344567  [  368/  728]\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.195518  [   16/  728]\n",
      "loss: 0.362241  [  368/  728]\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.287734  [   16/  728]\n",
      "loss: 0.410721  [  368/  728]\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.224180  [   16/  728]\n",
      "loss: 0.428791  [  368/  728]\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.160291  [   16/  728]\n",
      "loss: 0.394391  [  368/  728]\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.210360  [   16/  728]\n",
      "loss: 0.353724  [  368/  728]\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.212118  [   16/  728]\n",
      "loss: 0.358879  [  368/  728]\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.241291  [   16/  728]\n",
      "loss: 0.387480  [  368/  728]\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.184810  [   16/  728]\n",
      "loss: 0.513154  [  368/  728]\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.219844  [   16/  728]\n",
      "loss: 0.430499  [  368/  728]\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.264335  [   16/  728]\n",
      "loss: 0.451889  [  368/  728]\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.251684  [   16/  728]\n",
      "loss: 0.340374  [  368/  728]\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.349985  [   16/  728]\n",
      "loss: 0.312784  [  368/  728]\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.294551  [   16/  728]\n",
      "loss: 0.385782  [  368/  728]\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.216165  [   16/  728]\n",
      "loss: 0.389699  [  368/  728]\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.277021  [   16/  728]\n",
      "loss: 0.340731  [  368/  728]\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.245952  [   16/  728]\n",
      "loss: 0.432581  [  368/  728]\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.303663  [   16/  728]\n",
      "loss: 0.374020  [  368/  728]\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.278028  [   16/  728]\n",
      "loss: 0.455322  [  368/  728]\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.248774  [   16/  728]\n",
      "loss: 0.411213  [  368/  728]\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.237050  [   16/  728]\n",
      "loss: 0.303052  [  368/  728]\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.282575  [   16/  728]\n",
      "loss: 0.345423  [  368/  728]\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.275157  [   16/  728]\n",
      "loss: 0.358555  [  368/  728]\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.263437  [   16/  728]\n",
      "loss: 0.437829  [  368/  728]\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.264362  [   16/  728]\n",
      "loss: 0.330780  [  368/  728]\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.197303  [   16/  728]\n",
      "loss: 0.384095  [  368/  728]\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.208960  [   16/  728]\n",
      "loss: 0.313801  [  368/  728]\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.181696  [   16/  728]\n",
      "loss: 33.096802  [  368/  728]\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.246255  [   16/  728]\n",
      "loss: 0.317554  [  368/  728]\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.261534  [   16/  728]\n",
      "loss: 0.319744  [  368/  728]\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.210902  [   16/  728]\n",
      "loss: 0.459501  [  368/  728]\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.228701  [   16/  728]\n",
      "loss: 0.393905  [  368/  728]\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.267193  [   16/  728]\n",
      "loss: 0.250726  [  368/  728]\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.214027  [   16/  728]\n",
      "loss: 0.267797  [  368/  728]\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.256748  [   16/  728]\n",
      "loss: 0.435815  [  368/  728]\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.262589  [   16/  728]\n",
      "loss: 0.728452  [  368/  728]\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.239248  [   16/  728]\n",
      "loss: 0.503669  [  368/  728]\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.306689  [   16/  728]\n",
      "loss: 0.408296  [  368/  728]\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.241412  [   16/  728]\n",
      "loss: 0.297724  [  368/  728]\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.290413  [   16/  728]\n",
      "loss: 0.187552  [  368/  728]\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.285591  [   16/  728]\n",
      "loss: 0.505486  [  368/  728]\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.322813  [   16/  728]\n",
      "loss: 0.358068  [  368/  728]\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.253769  [   16/  728]\n",
      "loss: 0.423135  [  368/  728]\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 0.277925  [   16/  728]\n",
      "loss: 0.463912  [  368/  728]\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 0.272884  [   16/  728]\n",
      "loss: 12.037002  [  368/  728]\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 0.268662  [   16/  728]\n",
      "loss: 0.394083  [  368/  728]\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 0.266489  [   16/  728]\n",
      "loss: 0.328940  [  368/  728]\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 0.243790  [   16/  728]\n",
      "loss: 0.259786  [  368/  728]\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 0.172767  [   16/  728]\n",
      "loss: 0.374149  [  368/  728]\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 0.227762  [   16/  728]\n",
      "loss: 0.425463  [  368/  728]\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 0.262179  [   16/  728]\n",
      "loss: 0.367985  [  368/  728]\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 0.291726  [   16/  728]\n",
      "loss: 0.323348  [  368/  728]\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 0.304726  [   16/  728]\n",
      "loss: 0.280378  [  368/  728]\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 0.178393  [   16/  728]\n",
      "loss: 0.460271  [  368/  728]\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 0.266071  [   16/  728]\n",
      "loss: 0.392668  [  368/  728]\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 0.274517  [   16/  728]\n",
      "loss: 0.373803  [  368/  728]\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 0.204813  [   16/  728]\n",
      "loss: 0.283645  [  368/  728]\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 0.258224  [   16/  728]\n",
      "loss: 0.408108  [  368/  728]\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 0.248659  [   16/  728]\n",
      "loss: 0.436337  [  368/  728]\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 0.258526  [   16/  728]\n",
      "loss: 0.252689  [  368/  728]\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 0.224688  [   16/  728]\n",
      "loss: 0.348183  [  368/  728]\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 0.312165  [   16/  728]\n",
      "loss: 0.308896  [  368/  728]\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 0.291139  [   16/  728]\n",
      "loss: 0.444694  [  368/  728]\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 0.222089  [   16/  728]\n",
      "loss: 0.277959  [  368/  728]\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 0.288764  [   16/  728]\n",
      "loss: 0.452708  [  368/  728]\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 0.261737  [   16/  728]\n",
      "loss: 0.387146  [  368/  728]\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 0.279730  [   16/  728]\n",
      "loss: 0.383831  [  368/  728]\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 0.209099  [   16/  728]\n",
      "loss: 0.302119  [  368/  728]\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 0.196382  [   16/  728]\n",
      "loss: 0.294537  [  368/  728]\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 0.228792  [   16/  728]\n",
      "loss: 0.465930  [  368/  728]\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 0.232717  [   16/  728]\n",
      "loss: 0.314092  [  368/  728]\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 0.301465  [   16/  728]\n",
      "loss: 0.214078  [  368/  728]\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 0.221796  [   16/  728]\n",
      "loss: 0.292759  [  368/  728]\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 0.255260  [   16/  728]\n",
      "loss: 0.362950  [  368/  728]\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 0.252395  [   16/  728]\n",
      "loss: 0.453411  [  368/  728]\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 0.213135  [   16/  728]\n",
      "loss: 0.339464  [  368/  728]\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 0.213680  [   16/  728]\n",
      "loss: 0.462531  [  368/  728]\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 0.269283  [   16/  728]\n",
      "loss: 0.277913  [  368/  728]\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 0.270159  [   16/  728]\n",
      "loss: 0.309310  [  368/  728]\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 0.240199  [   16/  728]\n",
      "loss: 0.330777  [  368/  728]\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 0.226122  [   16/  728]\n",
      "loss: 0.275156  [  368/  728]\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 0.340215  [   16/  728]\n",
      "loss: 0.379666  [  368/  728]\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 0.182991  [   16/  728]\n",
      "loss: 0.250864  [  368/  728]\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 0.287064  [   16/  728]\n",
      "loss: 0.447498  [  368/  728]\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 0.283967  [   16/  728]\n",
      "loss: 0.526324  [  368/  728]\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 0.243821  [   16/  728]\n",
      "loss: 0.356045  [  368/  728]\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.208171  [   16/  728]\n",
      "loss: 0.338431  [  368/  728]\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 0.285501  [   16/  728]\n",
      "loss: 0.266699  [  368/  728]\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 0.250049  [   16/  728]\n",
      "loss: 0.397891  [  368/  728]\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 0.252719  [   16/  728]\n",
      "loss: 0.440668  [  368/  728]\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 0.267182  [   16/  728]\n",
      "loss: 0.359720  [  368/  728]\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 0.292783  [   16/  728]\n",
      "loss: 0.379042  [  368/  728]\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 0.237666  [   16/  728]\n",
      "loss: 0.356887  [  368/  728]\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 0.262366  [   16/  728]\n",
      "loss: 0.308751  [  368/  728]\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 0.253051  [   16/  728]\n",
      "loss: 0.324828  [  368/  728]\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 0.202643  [   16/  728]\n",
      "loss: 0.671713  [  368/  728]\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 0.294776  [   16/  728]\n",
      "loss: 0.239991  [  368/  728]\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 0.160143  [   16/  728]\n",
      "loss: 0.340060  [  368/  728]\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 0.244499  [   16/  728]\n",
      "loss: 0.330853  [  368/  728]\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 0.252341  [   16/  728]\n",
      "loss: 0.314981  [  368/  728]\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 0.199019  [   16/  728]\n",
      "loss: 0.436070  [  368/  728]\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.254544  [   16/  728]\n",
      "loss: 0.330245  [  368/  728]\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 0.264325  [   16/  728]\n",
      "loss: 0.351866  [  368/  728]\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 0.198976  [   16/  728]\n",
      "loss: 0.491600  [  368/  728]\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 0.282068  [   16/  728]\n",
      "loss: 0.290819  [  368/  728]\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 0.304796  [   16/  728]\n",
      "loss: 70.120506  [  368/  728]\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 0.250306  [   16/  728]\n",
      "loss: 0.467613  [  368/  728]\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 0.191232  [   16/  728]\n",
      "loss: 0.234938  [  368/  728]\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 0.235676  [   16/  728]\n",
      "loss: 0.397763  [  368/  728]\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 0.292364  [   16/  728]\n",
      "loss: 0.355746  [  368/  728]\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 0.243036  [   16/  728]\n",
      "loss: 0.445175  [  368/  728]\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 0.238740  [   16/  728]\n",
      "loss: 0.363009  [  368/  728]\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.231314  [   16/  728]\n",
      "loss: 0.346464  [  368/  728]\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 0.281730  [   16/  728]\n",
      "loss: 0.349622  [  368/  728]\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 0.305718  [   16/  728]\n",
      "loss: 0.301781  [  368/  728]\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 0.221218  [   16/  728]\n",
      "loss: 0.241182  [  368/  728]\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 0.275922  [   16/  728]\n",
      "loss: 0.393191  [  368/  728]\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 0.230643  [   16/  728]\n",
      "loss: 0.349179  [  368/  728]\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 0.206180  [   16/  728]\n",
      "loss: 0.526047  [  368/  728]\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 0.274437  [   16/  728]\n",
      "loss: 0.360736  [  368/  728]\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 0.269683  [   16/  728]\n",
      "loss: 0.290094  [  368/  728]\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 0.202376  [   16/  728]\n",
      "loss: 0.319525  [  368/  728]\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 0.218490  [   16/  728]\n",
      "loss: 0.484136  [  368/  728]\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 0.197084  [   16/  728]\n",
      "loss: 0.350607  [  368/  728]\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 0.288349  [   16/  728]\n",
      "loss: 0.389138  [  368/  728]\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 0.268579  [   16/  728]\n",
      "loss: 0.388120  [  368/  728]\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 0.249910  [   16/  728]\n",
      "loss: 0.348676  [  368/  728]\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.214073  [   16/  728]\n",
      "loss: 0.450138  [  368/  728]\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 0.219045  [   16/  728]\n",
      "loss: 0.233879  [  368/  728]\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 0.233967  [   16/  728]\n",
      "loss: 0.295959  [  368/  728]\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 0.253997  [   16/  728]\n",
      "loss: 0.304153  [  368/  728]\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 0.218830  [   16/  728]\n",
      "loss: 0.285797  [  368/  728]\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 0.222915  [   16/  728]\n",
      "loss: 0.345717  [  368/  728]\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 0.245292  [   16/  728]\n",
      "loss: 0.290937  [  368/  728]\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 0.308866  [   16/  728]\n",
      "loss: 0.394202  [  368/  728]\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 0.312093  [   16/  728]\n",
      "loss: 0.389189  [  368/  728]\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 0.245026  [   16/  728]\n",
      "loss: 0.529952  [  368/  728]\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 0.210586  [   16/  728]\n",
      "loss: 0.351516  [  368/  728]\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 0.234573  [   16/  728]\n",
      "loss: 0.298724  [  368/  728]\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 0.174465  [   16/  728]\n",
      "loss: 0.410915  [  368/  728]\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 0.250304  [   16/  728]\n",
      "loss: 0.358650  [  368/  728]\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 0.222246  [   16/  728]\n",
      "loss: 0.461191  [  368/  728]\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 0.293833  [   16/  728]\n",
      "loss: 0.297574  [  368/  728]\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 0.243349  [   16/  728]\n",
      "loss: 0.383236  [  368/  728]\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 0.194620  [   16/  728]\n",
      "loss: 0.315025  [  368/  728]\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 0.255822  [   16/  728]\n",
      "loss: 0.388859  [  368/  728]\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 0.180241  [   16/  728]\n",
      "loss: 0.224868  [  368/  728]\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 0.290013  [   16/  728]\n",
      "loss: 0.541848  [  368/  728]\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 0.236666  [   16/  728]\n",
      "loss: 0.437290  [  368/  728]\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 0.240989  [   16/  728]\n",
      "loss: 0.235702  [  368/  728]\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 0.249695  [   16/  728]\n",
      "loss: 0.254885  [  368/  728]\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 0.236340  [   16/  728]\n",
      "loss: 0.326946  [  368/  728]\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 0.206135  [   16/  728]\n",
      "loss: 0.349873  [  368/  728]\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 0.258669  [   16/  728]\n",
      "loss: 0.454757  [  368/  728]\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 0.203468  [   16/  728]\n",
      "loss: 0.378198  [  368/  728]\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 0.321011  [   16/  728]\n",
      "loss: 0.357754  [  368/  728]\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 0.272952  [   16/  728]\n",
      "loss: 0.311533  [  368/  728]\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.219858  [   16/  728]\n",
      "loss: 0.365375  [  368/  728]\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 0.235416  [   16/  728]\n",
      "loss: 0.338859  [  368/  728]\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 0.276622  [   16/  728]\n",
      "loss: 0.173476  [  368/  728]\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 0.278694  [   16/  728]\n",
      "loss: 0.362864  [  368/  728]\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 0.257015  [   16/  728]\n",
      "loss: 0.286743  [  368/  728]\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 0.227274  [   16/  728]\n",
      "loss: 0.412611  [  368/  728]\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 0.206218  [   16/  728]\n",
      "loss: 0.281392  [  368/  728]\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 0.280574  [   16/  728]\n",
      "loss: 0.279239  [  368/  728]\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 0.196923  [   16/  728]\n",
      "loss: 0.204960  [  368/  728]\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 0.276718  [   16/  728]\n",
      "loss: 0.357231  [  368/  728]\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 0.184376  [   16/  728]\n",
      "loss: 0.273763  [  368/  728]\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 0.244446  [   16/  728]\n",
      "loss: 0.254251  [  368/  728]\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 0.157602  [   16/  728]\n",
      "loss: 0.333447  [  368/  728]\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 0.239339  [   16/  728]\n",
      "loss: 0.231772  [  368/  728]\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 0.272600  [   16/  728]\n",
      "loss: 0.518932  [  368/  728]\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 0.308382  [   16/  728]\n",
      "loss: 0.313337  [  368/  728]\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 0.231620  [   16/  728]\n",
      "loss: 0.360430  [  368/  728]\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 0.305326  [   16/  728]\n",
      "loss: 0.288822  [  368/  728]\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 0.229051  [   16/  728]\n",
      "loss: 0.355248  [  368/  728]\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 0.240060  [   16/  728]\n",
      "loss: 0.318377  [  368/  728]\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 0.246695  [   16/  728]\n",
      "loss: 0.324673  [  368/  728]\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 0.197078  [   16/  728]\n",
      "loss: 0.386597  [  368/  728]\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 0.178539  [   16/  728]\n",
      "loss: 0.241615  [  368/  728]\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 0.250245  [   16/  728]\n",
      "loss: 110.976967  [  368/  728]\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 0.192815  [   16/  728]\n",
      "loss: 0.275133  [  368/  728]\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 0.216019  [   16/  728]\n",
      "loss: 0.335346  [  368/  728]\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 0.223786  [   16/  728]\n",
      "loss: 0.330960  [  368/  728]\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 0.218969  [   16/  728]\n",
      "loss: 0.245461  [  368/  728]\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 0.229053  [   16/  728]\n",
      "loss: 0.693884  [  368/  728]\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 0.306180  [   16/  728]\n",
      "loss: 0.229942  [  368/  728]\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 0.237631  [   16/  728]\n",
      "loss: 0.239174  [  368/  728]\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 0.192158  [   16/  728]\n",
      "loss: 0.473104  [  368/  728]\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 0.215932  [   16/  728]\n",
      "loss: 0.277040  [  368/  728]\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 0.170862  [   16/  728]\n",
      "loss: 0.296653  [  368/  728]\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 0.243803  [   16/  728]\n",
      "loss: 0.280702  [  368/  728]\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 0.262468  [   16/  728]\n",
      "loss: 0.308697  [  368/  728]\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 0.225253  [   16/  728]\n",
      "loss: 0.232377  [  368/  728]\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 0.184823  [   16/  728]\n",
      "loss: 0.247574  [  368/  728]\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 0.246621  [   16/  728]\n",
      "loss: 0.271863  [  368/  728]\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 0.260945  [   16/  728]\n",
      "loss: 0.328654  [  368/  728]\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 0.252765  [   16/  728]\n",
      "loss: 0.313253  [  368/  728]\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 0.252406  [   16/  728]\n",
      "loss: 0.339559  [  368/  728]\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 0.237353  [   16/  728]\n",
      "loss: 0.258426  [  368/  728]\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 0.284430  [   16/  728]\n",
      "loss: 0.326589  [  368/  728]\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 0.159473  [   16/  728]\n",
      "loss: 0.299831  [  368/  728]\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 0.177140  [   16/  728]\n",
      "loss: 0.320619  [  368/  728]\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 0.198945  [   16/  728]\n",
      "loss: 0.340548  [  368/  728]\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 0.254349  [   16/  728]\n",
      "loss: 0.307239  [  368/  728]\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 0.292434  [   16/  728]\n",
      "loss: 0.317466  [  368/  728]\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 0.245925  [   16/  728]\n",
      "loss: 0.324550  [  368/  728]\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 0.221129  [   16/  728]\n",
      "loss: 0.499682  [  368/  728]\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 0.247268  [   16/  728]\n",
      "loss: 0.321968  [  368/  728]\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.227771  [   16/  728]\n",
      "loss: 0.261508  [  368/  728]\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.245316  [   16/  728]\n",
      "loss: 0.259280  [  368/  728]\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 0.220732  [   16/  728]\n",
      "loss: 0.369517  [  368/  728]\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 0.162249  [   16/  728]\n",
      "loss: 200.440430  [  368/  728]\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 0.138063  [   16/  728]\n",
      "loss: 0.250922  [  368/  728]\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.268121  [   16/  728]\n",
      "loss: 0.344447  [  368/  728]\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 0.181418  [   16/  728]\n",
      "loss: 0.293886  [  368/  728]\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 0.264360  [   16/  728]\n",
      "loss: 0.399012  [  368/  728]\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 0.233888  [   16/  728]\n",
      "loss: 0.322719  [  368/  728]\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 0.195257  [   16/  728]\n",
      "loss: 0.270845  [  368/  728]\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 0.217097  [   16/  728]\n",
      "loss: 0.244449  [  368/  728]\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 0.194528  [   16/  728]\n",
      "loss: 0.304525  [  368/  728]\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 0.310627  [   16/  728]\n",
      "loss: 0.300119  [  368/  728]\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 0.218216  [   16/  728]\n",
      "loss: 0.321981  [  368/  728]\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.271669  [   16/  728]\n",
      "loss: 0.261894  [  368/  728]\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 0.180516  [   16/  728]\n",
      "loss: 0.220473  [  368/  728]\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 0.223405  [   16/  728]\n",
      "loss: 0.268384  [  368/  728]\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 0.273096  [   16/  728]\n",
      "loss: 0.368220  [  368/  728]\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 0.185413  [   16/  728]\n",
      "loss: 0.200584  [  368/  728]\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 0.238898  [   16/  728]\n",
      "loss: 0.317757  [  368/  728]\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 0.207807  [   16/  728]\n",
      "loss: 0.314544  [  368/  728]\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.276429  [   16/  728]\n",
      "loss: 0.334500  [  368/  728]\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 0.209869  [   16/  728]\n",
      "loss: 0.326414  [  368/  728]\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 0.182072  [   16/  728]\n",
      "loss: 0.365450  [  368/  728]\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 0.233124  [   16/  728]\n",
      "loss: 0.555604  [  368/  728]\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 0.369290  [   16/  728]\n",
      "loss: 0.280504  [  368/  728]\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 0.231648  [   16/  728]\n",
      "loss: 0.265919  [  368/  728]\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 0.265176  [   16/  728]\n",
      "loss: 0.270818  [  368/  728]\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 0.242372  [   16/  728]\n",
      "loss: 0.277376  [  368/  728]\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 0.274201  [   16/  728]\n",
      "loss: 0.234353  [  368/  728]\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 0.172665  [   16/  728]\n",
      "loss: 0.304461  [  368/  728]\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 0.162319  [   16/  728]\n",
      "loss: 0.336117  [  368/  728]\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 0.256347  [   16/  728]\n",
      "loss: 0.490890  [  368/  728]\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.218454  [   16/  728]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|                           | 2/5 [00:38<00:57, 19.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.389707  [  368/  728]\n",
      "Done!\n",
      "Trial 3:\n",
      "-------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 5.407807  [   16/  728]\n",
      "loss: 5.168161  [  368/  728]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 4.651819  [   16/  728]\n",
      "loss: 393.726471  [  368/  728]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.349666  [   16/  728]\n",
      "loss: 689.372253  [  368/  728]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.046422  [   16/  728]\n",
      "loss: 2497.015137  [  368/  728]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.496680  [   16/  728]\n",
      "loss: 2.118964  [  368/  728]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.462994  [   16/  728]\n",
      "loss: 699.776733  [  368/  728]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.341094  [   16/  728]\n",
      "loss: 520.818054  [  368/  728]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.666034  [   16/  728]\n",
      "loss: 1423.583496  [  368/  728]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.160135  [   16/  728]\n",
      "loss: 944.887024  [  368/  728]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.336257  [   16/  728]\n",
      "loss: 970.690491  [  368/  728]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.383969  [   16/  728]\n",
      "loss: 246.266357  [  368/  728]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.147606  [   16/  728]\n",
      "loss: 207.948425  [  368/  728]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.240413  [   16/  728]\n",
      "loss: 779.790710  [  368/  728]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.214457  [   16/  728]\n",
      "loss: 367.756622  [  368/  728]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.989978  [   16/  728]\n",
      "loss: 119.250160  [  368/  728]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.085223  [   16/  728]\n",
      "loss: 1.023410  [  368/  728]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.885648  [   16/  728]\n",
      "loss: 510.615265  [  368/  728]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.291783  [   16/  728]\n",
      "loss: 521.979187  [  368/  728]\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.015754  [   16/  728]\n",
      "loss: 665.268494  [  368/  728]\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.112827  [   16/  728]\n",
      "loss: 94.690239  [  368/  728]\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.667631  [   16/  728]\n",
      "loss: 1.261298  [  368/  728]\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.857780  [   16/  728]\n",
      "loss: 1.644326  [  368/  728]\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.926090  [   16/  728]\n",
      "loss: 1.890526  [  368/  728]\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.575578  [   16/  728]\n",
      "loss: 656.927429  [  368/  728]\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1.005607  [   16/  728]\n",
      "loss: 313.711090  [  368/  728]\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.679337  [   16/  728]\n",
      "loss: 151.274246  [  368/  728]\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 1.026064  [   16/  728]\n",
      "loss: 146.340775  [  368/  728]\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 1.004022  [   16/  728]\n",
      "loss: 0.971943  [  368/  728]\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.759179  [   16/  728]\n",
      "loss: 1.412478  [  368/  728]\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.816245  [   16/  728]\n",
      "loss: 1.779246  [  368/  728]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.983911  [   16/  728]\n",
      "loss: 1.295653  [  368/  728]\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.858130  [   16/  728]\n",
      "loss: 16.582300  [  368/  728]\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.907561  [   16/  728]\n",
      "loss: 1.312327  [  368/  728]\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.889157  [   16/  728]\n",
      "loss: 2.914140  [  368/  728]\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.653773  [   16/  728]\n",
      "loss: 1.022534  [  368/  728]\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.845474  [   16/  728]\n",
      "loss: 17.929585  [  368/  728]\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 1.399728  [   16/  728]\n",
      "loss: 1.680695  [  368/  728]\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.940294  [   16/  728]\n",
      "loss: 2.899602  [  368/  728]\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.977128  [   16/  728]\n",
      "loss: 21.468458  [  368/  728]\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.811979  [   16/  728]\n",
      "loss: 1.279334  [  368/  728]\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.739562  [   16/  728]\n",
      "loss: 1.292670  [  368/  728]\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.927535  [   16/  728]\n",
      "loss: 1.546714  [  368/  728]\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.998825  [   16/  728]\n",
      "loss: 1.306705  [  368/  728]\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.886453  [   16/  728]\n",
      "loss: 1.599938  [  368/  728]\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.856810  [   16/  728]\n",
      "loss: 1.507677  [  368/  728]\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.550820  [   16/  728]\n",
      "loss: 24.364397  [  368/  728]\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.865647  [   16/  728]\n",
      "loss: 1.457900  [  368/  728]\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.951623  [   16/  728]\n",
      "loss: 11.985441  [  368/  728]\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 1.198587  [   16/  728]\n",
      "loss: 3.212027  [  368/  728]\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.836449  [   16/  728]\n",
      "loss: 0.927563  [  368/  728]\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.957923  [   16/  728]\n",
      "loss: 1.354127  [  368/  728]\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.921052  [   16/  728]\n",
      "loss: 203.872513  [  368/  728]\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.626199  [   16/  728]\n",
      "loss: 1.086778  [  368/  728]\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.719969  [   16/  728]\n",
      "loss: 1.129485  [  368/  728]\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.793959  [   16/  728]\n",
      "loss: 1.901566  [  368/  728]\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.836555  [   16/  728]\n",
      "loss: 1.256144  [  368/  728]\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.852171  [   16/  728]\n",
      "loss: 1.379196  [  368/  728]\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.874972  [   16/  728]\n",
      "loss: 1.528185  [  368/  728]\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.542264  [   16/  728]\n",
      "loss: 1.068105  [  368/  728]\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.779440  [   16/  728]\n",
      "loss: 1.150016  [  368/  728]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.612048  [   16/  728]\n",
      "loss: 8.756090  [  368/  728]\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.467315  [   16/  728]\n",
      "loss: 0.682144  [  368/  728]\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 1.014836  [   16/  728]\n",
      "loss: 90.041008  [  368/  728]\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.572249  [   16/  728]\n",
      "loss: 1.087355  [  368/  728]\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.941495  [   16/  728]\n",
      "loss: 0.967905  [  368/  728]\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.367058  [   16/  728]\n",
      "loss: 0.974708  [  368/  728]\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.600283  [   16/  728]\n",
      "loss: 129.811722  [  368/  728]\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.662088  [   16/  728]\n",
      "loss: 32.407108  [  368/  728]\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.952968  [   16/  728]\n",
      "loss: 1.270910  [  368/  728]\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.828991  [   16/  728]\n",
      "loss: 55.935265  [  368/  728]\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.491542  [   16/  728]\n",
      "loss: 174.435486  [  368/  728]\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.464154  [   16/  728]\n",
      "loss: 1.482427  [  368/  728]\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.534582  [   16/  728]\n",
      "loss: 1.095550  [  368/  728]\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.584435  [   16/  728]\n",
      "loss: 23.522856  [  368/  728]\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.705551  [   16/  728]\n",
      "loss: 157.674728  [  368/  728]\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.861590  [   16/  728]\n",
      "loss: 1.105234  [  368/  728]\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.778516  [   16/  728]\n",
      "loss: 65.300888  [  368/  728]\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.664277  [   16/  728]\n",
      "loss: 0.858401  [  368/  728]\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.568223  [   16/  728]\n",
      "loss: 1.131252  [  368/  728]\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.386314  [   16/  728]\n",
      "loss: 21.295321  [  368/  728]\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.725747  [   16/  728]\n",
      "loss: 34.294540  [  368/  728]\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.650249  [   16/  728]\n",
      "loss: 45.551006  [  368/  728]\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.734235  [   16/  728]\n",
      "loss: 1.201271  [  368/  728]\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.644327  [   16/  728]\n",
      "loss: 0.908609  [  368/  728]\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.481950  [   16/  728]\n",
      "loss: 1.129145  [  368/  728]\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.704535  [   16/  728]\n",
      "loss: 1.185407  [  368/  728]\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.503260  [   16/  728]\n",
      "loss: 10.136836  [  368/  728]\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.623209  [   16/  728]\n",
      "loss: 0.984717  [  368/  728]\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.690273  [   16/  728]\n",
      "loss: 19.324291  [  368/  728]\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.556109  [   16/  728]\n",
      "loss: 1.218494  [  368/  728]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.719600  [   16/  728]\n",
      "loss: 0.900273  [  368/  728]\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.565358  [   16/  728]\n",
      "loss: 1.059192  [  368/  728]\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.382686  [   16/  728]\n",
      "loss: 0.776212  [  368/  728]\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.392274  [   16/  728]\n",
      "loss: 0.858197  [  368/  728]\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.470599  [   16/  728]\n",
      "loss: 0.883066  [  368/  728]\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.670287  [   16/  728]\n",
      "loss: 0.924096  [  368/  728]\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.378229  [   16/  728]\n",
      "loss: 0.730828  [  368/  728]\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.502109  [   16/  728]\n",
      "loss: 1.076601  [  368/  728]\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.471879  [   16/  728]\n",
      "loss: 0.781550  [  368/  728]\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.448335  [   16/  728]\n",
      "loss: 0.955599  [  368/  728]\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.541879  [   16/  728]\n",
      "loss: 1.131792  [  368/  728]\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.449396  [   16/  728]\n",
      "loss: 2.763271  [  368/  728]\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.439698  [   16/  728]\n",
      "loss: 10.263124  [  368/  728]\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.484415  [   16/  728]\n",
      "loss: 0.938283  [  368/  728]\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.379600  [   16/  728]\n",
      "loss: 0.867395  [  368/  728]\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.537011  [   16/  728]\n",
      "loss: 1.028561  [  368/  728]\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.557826  [   16/  728]\n",
      "loss: 27.291079  [  368/  728]\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.524453  [   16/  728]\n",
      "loss: 0.913524  [  368/  728]\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.355753  [   16/  728]\n",
      "loss: 0.749222  [  368/  728]\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.572165  [   16/  728]\n",
      "loss: 0.902903  [  368/  728]\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.380105  [   16/  728]\n",
      "loss: 0.801198  [  368/  728]\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.452841  [   16/  728]\n",
      "loss: 0.789838  [  368/  728]\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.433179  [   16/  728]\n",
      "loss: 17.134178  [  368/  728]\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.433013  [   16/  728]\n",
      "loss: 0.732269  [  368/  728]\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.523997  [   16/  728]\n",
      "loss: 0.660007  [  368/  728]\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.356673  [   16/  728]\n",
      "loss: 1.006618  [  368/  728]\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.276191  [   16/  728]\n",
      "loss: 0.513955  [  368/  728]\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.448099  [   16/  728]\n",
      "loss: 0.920548  [  368/  728]\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.492335  [   16/  728]\n",
      "loss: 0.710867  [  368/  728]\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.211884  [   16/  728]\n",
      "loss: 0.878743  [  368/  728]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.412068  [   16/  728]\n",
      "loss: 0.583956  [  368/  728]\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.367622  [   16/  728]\n",
      "loss: 0.584278  [  368/  728]\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.448063  [   16/  728]\n",
      "loss: 0.679902  [  368/  728]\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.411600  [   16/  728]\n",
      "loss: 0.579713  [  368/  728]\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.492343  [   16/  728]\n",
      "loss: 0.669590  [  368/  728]\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.355249  [   16/  728]\n",
      "loss: 30.419273  [  368/  728]\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.306951  [   16/  728]\n",
      "loss: 0.633792  [  368/  728]\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.445392  [   16/  728]\n",
      "loss: 0.780800  [  368/  728]\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.413535  [   16/  728]\n",
      "loss: 0.745999  [  368/  728]\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.550169  [   16/  728]\n",
      "loss: 0.767292  [  368/  728]\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.405825  [   16/  728]\n",
      "loss: 0.679668  [  368/  728]\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.398031  [   16/  728]\n",
      "loss: 0.752313  [  368/  728]\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.374379  [   16/  728]\n",
      "loss: 0.816074  [  368/  728]\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.231067  [   16/  728]\n",
      "loss: 0.826523  [  368/  728]\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.379200  [   16/  728]\n",
      "loss: 0.662384  [  368/  728]\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.293638  [   16/  728]\n",
      "loss: 0.718664  [  368/  728]\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.293999  [   16/  728]\n",
      "loss: 0.892455  [  368/  728]\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.430940  [   16/  728]\n",
      "loss: 0.612711  [  368/  728]\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.381202  [   16/  728]\n",
      "loss: 0.734963  [  368/  728]\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.374277  [   16/  728]\n",
      "loss: 0.625953  [  368/  728]\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.373724  [   16/  728]\n",
      "loss: 0.750461  [  368/  728]\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.365411  [   16/  728]\n",
      "loss: 0.555154  [  368/  728]\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.354431  [   16/  728]\n",
      "loss: 1.052939  [  368/  728]\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.349326  [   16/  728]\n",
      "loss: 0.654711  [  368/  728]\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.390776  [   16/  728]\n",
      "loss: 0.744994  [  368/  728]\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.367377  [   16/  728]\n",
      "loss: 0.567870  [  368/  728]\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.271408  [   16/  728]\n",
      "loss: 0.581173  [  368/  728]\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.294828  [   16/  728]\n",
      "loss: 0.578583  [  368/  728]\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.350009  [   16/  728]\n",
      "loss: 0.498231  [  368/  728]\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.272805  [   16/  728]\n",
      "loss: 0.662372  [  368/  728]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.304781  [   16/  728]\n",
      "loss: 0.580137  [  368/  728]\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.284494  [   16/  728]\n",
      "loss: 0.846087  [  368/  728]\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.326765  [   16/  728]\n",
      "loss: 0.534978  [  368/  728]\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.387273  [   16/  728]\n",
      "loss: 0.542490  [  368/  728]\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.367448  [   16/  728]\n",
      "loss: 0.579060  [  368/  728]\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.379670  [   16/  728]\n",
      "loss: 0.748172  [  368/  728]\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.255660  [   16/  728]\n",
      "loss: 0.560665  [  368/  728]\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.349560  [   16/  728]\n",
      "loss: 0.556180  [  368/  728]\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.264838  [   16/  728]\n",
      "loss: 0.549416  [  368/  728]\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.321040  [   16/  728]\n",
      "loss: 0.519353  [  368/  728]\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.251431  [   16/  728]\n",
      "loss: 0.505550  [  368/  728]\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.295847  [   16/  728]\n",
      "loss: 0.518017  [  368/  728]\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.344541  [   16/  728]\n",
      "loss: 0.475097  [  368/  728]\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.301895  [   16/  728]\n",
      "loss: 0.514589  [  368/  728]\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.183893  [   16/  728]\n",
      "loss: 0.639536  [  368/  728]\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.322491  [   16/  728]\n",
      "loss: 45.577835  [  368/  728]\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.248027  [   16/  728]\n",
      "loss: 0.482930  [  368/  728]\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.311417  [   16/  728]\n",
      "loss: 0.646001  [  368/  728]\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.322949  [   16/  728]\n",
      "loss: 0.469461  [  368/  728]\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.400109  [   16/  728]\n",
      "loss: 0.616732  [  368/  728]\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.287466  [   16/  728]\n",
      "loss: 0.553398  [  368/  728]\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.250715  [   16/  728]\n",
      "loss: 0.459095  [  368/  728]\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.167267  [   16/  728]\n",
      "loss: 0.560240  [  368/  728]\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.300681  [   16/  728]\n",
      "loss: 0.376488  [  368/  728]\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.275239  [   16/  728]\n",
      "loss: 0.754257  [  368/  728]\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.304134  [   16/  728]\n",
      "loss: 0.660071  [  368/  728]\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.233459  [   16/  728]\n",
      "loss: 0.380205  [  368/  728]\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.213832  [   16/  728]\n",
      "loss: 0.509071  [  368/  728]\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.252554  [   16/  728]\n",
      "loss: 11.082449  [  368/  728]\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.239252  [   16/  728]\n",
      "loss: 0.419633  [  368/  728]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.253461  [   16/  728]\n",
      "loss: 0.617367  [  368/  728]\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.261683  [   16/  728]\n",
      "loss: 0.264181  [  368/  728]\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.259074  [   16/  728]\n",
      "loss: 0.647737  [  368/  728]\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.302401  [   16/  728]\n",
      "loss: 0.640085  [  368/  728]\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.274855  [   16/  728]\n",
      "loss: 7.777936  [  368/  728]\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.343861  [   16/  728]\n",
      "loss: 0.477715  [  368/  728]\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.247868  [   16/  728]\n",
      "loss: 0.474149  [  368/  728]\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.274936  [   16/  728]\n",
      "loss: 0.389918  [  368/  728]\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.293295  [   16/  728]\n",
      "loss: 0.501702  [  368/  728]\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.250282  [   16/  728]\n",
      "loss: 0.425383  [  368/  728]\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.224697  [   16/  728]\n",
      "loss: 0.559563  [  368/  728]\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.221260  [   16/  728]\n",
      "loss: 0.438448  [  368/  728]\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.266421  [   16/  728]\n",
      "loss: 0.426605  [  368/  728]\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.253226  [   16/  728]\n",
      "loss: 0.515178  [  368/  728]\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.272465  [   16/  728]\n",
      "loss: 0.462278  [  368/  728]\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.300109  [   16/  728]\n",
      "loss: 0.590129  [  368/  728]\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.263373  [   16/  728]\n",
      "loss: 0.526066  [  368/  728]\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.189856  [   16/  728]\n",
      "loss: 0.399757  [  368/  728]\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.237113  [   16/  728]\n",
      "loss: 0.609283  [  368/  728]\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.259840  [   16/  728]\n",
      "loss: 0.507010  [  368/  728]\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.214975  [   16/  728]\n",
      "loss: 0.361702  [  368/  728]\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.262358  [   16/  728]\n",
      "loss: 0.470132  [  368/  728]\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.200420  [   16/  728]\n",
      "loss: 0.505678  [  368/  728]\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.230386  [   16/  728]\n",
      "loss: 0.367461  [  368/  728]\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.204354  [   16/  728]\n",
      "loss: 0.510960  [  368/  728]\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.240816  [   16/  728]\n",
      "loss: 1.758922  [  368/  728]\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.197096  [   16/  728]\n",
      "loss: 0.428226  [  368/  728]\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.247155  [   16/  728]\n",
      "loss: 0.522167  [  368/  728]\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.294531  [   16/  728]\n",
      "loss: 0.412633  [  368/  728]\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.268201  [   16/  728]\n",
      "loss: 0.439676  [  368/  728]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.239279  [   16/  728]\n",
      "loss: 0.559674  [  368/  728]\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.176893  [   16/  728]\n",
      "loss: 0.300830  [  368/  728]\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.289384  [   16/  728]\n",
      "loss: 0.598620  [  368/  728]\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.241189  [   16/  728]\n",
      "loss: 0.350294  [  368/  728]\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.229914  [   16/  728]\n",
      "loss: 0.429336  [  368/  728]\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.277007  [   16/  728]\n",
      "loss: 0.478680  [  368/  728]\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.231336  [   16/  728]\n",
      "loss: 0.473698  [  368/  728]\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.274662  [   16/  728]\n",
      "loss: 0.430616  [  368/  728]\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.325706  [   16/  728]\n",
      "loss: 0.509719  [  368/  728]\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.335047  [   16/  728]\n",
      "loss: 0.297239  [  368/  728]\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.267698  [   16/  728]\n",
      "loss: 0.439849  [  368/  728]\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.278128  [   16/  728]\n",
      "loss: 0.373539  [  368/  728]\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.197289  [   16/  728]\n",
      "loss: 0.348639  [  368/  728]\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.279647  [   16/  728]\n",
      "loss: 0.695570  [  368/  728]\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.256328  [   16/  728]\n",
      "loss: 0.636164  [  368/  728]\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.242809  [   16/  728]\n",
      "loss: 0.340395  [  368/  728]\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.201871  [   16/  728]\n",
      "loss: 0.377422  [  368/  728]\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.311918  [   16/  728]\n",
      "loss: 0.482905  [  368/  728]\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.320312  [   16/  728]\n",
      "loss: 0.439748  [  368/  728]\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.262430  [   16/  728]\n",
      "loss: 0.436961  [  368/  728]\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.249734  [   16/  728]\n",
      "loss: 0.534310  [  368/  728]\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.219787  [   16/  728]\n",
      "loss: 0.484105  [  368/  728]\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.195478  [   16/  728]\n",
      "loss: 0.491486  [  368/  728]\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.236598  [   16/  728]\n",
      "loss: 0.548607  [  368/  728]\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.215947  [   16/  728]\n",
      "loss: 0.484972  [  368/  728]\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.216760  [   16/  728]\n",
      "loss: 0.349926  [  368/  728]\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.199463  [   16/  728]\n",
      "loss: 0.353637  [  368/  728]\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.199681  [   16/  728]\n",
      "loss: 0.788421  [  368/  728]\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.172295  [   16/  728]\n",
      "loss: 0.509413  [  368/  728]\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.203918  [   16/  728]\n",
      "loss: 0.651825  [  368/  728]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.234068  [   16/  728]\n",
      "loss: 0.435179  [  368/  728]\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.203209  [   16/  728]\n",
      "loss: 0.322585  [  368/  728]\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.252936  [   16/  728]\n",
      "loss: 0.415267  [  368/  728]\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.224220  [   16/  728]\n",
      "loss: 0.531363  [  368/  728]\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.240531  [   16/  728]\n",
      "loss: 0.347158  [  368/  728]\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.220014  [   16/  728]\n",
      "loss: 0.493117  [  368/  728]\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.193751  [   16/  728]\n",
      "loss: 0.525336  [  368/  728]\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.272872  [   16/  728]\n",
      "loss: 0.486197  [  368/  728]\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.374934  [   16/  728]\n",
      "loss: 0.597918  [  368/  728]\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.242771  [   16/  728]\n",
      "loss: 0.302793  [  368/  728]\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.247438  [   16/  728]\n",
      "loss: 0.579090  [  368/  728]\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.229717  [   16/  728]\n",
      "loss: 0.324636  [  368/  728]\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.320143  [   16/  728]\n",
      "loss: 0.327262  [  368/  728]\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.262592  [   16/  728]\n",
      "loss: 0.351864  [  368/  728]\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.222795  [   16/  728]\n",
      "loss: 0.485197  [  368/  728]\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.314715  [   16/  728]\n",
      "loss: 0.650809  [  368/  728]\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.478931  [   16/  728]\n",
      "loss: 0.543010  [  368/  728]\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.288018  [   16/  728]\n",
      "loss: 0.331853  [  368/  728]\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.268310  [   16/  728]\n",
      "loss: 0.481604  [  368/  728]\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.328126  [   16/  728]\n",
      "loss: 0.366405  [  368/  728]\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.305229  [   16/  728]\n",
      "loss: 0.279523  [  368/  728]\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.225540  [   16/  728]\n",
      "loss: 0.385764  [  368/  728]\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.279871  [   16/  728]\n",
      "loss: 0.434667  [  368/  728]\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.263119  [   16/  728]\n",
      "loss: 0.370251  [  368/  728]\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.267090  [   16/  728]\n",
      "loss: 0.285347  [  368/  728]\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.245325  [   16/  728]\n",
      "loss: 0.627589  [  368/  728]\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.140038  [   16/  728]\n",
      "loss: 0.364094  [  368/  728]\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.270843  [   16/  728]\n",
      "loss: 0.382319  [  368/  728]\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.239466  [   16/  728]\n",
      "loss: 0.435345  [  368/  728]\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.229621  [   16/  728]\n",
      "loss: 0.403681  [  368/  728]\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.273920  [   16/  728]\n",
      "loss: 0.313952  [  368/  728]\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.238272  [   16/  728]\n",
      "loss: 0.456850  [  368/  728]\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.248870  [   16/  728]\n",
      "loss: 0.467698  [  368/  728]\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.241500  [   16/  728]\n",
      "loss: 0.409258  [  368/  728]\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.277057  [   16/  728]\n",
      "loss: 0.317047  [  368/  728]\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.285087  [   16/  728]\n",
      "loss: 0.366179  [  368/  728]\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.262487  [   16/  728]\n",
      "loss: 0.350652  [  368/  728]\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.196898  [   16/  728]\n",
      "loss: 0.670640  [  368/  728]\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.255944  [   16/  728]\n",
      "loss: 0.343659  [  368/  728]\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.273037  [   16/  728]\n",
      "loss: 0.391085  [  368/  728]\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.326359  [   16/  728]\n",
      "loss: 0.525411  [  368/  728]\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.269398  [   16/  728]\n",
      "loss: 67.810989  [  368/  728]\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.251946  [   16/  728]\n",
      "loss: 0.519457  [  368/  728]\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.385729  [   16/  728]\n",
      "loss: 0.299101  [  368/  728]\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.287538  [   16/  728]\n",
      "loss: 0.252182  [  368/  728]\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.334111  [   16/  728]\n",
      "loss: 0.526203  [  368/  728]\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.352277  [   16/  728]\n",
      "loss: 0.251479  [  368/  728]\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.303804  [   16/  728]\n",
      "loss: 0.342296  [  368/  728]\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.360711  [   16/  728]\n",
      "loss: 0.269927  [  368/  728]\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.233721  [   16/  728]\n",
      "loss: 0.386697  [  368/  728]\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.263954  [   16/  728]\n",
      "loss: 0.742313  [  368/  728]\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.332517  [   16/  728]\n",
      "loss: 0.393993  [  368/  728]\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.261258  [   16/  728]\n",
      "loss: 0.295783  [  368/  728]\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.248481  [   16/  728]\n",
      "loss: 0.356332  [  368/  728]\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.335705  [   16/  728]\n",
      "loss: 0.609144  [  368/  728]\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.231547  [   16/  728]\n",
      "loss: 0.395823  [  368/  728]\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.362964  [   16/  728]\n",
      "loss: 0.424545  [  368/  728]\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.248938  [   16/  728]\n",
      "loss: 0.343413  [  368/  728]\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.299344  [   16/  728]\n",
      "loss: 0.219932  [  368/  728]\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.313556  [   16/  728]\n",
      "loss: 0.379569  [  368/  728]\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 0.268684  [   16/  728]\n",
      "loss: 0.416062  [  368/  728]\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 0.384819  [   16/  728]\n",
      "loss: 0.501440  [  368/  728]\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 0.201250  [   16/  728]\n",
      "loss: 0.548739  [  368/  728]\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 0.298263  [   16/  728]\n",
      "loss: 0.503256  [  368/  728]\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 0.300121  [   16/  728]\n",
      "loss: 0.316680  [  368/  728]\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 0.209684  [   16/  728]\n",
      "loss: 0.476643  [  368/  728]\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 0.332862  [   16/  728]\n",
      "loss: 0.523569  [  368/  728]\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 0.313975  [   16/  728]\n",
      "loss: 8.558921  [  368/  728]\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 0.370674  [   16/  728]\n",
      "loss: 0.674114  [  368/  728]\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 0.248253  [   16/  728]\n",
      "loss: 0.381850  [  368/  728]\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 0.258868  [   16/  728]\n",
      "loss: 0.381977  [  368/  728]\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 0.260652  [   16/  728]\n",
      "loss: 0.433854  [  368/  728]\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 0.274461  [   16/  728]\n",
      "loss: 0.302420  [  368/  728]\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 0.276475  [   16/  728]\n",
      "loss: 0.459682  [  368/  728]\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 0.217503  [   16/  728]\n",
      "loss: 0.346532  [  368/  728]\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 0.267823  [   16/  728]\n",
      "loss: 0.288848  [  368/  728]\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 0.258718  [   16/  728]\n",
      "loss: 0.276594  [  368/  728]\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 0.226040  [   16/  728]\n",
      "loss: 0.409372  [  368/  728]\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 0.307947  [   16/  728]\n",
      "loss: 0.395618  [  368/  728]\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 0.284251  [   16/  728]\n",
      "loss: 0.286364  [  368/  728]\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 0.260768  [   16/  728]\n",
      "loss: 0.436526  [  368/  728]\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 0.245591  [   16/  728]\n",
      "loss: 0.366421  [  368/  728]\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 0.278546  [   16/  728]\n",
      "loss: 0.282371  [  368/  728]\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 0.297861  [   16/  728]\n",
      "loss: 0.325521  [  368/  728]\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 0.183301  [   16/  728]\n",
      "loss: 0.250943  [  368/  728]\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 0.236855  [   16/  728]\n",
      "loss: 0.223780  [  368/  728]\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 0.334593  [   16/  728]\n",
      "loss: 0.221095  [  368/  728]\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 0.332225  [   16/  728]\n",
      "loss: 0.396086  [  368/  728]\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 0.224056  [   16/  728]\n",
      "loss: 0.409806  [  368/  728]\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 0.167916  [   16/  728]\n",
      "loss: 0.312261  [  368/  728]\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 0.209916  [   16/  728]\n",
      "loss: 0.262348  [  368/  728]\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 0.295803  [   16/  728]\n",
      "loss: 0.436783  [  368/  728]\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 0.252519  [   16/  728]\n",
      "loss: 0.263215  [  368/  728]\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 0.207816  [   16/  728]\n",
      "loss: 0.305148  [  368/  728]\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 0.293218  [   16/  728]\n",
      "loss: 0.422504  [  368/  728]\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 0.206650  [   16/  728]\n",
      "loss: 0.313171  [  368/  728]\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 0.183214  [   16/  728]\n",
      "loss: 0.359544  [  368/  728]\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 0.309810  [   16/  728]\n",
      "loss: 0.457147  [  368/  728]\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 0.195506  [   16/  728]\n",
      "loss: 0.237053  [  368/  728]\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 0.215507  [   16/  728]\n",
      "loss: 0.305053  [  368/  728]\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 0.305687  [   16/  728]\n",
      "loss: 0.389746  [  368/  728]\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 0.233590  [   16/  728]\n",
      "loss: 0.293964  [  368/  728]\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 0.229024  [   16/  728]\n",
      "loss: 0.445526  [  368/  728]\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.340099  [   16/  728]\n",
      "loss: 0.233505  [  368/  728]\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 0.201672  [   16/  728]\n",
      "loss: 0.280936  [  368/  728]\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 0.248695  [   16/  728]\n",
      "loss: 0.526102  [  368/  728]\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 0.284186  [   16/  728]\n",
      "loss: 0.156736  [  368/  728]\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 0.299160  [   16/  728]\n",
      "loss: 0.399430  [  368/  728]\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 0.391209  [   16/  728]\n",
      "loss: 0.273696  [  368/  728]\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 0.234464  [   16/  728]\n",
      "loss: 0.336452  [  368/  728]\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 0.313142  [   16/  728]\n",
      "loss: 0.325550  [  368/  728]\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 0.250907  [   16/  728]\n",
      "loss: 0.284267  [  368/  728]\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 0.316598  [   16/  728]\n",
      "loss: 0.371376  [  368/  728]\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 0.316697  [   16/  728]\n",
      "loss: 0.311396  [  368/  728]\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 0.361657  [   16/  728]\n",
      "loss: 0.480028  [  368/  728]\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 0.297160  [   16/  728]\n",
      "loss: 0.719110  [  368/  728]\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 0.177075  [   16/  728]\n",
      "loss: 0.233054  [  368/  728]\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 0.246967  [   16/  728]\n",
      "loss: 0.279237  [  368/  728]\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.242454  [   16/  728]\n",
      "loss: 0.403557  [  368/  728]\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 0.233332  [   16/  728]\n",
      "loss: 0.333344  [  368/  728]\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 0.245331  [   16/  728]\n",
      "loss: 0.315229  [  368/  728]\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 0.259603  [   16/  728]\n",
      "loss: 0.428890  [  368/  728]\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 0.186260  [   16/  728]\n",
      "loss: 0.283551  [  368/  728]\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 0.208703  [   16/  728]\n",
      "loss: 0.269669  [  368/  728]\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 0.252546  [   16/  728]\n",
      "loss: 0.246717  [  368/  728]\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 0.276073  [   16/  728]\n",
      "loss: 0.225261  [  368/  728]\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 0.246389  [   16/  728]\n",
      "loss: 0.101958  [  368/  728]\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 0.191236  [   16/  728]\n",
      "loss: 0.248426  [  368/  728]\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 0.195332  [   16/  728]\n",
      "loss: 0.218477  [  368/  728]\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.258656  [   16/  728]\n",
      "loss: 0.306102  [  368/  728]\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 0.283721  [   16/  728]\n",
      "loss: 0.309823  [  368/  728]\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 0.269079  [   16/  728]\n",
      "loss: 0.367515  [  368/  728]\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 0.199397  [   16/  728]\n",
      "loss: 0.214926  [  368/  728]\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 0.181885  [   16/  728]\n",
      "loss: 0.286192  [  368/  728]\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 0.313696  [   16/  728]\n",
      "loss: 0.413865  [  368/  728]\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 0.253488  [   16/  728]\n",
      "loss: 121.493736  [  368/  728]\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 0.199471  [   16/  728]\n",
      "loss: 0.250314  [  368/  728]\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 0.279520  [   16/  728]\n",
      "loss: 0.263099  [  368/  728]\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 0.230476  [   16/  728]\n",
      "loss: 0.410850  [  368/  728]\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 0.304895  [   16/  728]\n",
      "loss: 0.318892  [  368/  728]\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 0.279590  [   16/  728]\n",
      "loss: 0.481501  [  368/  728]\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 0.286645  [   16/  728]\n",
      "loss: 0.369253  [  368/  728]\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 0.350955  [   16/  728]\n",
      "loss: 0.273612  [  368/  728]\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 0.206040  [   16/  728]\n",
      "loss: 0.109412  [  368/  728]\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.233218  [   16/  728]\n",
      "loss: 0.335521  [  368/  728]\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 0.182881  [   16/  728]\n",
      "loss: 0.134221  [  368/  728]\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 0.263274  [   16/  728]\n",
      "loss: 0.411402  [  368/  728]\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 0.238829  [   16/  728]\n",
      "loss: 0.474250  [  368/  728]\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 0.252432  [   16/  728]\n",
      "loss: 0.215294  [  368/  728]\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 0.248016  [   16/  728]\n",
      "loss: 0.434783  [  368/  728]\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 0.278038  [   16/  728]\n",
      "loss: 0.441529  [  368/  728]\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 0.276560  [   16/  728]\n",
      "loss: 0.277981  [  368/  728]\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 0.292492  [   16/  728]\n",
      "loss: 0.339580  [  368/  728]\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 0.219207  [   16/  728]\n",
      "loss: 0.311311  [  368/  728]\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 0.281427  [   16/  728]\n",
      "loss: 0.335857  [  368/  728]\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 0.194773  [   16/  728]\n",
      "loss: 0.329335  [  368/  728]\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 0.254039  [   16/  728]\n",
      "loss: 0.286873  [  368/  728]\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 0.250588  [   16/  728]\n",
      "loss: 0.340754  [  368/  728]\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 0.232294  [   16/  728]\n",
      "loss: 0.206327  [  368/  728]\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 0.234110  [   16/  728]\n",
      "loss: 0.272276  [  368/  728]\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 0.269249  [   16/  728]\n",
      "loss: 0.278319  [  368/  728]\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 0.168197  [   16/  728]\n",
      "loss: 0.112947  [  368/  728]\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 0.275080  [   16/  728]\n",
      "loss: 0.308397  [  368/  728]\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 0.278187  [   16/  728]\n",
      "loss: 0.296040  [  368/  728]\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 0.208018  [   16/  728]\n",
      "loss: 0.178753  [  368/  728]\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 0.255133  [   16/  728]\n",
      "loss: 0.346304  [  368/  728]\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 0.173306  [   16/  728]\n",
      "loss: 0.278443  [  368/  728]\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 0.229853  [   16/  728]\n",
      "loss: 0.385102  [  368/  728]\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 0.308130  [   16/  728]\n",
      "loss: 0.264081  [  368/  728]\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 0.307450  [   16/  728]\n",
      "loss: 0.305017  [  368/  728]\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 0.260454  [   16/  728]\n",
      "loss: 0.348882  [  368/  728]\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 0.253273  [   16/  728]\n",
      "loss: 0.313547  [  368/  728]\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 0.270154  [   16/  728]\n",
      "loss: 0.231588  [  368/  728]\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 0.261435  [   16/  728]\n",
      "loss: 0.308400  [  368/  728]\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.268048  [   16/  728]\n",
      "loss: 0.147772  [  368/  728]\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 0.222938  [   16/  728]\n",
      "loss: 0.362181  [  368/  728]\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 0.283211  [   16/  728]\n",
      "loss: 0.252046  [  368/  728]\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 0.181670  [   16/  728]\n",
      "loss: 0.333746  [  368/  728]\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 0.221374  [   16/  728]\n",
      "loss: 0.325348  [  368/  728]\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 0.225815  [   16/  728]\n",
      "loss: 0.496722  [  368/  728]\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 0.246370  [   16/  728]\n",
      "loss: 0.329422  [  368/  728]\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 0.226238  [   16/  728]\n",
      "loss: 0.272942  [  368/  728]\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 0.167784  [   16/  728]\n",
      "loss: 0.222139  [  368/  728]\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 0.190429  [   16/  728]\n",
      "loss: 0.229606  [  368/  728]\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 0.308058  [   16/  728]\n",
      "loss: 0.328702  [  368/  728]\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 0.311717  [   16/  728]\n",
      "loss: 0.222956  [  368/  728]\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 0.278963  [   16/  728]\n",
      "loss: 0.354780  [  368/  728]\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 0.275443  [   16/  728]\n",
      "loss: 0.369386  [  368/  728]\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 0.256755  [   16/  728]\n",
      "loss: 0.434812  [  368/  728]\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 0.209297  [   16/  728]\n",
      "loss: 0.348062  [  368/  728]\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 0.224934  [   16/  728]\n",
      "loss: 0.332003  [  368/  728]\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 0.207754  [   16/  728]\n",
      "loss: 0.295712  [  368/  728]\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 0.193933  [   16/  728]\n",
      "loss: 0.229096  [  368/  728]\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 0.187331  [   16/  728]\n",
      "loss: 0.335272  [  368/  728]\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 0.227620  [   16/  728]\n",
      "loss: 0.331486  [  368/  728]\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 0.188039  [   16/  728]\n",
      "loss: 0.337171  [  368/  728]\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 0.242065  [   16/  728]\n",
      "loss: 0.364174  [  368/  728]\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 0.252645  [   16/  728]\n",
      "loss: 0.201126  [  368/  728]\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 0.304259  [   16/  728]\n",
      "loss: 0.248799  [  368/  728]\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 0.184969  [   16/  728]\n",
      "loss: 0.247072  [  368/  728]\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 0.264023  [   16/  728]\n",
      "loss: 0.270606  [  368/  728]\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 0.180192  [   16/  728]\n",
      "loss: 0.387639  [  368/  728]\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 0.224472  [   16/  728]\n",
      "loss: 0.305790  [  368/  728]\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 0.281299  [   16/  728]\n",
      "loss: 0.243049  [  368/  728]\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 0.203794  [   16/  728]\n",
      "loss: 0.391400  [  368/  728]\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 0.306317  [   16/  728]\n",
      "loss: 0.250261  [  368/  728]\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 0.258669  [   16/  728]\n",
      "loss: 0.162000  [  368/  728]\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 0.278602  [   16/  728]\n",
      "loss: 0.208884  [  368/  728]\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 0.241860  [   16/  728]\n",
      "loss: 0.326121  [  368/  728]\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 0.170456  [   16/  728]\n",
      "loss: 0.600655  [  368/  728]\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 0.246390  [   16/  728]\n",
      "loss: 0.249876  [  368/  728]\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 0.300693  [   16/  728]\n",
      "loss: 0.151064  [  368/  728]\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 0.184983  [   16/  728]\n",
      "loss: 0.537595  [  368/  728]\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 0.170475  [   16/  728]\n",
      "loss: 0.251202  [  368/  728]\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 0.276940  [   16/  728]\n",
      "loss: 0.433311  [  368/  728]\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 0.264709  [   16/  728]\n",
      "loss: 0.232428  [  368/  728]\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 0.280686  [   16/  728]\n",
      "loss: 0.204783  [  368/  728]\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 0.225393  [   16/  728]\n",
      "loss: 0.270860  [  368/  728]\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 0.197251  [   16/  728]\n",
      "loss: 0.327641  [  368/  728]\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 0.272703  [   16/  728]\n",
      "loss: 0.211699  [  368/  728]\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 0.225481  [   16/  728]\n",
      "loss: 0.189547  [  368/  728]\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 0.130975  [   16/  728]\n",
      "loss: 0.153808  [  368/  728]\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 0.259760  [   16/  728]\n",
      "loss: 0.360132  [  368/  728]\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 0.239789  [   16/  728]\n",
      "loss: 0.476223  [  368/  728]\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 0.212740  [   16/  728]\n",
      "loss: 0.297083  [  368/  728]\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 0.285194  [   16/  728]\n",
      "loss: 0.380227  [  368/  728]\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.326562  [   16/  728]\n",
      "loss: 0.294774  [  368/  728]\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.222083  [   16/  728]\n",
      "loss: 0.484708  [  368/  728]\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 0.315640  [   16/  728]\n",
      "loss: 0.374714  [  368/  728]\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 0.286892  [   16/  728]\n",
      "loss: 0.248062  [  368/  728]\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 0.224361  [   16/  728]\n",
      "loss: 0.254625  [  368/  728]\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.188878  [   16/  728]\n",
      "loss: 0.245775  [  368/  728]\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 0.184005  [   16/  728]\n",
      "loss: 0.222307  [  368/  728]\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 0.163197  [   16/  728]\n",
      "loss: 0.223946  [  368/  728]\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 0.254227  [   16/  728]\n",
      "loss: 0.167136  [  368/  728]\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 0.172612  [   16/  728]\n",
      "loss: 0.184943  [  368/  728]\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 0.196946  [   16/  728]\n",
      "loss: 0.216505  [  368/  728]\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 0.245239  [   16/  728]\n",
      "loss: 0.256914  [  368/  728]\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 0.164684  [   16/  728]\n",
      "loss: 0.199986  [  368/  728]\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 0.193741  [   16/  728]\n",
      "loss: 0.413813  [  368/  728]\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.244442  [   16/  728]\n",
      "loss: 0.324201  [  368/  728]\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 0.229409  [   16/  728]\n",
      "loss: 0.254952  [  368/  728]\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 0.212634  [   16/  728]\n",
      "loss: 0.227457  [  368/  728]\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 0.234799  [   16/  728]\n",
      "loss: 0.326306  [  368/  728]\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 0.276234  [   16/  728]\n",
      "loss: 0.223494  [  368/  728]\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 0.284536  [   16/  728]\n",
      "loss: 0.331853  [  368/  728]\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 0.294663  [   16/  728]\n",
      "loss: 0.275723  [  368/  728]\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.184149  [   16/  728]\n",
      "loss: 0.308451  [  368/  728]\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 0.174380  [   16/  728]\n",
      "loss: 0.478906  [  368/  728]\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 0.251621  [   16/  728]\n",
      "loss: 0.521228  [  368/  728]\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 0.245724  [   16/  728]\n",
      "loss: 0.206539  [  368/  728]\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 0.268350  [   16/  728]\n",
      "loss: 0.227858  [  368/  728]\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 0.356670  [   16/  728]\n",
      "loss: 0.284903  [  368/  728]\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 0.233051  [   16/  728]\n",
      "loss: 0.326627  [  368/  728]\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 0.283256  [   16/  728]\n",
      "loss: 0.258624  [  368/  728]\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 0.286935  [   16/  728]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|                  | 3/5 [00:57<00:38, 19.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.204302  [  368/  728]\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 0.257358  [   16/  728]\n",
      "loss: 0.259067  [  368/  728]\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 0.210452  [   16/  728]\n",
      "loss: 0.263939  [  368/  728]\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 0.201757  [   16/  728]\n",
      "loss: 0.360133  [  368/  728]\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.223772  [   16/  728]\n",
      "loss: 0.228195  [  368/  728]\n",
      "Done!\n",
      "Trial 4:\n",
      "-------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 5.088980  [   16/  728]\n",
      "loss: 4548.611816  [  368/  728]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.791866  [   16/  728]\n",
      "loss: 623.543396  [  368/  728]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.063714  [   16/  728]\n",
      "loss: 2362.058594  [  368/  728]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.629905  [   16/  728]\n",
      "loss: 2240.039795  [  368/  728]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.273923  [   16/  728]\n",
      "loss: 2.031538  [  368/  728]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.565661  [   16/  728]\n",
      "loss: 789.001343  [  368/  728]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.561596  [   16/  728]\n",
      "loss: 559.947632  [  368/  728]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.944630  [   16/  728]\n",
      "loss: 1.563386  [  368/  728]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.128834  [   16/  728]\n",
      "loss: 378.808197  [  368/  728]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.040684  [   16/  728]\n",
      "loss: 1304.401001  [  368/  728]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.024120  [   16/  728]\n",
      "loss: 3843.214355  [  368/  728]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.968463  [   16/  728]\n",
      "loss: 1273.321899  [  368/  728]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.210699  [   16/  728]\n",
      "loss: 1275.192017  [  368/  728]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.409708  [   16/  728]\n",
      "loss: 944.544983  [  368/  728]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.909902  [   16/  728]\n",
      "loss: 2.334616  [  368/  728]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.071449  [   16/  728]\n",
      "loss: 1646.404419  [  368/  728]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.063230  [   16/  728]\n",
      "loss: 1139.197021  [  368/  728]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.824002  [   16/  728]\n",
      "loss: 370.823059  [  368/  728]\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.612129  [   16/  728]\n",
      "loss: 901.825073  [  368/  728]\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.232391  [   16/  728]\n",
      "loss: 257.637390  [  368/  728]\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.215008  [   16/  728]\n",
      "loss: 391.246216  [  368/  728]\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1.256112  [   16/  728]\n",
      "loss: 389.514221  [  368/  728]\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.884418  [   16/  728]\n",
      "loss: 381.562988  [  368/  728]\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1.016044  [   16/  728]\n",
      "loss: 1300.655396  [  368/  728]\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.950887  [   16/  728]\n",
      "loss: 21.103228  [  368/  728]\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.551667  [   16/  728]\n",
      "loss: 370.592987  [  368/  728]\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 1.106650  [   16/  728]\n",
      "loss: 1.857474  [  368/  728]\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.890284  [   16/  728]\n",
      "loss: 502.387360  [  368/  728]\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 1.014247  [   16/  728]\n",
      "loss: 557.447266  [  368/  728]\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.618871  [   16/  728]\n",
      "loss: 320.916565  [  368/  728]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.724416  [   16/  728]\n",
      "loss: 189.241760  [  368/  728]\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.889595  [   16/  728]\n",
      "loss: 147.245163  [  368/  728]\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.760297  [   16/  728]\n",
      "loss: 135.831558  [  368/  728]\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.648966  [   16/  728]\n",
      "loss: 1.089897  [  368/  728]\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 1.068535  [   16/  728]\n",
      "loss: 399.407440  [  368/  728]\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.796842  [   16/  728]\n",
      "loss: 306.744019  [  368/  728]\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.608159  [   16/  728]\n",
      "loss: 140.487976  [  368/  728]\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.767858  [   16/  728]\n",
      "loss: 0.958205  [  368/  728]\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.473736  [   16/  728]\n",
      "loss: 69.702110  [  368/  728]\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.797584  [   16/  728]\n",
      "loss: 215.308472  [  368/  728]\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.884645  [   16/  728]\n",
      "loss: 5.062999  [  368/  728]\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.999827  [   16/  728]\n",
      "loss: 1.243486  [  368/  728]\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.679402  [   16/  728]\n",
      "loss: 68.938293  [  368/  728]\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.627908  [   16/  728]\n",
      "loss: 115.543205  [  368/  728]\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.828392  [   16/  728]\n",
      "loss: 1.189860  [  368/  728]\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.615331  [   16/  728]\n",
      "loss: 118.828659  [  368/  728]\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.691976  [   16/  728]\n",
      "loss: 9.692867  [  368/  728]\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.826916  [   16/  728]\n",
      "loss: 243.130096  [  368/  728]\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.550797  [   16/  728]\n",
      "loss: 170.909317  [  368/  728]\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.740221  [   16/  728]\n",
      "loss: 1.371742  [  368/  728]\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.764358  [   16/  728]\n",
      "loss: 0.959093  [  368/  728]\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.615764  [   16/  728]\n",
      "loss: 77.840157  [  368/  728]\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.655526  [   16/  728]\n",
      "loss: 14.909123  [  368/  728]\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.741143  [   16/  728]\n",
      "loss: 104.037766  [  368/  728]\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.597499  [   16/  728]\n",
      "loss: 36.896133  [  368/  728]\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.579572  [   16/  728]\n",
      "loss: 11.699994  [  368/  728]\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.781800  [   16/  728]\n",
      "loss: 1.569099  [  368/  728]\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.708663  [   16/  728]\n",
      "loss: 0.899754  [  368/  728]\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.783422  [   16/  728]\n",
      "loss: 31.360901  [  368/  728]\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.515032  [   16/  728]\n",
      "loss: 14.710589  [  368/  728]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.533912  [   16/  728]\n",
      "loss: 70.347748  [  368/  728]\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.581569  [   16/  728]\n",
      "loss: 41.728565  [  368/  728]\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.498597  [   16/  728]\n",
      "loss: 9.468670  [  368/  728]\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.722721  [   16/  728]\n",
      "loss: 1.103800  [  368/  728]\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.523759  [   16/  728]\n",
      "loss: 1.234423  [  368/  728]\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.629341  [   16/  728]\n",
      "loss: 11.158112  [  368/  728]\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.718489  [   16/  728]\n",
      "loss: 180.823105  [  368/  728]\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.806320  [   16/  728]\n",
      "loss: 16.733126  [  368/  728]\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.823948  [   16/  728]\n",
      "loss: 38.720158  [  368/  728]\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.913935  [   16/  728]\n",
      "loss: 0.832687  [  368/  728]\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.864507  [   16/  728]\n",
      "loss: 5.609587  [  368/  728]\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.655215  [   16/  728]\n",
      "loss: 159.153137  [  368/  728]\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.745605  [   16/  728]\n",
      "loss: 52.344223  [  368/  728]\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.630072  [   16/  728]\n",
      "loss: 9.796001  [  368/  728]\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.720195  [   16/  728]\n",
      "loss: 0.915462  [  368/  728]\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.563580  [   16/  728]\n",
      "loss: 0.759513  [  368/  728]\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.722413  [   16/  728]\n",
      "loss: 3.451640  [  368/  728]\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.733776  [   16/  728]\n",
      "loss: 23.052233  [  368/  728]\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.611793  [   16/  728]\n",
      "loss: 29.843584  [  368/  728]\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.707665  [   16/  728]\n",
      "loss: 0.940703  [  368/  728]\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.553577  [   16/  728]\n",
      "loss: 50.965141  [  368/  728]\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.528837  [   16/  728]\n",
      "loss: 8.987453  [  368/  728]\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.521637  [   16/  728]\n",
      "loss: 2.247211  [  368/  728]\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.522823  [   16/  728]\n",
      "loss: 0.885657  [  368/  728]\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.550184  [   16/  728]\n",
      "loss: 0.926175  [  368/  728]\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.534267  [   16/  728]\n",
      "loss: 15.864605  [  368/  728]\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.586196  [   16/  728]\n",
      "loss: 6.141643  [  368/  728]\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.529366  [   16/  728]\n",
      "loss: 12.919562  [  368/  728]\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.594260  [   16/  728]\n",
      "loss: 0.848765  [  368/  728]\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.458379  [   16/  728]\n",
      "loss: 0.702179  [  368/  728]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.483465  [   16/  728]\n",
      "loss: 0.946480  [  368/  728]\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.519017  [   16/  728]\n",
      "loss: 0.910645  [  368/  728]\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.584705  [   16/  728]\n",
      "loss: 0.883756  [  368/  728]\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.656613  [   16/  728]\n",
      "loss: 0.748287  [  368/  728]\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.435371  [   16/  728]\n",
      "loss: 1.051959  [  368/  728]\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.537450  [   16/  728]\n",
      "loss: 0.622480  [  368/  728]\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.361583  [   16/  728]\n",
      "loss: 0.548154  [  368/  728]\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.378036  [   16/  728]\n",
      "loss: 0.840889  [  368/  728]\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.434902  [   16/  728]\n",
      "loss: 2.835853  [  368/  728]\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.377541  [   16/  728]\n",
      "loss: 0.715026  [  368/  728]\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.337172  [   16/  728]\n",
      "loss: 1.160155  [  368/  728]\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.329265  [   16/  728]\n",
      "loss: 0.862725  [  368/  728]\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.285171  [   16/  728]\n",
      "loss: 0.630557  [  368/  728]\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.426829  [   16/  728]\n",
      "loss: 0.559647  [  368/  728]\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.395914  [   16/  728]\n",
      "loss: 0.570453  [  368/  728]\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.528080  [   16/  728]\n",
      "loss: 0.670815  [  368/  728]\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.321893  [   16/  728]\n",
      "loss: 0.595772  [  368/  728]\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.262839  [   16/  728]\n",
      "loss: 0.598860  [  368/  728]\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.457407  [   16/  728]\n",
      "loss: 0.519616  [  368/  728]\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.515878  [   16/  728]\n",
      "loss: 0.564560  [  368/  728]\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.292093  [   16/  728]\n",
      "loss: 0.793782  [  368/  728]\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.403104  [   16/  728]\n",
      "loss: 0.682594  [  368/  728]\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.409251  [   16/  728]\n",
      "loss: 0.291388  [  368/  728]\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.247202  [   16/  728]\n",
      "loss: 0.714525  [  368/  728]\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.316994  [   16/  728]\n",
      "loss: 0.578334  [  368/  728]\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.430054  [   16/  728]\n",
      "loss: 0.522166  [  368/  728]\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.394108  [   16/  728]\n",
      "loss: 1.159816  [  368/  728]\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.336817  [   16/  728]\n",
      "loss: 0.654056  [  368/  728]\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.453322  [   16/  728]\n",
      "loss: 0.833487  [  368/  728]\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.373453  [   16/  728]\n",
      "loss: 0.842029  [  368/  728]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.406621  [   16/  728]\n",
      "loss: 0.908247  [  368/  728]\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.376929  [   16/  728]\n",
      "loss: 0.895675  [  368/  728]\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.379120  [   16/  728]\n",
      "loss: 0.480600  [  368/  728]\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.366818  [   16/  728]\n",
      "loss: 0.592165  [  368/  728]\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.366479  [   16/  728]\n",
      "loss: 0.582581  [  368/  728]\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.408501  [   16/  728]\n",
      "loss: 0.568855  [  368/  728]\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.303290  [   16/  728]\n",
      "loss: 0.578600  [  368/  728]\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.407908  [   16/  728]\n",
      "loss: 0.583390  [  368/  728]\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.374839  [   16/  728]\n",
      "loss: 0.638578  [  368/  728]\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.480126  [   16/  728]\n",
      "loss: 0.765840  [  368/  728]\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.391837  [   16/  728]\n",
      "loss: 0.554568  [  368/  728]\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.378823  [   16/  728]\n",
      "loss: 0.465625  [  368/  728]\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.353463  [   16/  728]\n",
      "loss: 0.466589  [  368/  728]\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.262786  [   16/  728]\n",
      "loss: 0.404167  [  368/  728]\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.315941  [   16/  728]\n",
      "loss: 0.651789  [  368/  728]\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.427751  [   16/  728]\n",
      "loss: 0.602364  [  368/  728]\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.355236  [   16/  728]\n",
      "loss: 0.510297  [  368/  728]\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.281601  [   16/  728]\n",
      "loss: 0.398723  [  368/  728]\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.269668  [   16/  728]\n",
      "loss: 0.343835  [  368/  728]\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.403403  [   16/  728]\n",
      "loss: 0.601557  [  368/  728]\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.237648  [   16/  728]\n",
      "loss: 0.270484  [  368/  728]\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.213085  [   16/  728]\n",
      "loss: 0.434941  [  368/  728]\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.305595  [   16/  728]\n",
      "loss: 0.597698  [  368/  728]\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.318052  [   16/  728]\n",
      "loss: 0.679620  [  368/  728]\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.351135  [   16/  728]\n",
      "loss: 0.509523  [  368/  728]\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.243466  [   16/  728]\n",
      "loss: 0.441941  [  368/  728]\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.402140  [   16/  728]\n",
      "loss: 0.570818  [  368/  728]\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.418821  [   16/  728]\n",
      "loss: 0.426273  [  368/  728]\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.320722  [   16/  728]\n",
      "loss: 0.307612  [  368/  728]\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.300183  [   16/  728]\n",
      "loss: 0.280121  [  368/  728]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.299335  [   16/  728]\n",
      "loss: 0.775404  [  368/  728]\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.364736  [   16/  728]\n",
      "loss: 0.612242  [  368/  728]\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.359943  [   16/  728]\n",
      "loss: 0.403414  [  368/  728]\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.373399  [   16/  728]\n",
      "loss: 0.291923  [  368/  728]\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.399916  [   16/  728]\n",
      "loss: 0.447708  [  368/  728]\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.446773  [   16/  728]\n",
      "loss: 0.478016  [  368/  728]\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.268289  [   16/  728]\n",
      "loss: 0.838543  [  368/  728]\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.396762  [   16/  728]\n",
      "loss: 0.556511  [  368/  728]\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.362563  [   16/  728]\n",
      "loss: 0.415482  [  368/  728]\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.291252  [   16/  728]\n",
      "loss: 0.367344  [  368/  728]\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.392652  [   16/  728]\n",
      "loss: 0.474887  [  368/  728]\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.271744  [   16/  728]\n",
      "loss: 0.406885  [  368/  728]\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.275670  [   16/  728]\n",
      "loss: 0.307826  [  368/  728]\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.311202  [   16/  728]\n",
      "loss: 0.437724  [  368/  728]\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.373648  [   16/  728]\n",
      "loss: 0.519337  [  368/  728]\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.280501  [   16/  728]\n",
      "loss: 0.825183  [  368/  728]\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.271054  [   16/  728]\n",
      "loss: 0.461859  [  368/  728]\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.362166  [   16/  728]\n",
      "loss: 0.464472  [  368/  728]\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.295650  [   16/  728]\n",
      "loss: 0.332202  [  368/  728]\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.287295  [   16/  728]\n",
      "loss: 0.302957  [  368/  728]\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.364675  [   16/  728]\n",
      "loss: 0.611517  [  368/  728]\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.359959  [   16/  728]\n",
      "loss: 0.264012  [  368/  728]\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.242973  [   16/  728]\n",
      "loss: 0.578498  [  368/  728]\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.227082  [   16/  728]\n",
      "loss: 0.388954  [  368/  728]\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.321247  [   16/  728]\n",
      "loss: 0.408067  [  368/  728]\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.302228  [   16/  728]\n",
      "loss: 0.427738  [  368/  728]\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.181807  [   16/  728]\n",
      "loss: 0.361264  [  368/  728]\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.406046  [   16/  728]\n",
      "loss: 0.446183  [  368/  728]\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.252472  [   16/  728]\n",
      "loss: 0.443010  [  368/  728]\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.227083  [   16/  728]\n",
      "loss: 0.525133  [  368/  728]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.375646  [   16/  728]\n",
      "loss: 0.184928  [  368/  728]\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.300462  [   16/  728]\n",
      "loss: 0.451317  [  368/  728]\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.278680  [   16/  728]\n",
      "loss: 0.389567  [  368/  728]\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.223717  [   16/  728]\n",
      "loss: 0.333472  [  368/  728]\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.224702  [   16/  728]\n",
      "loss: 0.764220  [  368/  728]\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.336389  [   16/  728]\n",
      "loss: 0.547078  [  368/  728]\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.220773  [   16/  728]\n",
      "loss: 0.627592  [  368/  728]\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.306735  [   16/  728]\n",
      "loss: 0.578786  [  368/  728]\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.338893  [   16/  728]\n",
      "loss: 0.252567  [  368/  728]\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.259134  [   16/  728]\n",
      "loss: 0.393917  [  368/  728]\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.280276  [   16/  728]\n",
      "loss: 0.451155  [  368/  728]\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.200674  [   16/  728]\n",
      "loss: 0.626764  [  368/  728]\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.389916  [   16/  728]\n",
      "loss: 0.912991  [  368/  728]\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.443671  [   16/  728]\n",
      "loss: 0.354854  [  368/  728]\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.246412  [   16/  728]\n",
      "loss: 0.300852  [  368/  728]\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.231149  [   16/  728]\n",
      "loss: 0.390876  [  368/  728]\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.250514  [   16/  728]\n",
      "loss: 0.472678  [  368/  728]\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.261455  [   16/  728]\n",
      "loss: 0.387355  [  368/  728]\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.303516  [   16/  728]\n",
      "loss: 0.730869  [  368/  728]\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.229142  [   16/  728]\n",
      "loss: 0.388991  [  368/  728]\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.244257  [   16/  728]\n",
      "loss: 0.257400  [  368/  728]\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.266049  [   16/  728]\n",
      "loss: 0.515104  [  368/  728]\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.260349  [   16/  728]\n",
      "loss: 0.301678  [  368/  728]\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.286236  [   16/  728]\n",
      "loss: 0.387318  [  368/  728]\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.317413  [   16/  728]\n",
      "loss: 0.429236  [  368/  728]\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.259595  [   16/  728]\n",
      "loss: 0.292022  [  368/  728]\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.228994  [   16/  728]\n",
      "loss: 0.365478  [  368/  728]\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.347157  [   16/  728]\n",
      "loss: 0.345197  [  368/  728]\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.282363  [   16/  728]\n",
      "loss: 0.218244  [  368/  728]\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.318634  [   16/  728]\n",
      "loss: 0.453816  [  368/  728]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.375514  [   16/  728]\n",
      "loss: 0.478391  [  368/  728]\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.308583  [   16/  728]\n",
      "loss: 0.435304  [  368/  728]\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.255405  [   16/  728]\n",
      "loss: 0.564108  [  368/  728]\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.282035  [   16/  728]\n",
      "loss: 0.402073  [  368/  728]\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.313902  [   16/  728]\n",
      "loss: 0.477155  [  368/  728]\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.395588  [   16/  728]\n",
      "loss: 0.380930  [  368/  728]\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.198514  [   16/  728]\n",
      "loss: 0.468131  [  368/  728]\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.299015  [   16/  728]\n",
      "loss: 0.412752  [  368/  728]\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.316278  [   16/  728]\n",
      "loss: 0.513258  [  368/  728]\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.294532  [   16/  728]\n",
      "loss: 0.373357  [  368/  728]\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.265371  [   16/  728]\n",
      "loss: 0.286085  [  368/  728]\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.268855  [   16/  728]\n",
      "loss: 0.571473  [  368/  728]\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.284384  [   16/  728]\n",
      "loss: 0.269305  [  368/  728]\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.283786  [   16/  728]\n",
      "loss: 0.378279  [  368/  728]\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.258616  [   16/  728]\n",
      "loss: 0.548584  [  368/  728]\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.280349  [   16/  728]\n",
      "loss: 0.176578  [  368/  728]\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.291390  [   16/  728]\n",
      "loss: 0.393558  [  368/  728]\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.254936  [   16/  728]\n",
      "loss: 0.167871  [  368/  728]\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.357722  [   16/  728]\n",
      "loss: 0.559908  [  368/  728]\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.235857  [   16/  728]\n",
      "loss: 0.394528  [  368/  728]\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.308452  [   16/  728]\n",
      "loss: 0.389543  [  368/  728]\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.264187  [   16/  728]\n",
      "loss: 0.343115  [  368/  728]\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.246943  [   16/  728]\n",
      "loss: 0.440652  [  368/  728]\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.202643  [   16/  728]\n",
      "loss: 0.239206  [  368/  728]\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.247450  [   16/  728]\n",
      "loss: 0.356022  [  368/  728]\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.248112  [   16/  728]\n",
      "loss: 0.388233  [  368/  728]\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.285957  [   16/  728]\n",
      "loss: 0.609871  [  368/  728]\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.273470  [   16/  728]\n",
      "loss: 0.636057  [  368/  728]\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.335089  [   16/  728]\n",
      "loss: 0.525930  [  368/  728]\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.299691  [   16/  728]\n",
      "loss: 0.348725  [  368/  728]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.285572  [   16/  728]\n",
      "loss: 0.340785  [  368/  728]\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.248611  [   16/  728]\n",
      "loss: 0.388212  [  368/  728]\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.342241  [   16/  728]\n",
      "loss: 0.252245  [  368/  728]\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.269244  [   16/  728]\n",
      "loss: 0.330348  [  368/  728]\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.208572  [   16/  728]\n",
      "loss: 0.400330  [  368/  728]\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.306432  [   16/  728]\n",
      "loss: 0.316865  [  368/  728]\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.323258  [   16/  728]\n",
      "loss: 0.212412  [  368/  728]\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.304831  [   16/  728]\n",
      "loss: 0.290642  [  368/  728]\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.186304  [   16/  728]\n",
      "loss: 0.539379  [  368/  728]\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.395743  [   16/  728]\n",
      "loss: 0.180366  [  368/  728]\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.245132  [   16/  728]\n",
      "loss: 0.311056  [  368/  728]\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.327543  [   16/  728]\n",
      "loss: 0.278089  [  368/  728]\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.190481  [   16/  728]\n",
      "loss: 0.263833  [  368/  728]\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.254475  [   16/  728]\n",
      "loss: 0.485117  [  368/  728]\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.330259  [   16/  728]\n",
      "loss: 0.477153  [  368/  728]\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.189257  [   16/  728]\n",
      "loss: 0.494352  [  368/  728]\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.274786  [   16/  728]\n",
      "loss: 0.360988  [  368/  728]\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.344166  [   16/  728]\n",
      "loss: 0.210276  [  368/  728]\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.367227  [   16/  728]\n",
      "loss: 0.185438  [  368/  728]\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.300423  [   16/  728]\n",
      "loss: 0.695632  [  368/  728]\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.317877  [   16/  728]\n",
      "loss: 0.228166  [  368/  728]\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.338464  [   16/  728]\n",
      "loss: 0.287369  [  368/  728]\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.330821  [   16/  728]\n",
      "loss: 0.369219  [  368/  728]\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.294736  [   16/  728]\n",
      "loss: 0.320249  [  368/  728]\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.229646  [   16/  728]\n",
      "loss: 0.292661  [  368/  728]\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.326123  [   16/  728]\n",
      "loss: 0.368632  [  368/  728]\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.277162  [   16/  728]\n",
      "loss: 0.409557  [  368/  728]\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.258962  [   16/  728]\n",
      "loss: 0.439422  [  368/  728]\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.325303  [   16/  728]\n",
      "loss: 0.324449  [  368/  728]\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.267099  [   16/  728]\n",
      "loss: 0.226548  [  368/  728]\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.226313  [   16/  728]\n",
      "loss: 0.482257  [  368/  728]\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.281508  [   16/  728]\n",
      "loss: 0.253587  [  368/  728]\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.252938  [   16/  728]\n",
      "loss: 0.286599  [  368/  728]\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.299747  [   16/  728]\n",
      "loss: 0.490278  [  368/  728]\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.348851  [   16/  728]\n",
      "loss: 0.158684  [  368/  728]\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.190448  [   16/  728]\n",
      "loss: 0.306558  [  368/  728]\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.294021  [   16/  728]\n",
      "loss: 0.339009  [  368/  728]\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.268224  [   16/  728]\n",
      "loss: 0.154156  [  368/  728]\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.314664  [   16/  728]\n",
      "loss: 0.197747  [  368/  728]\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.262685  [   16/  728]\n",
      "loss: 0.318857  [  368/  728]\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.275171  [   16/  728]\n",
      "loss: 0.303779  [  368/  728]\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.314919  [   16/  728]\n",
      "loss: 0.266749  [  368/  728]\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.298225  [   16/  728]\n",
      "loss: 0.241411  [  368/  728]\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.243595  [   16/  728]\n",
      "loss: 0.347757  [  368/  728]\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.243771  [   16/  728]\n",
      "loss: 0.270602  [  368/  728]\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.247503  [   16/  728]\n",
      "loss: 0.396243  [  368/  728]\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.269675  [   16/  728]\n",
      "loss: 0.494675  [  368/  728]\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.214645  [   16/  728]\n",
      "loss: 0.269572  [  368/  728]\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.190090  [   16/  728]\n",
      "loss: 0.429537  [  368/  728]\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.212659  [   16/  728]\n",
      "loss: 0.421558  [  368/  728]\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.302612  [   16/  728]\n",
      "loss: 0.289972  [  368/  728]\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.269022  [   16/  728]\n",
      "loss: 0.522012  [  368/  728]\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.241570  [   16/  728]\n",
      "loss: 0.324239  [  368/  728]\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.242507  [   16/  728]\n",
      "loss: 0.151973  [  368/  728]\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.258147  [   16/  728]\n",
      "loss: 0.310616  [  368/  728]\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.223870  [   16/  728]\n",
      "loss: 0.123616  [  368/  728]\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.259998  [   16/  728]\n",
      "loss: 0.281086  [  368/  728]\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.243489  [   16/  728]\n",
      "loss: 0.258820  [  368/  728]\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.236197  [   16/  728]\n",
      "loss: 0.327878  [  368/  728]\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.203675  [   16/  728]\n",
      "loss: 0.324371  [  368/  728]\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 0.210978  [   16/  728]\n",
      "loss: 0.323094  [  368/  728]\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 0.295147  [   16/  728]\n",
      "loss: 0.207689  [  368/  728]\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 0.250921  [   16/  728]\n",
      "loss: 0.202721  [  368/  728]\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 0.272193  [   16/  728]\n",
      "loss: 0.244231  [  368/  728]\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 0.290145  [   16/  728]\n",
      "loss: 0.460401  [  368/  728]\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 0.189942  [   16/  728]\n",
      "loss: 0.164682  [  368/  728]\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 0.312932  [   16/  728]\n",
      "loss: 0.420058  [  368/  728]\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 0.236232  [   16/  728]\n",
      "loss: 0.145460  [  368/  728]\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 0.313491  [   16/  728]\n",
      "loss: 0.462369  [  368/  728]\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 0.263357  [   16/  728]\n",
      "loss: 0.473769  [  368/  728]\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 0.230186  [   16/  728]\n",
      "loss: 0.500052  [  368/  728]\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 0.305078  [   16/  728]\n",
      "loss: 0.212463  [  368/  728]\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 0.192327  [   16/  728]\n",
      "loss: 0.262926  [  368/  728]\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 0.211596  [   16/  728]\n",
      "loss: 0.289923  [  368/  728]\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 0.159132  [   16/  728]\n",
      "loss: 0.458809  [  368/  728]\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 0.189394  [   16/  728]\n",
      "loss: 0.162409  [  368/  728]\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 0.243391  [   16/  728]\n",
      "loss: 0.224391  [  368/  728]\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 0.310074  [   16/  728]\n",
      "loss: 0.309641  [  368/  728]\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 0.292834  [   16/  728]\n",
      "loss: 0.249628  [  368/  728]\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 0.339985  [   16/  728]\n",
      "loss: 0.618828  [  368/  728]\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 0.210932  [   16/  728]\n",
      "loss: 0.232862  [  368/  728]\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 0.308112  [   16/  728]\n",
      "loss: 0.698815  [  368/  728]\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 0.231487  [   16/  728]\n",
      "loss: 0.333989  [  368/  728]\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 0.318047  [   16/  728]\n",
      "loss: 0.173924  [  368/  728]\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 0.277678  [   16/  728]\n",
      "loss: 0.369844  [  368/  728]\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 0.181530  [   16/  728]\n",
      "loss: 0.405537  [  368/  728]\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 0.266410  [   16/  728]\n",
      "loss: 0.062863  [  368/  728]\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 0.245523  [   16/  728]\n",
      "loss: 0.249619  [  368/  728]\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 0.225079  [   16/  728]\n",
      "loss: 0.410618  [  368/  728]\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 0.272977  [   16/  728]\n",
      "loss: 0.277907  [  368/  728]\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 0.231346  [   16/  728]\n",
      "loss: 0.321227  [  368/  728]\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 0.162112  [   16/  728]\n",
      "loss: 0.291899  [  368/  728]\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 0.268623  [   16/  728]\n",
      "loss: 0.387484  [  368/  728]\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 0.265016  [   16/  728]\n",
      "loss: 0.245295  [  368/  728]\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 0.265612  [   16/  728]\n",
      "loss: 0.314337  [  368/  728]\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 0.194931  [   16/  728]\n",
      "loss: 0.208051  [  368/  728]\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 0.264897  [   16/  728]\n",
      "loss: 0.434701  [  368/  728]\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 0.291347  [   16/  728]\n",
      "loss: 0.239071  [  368/  728]\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 0.353372  [   16/  728]\n",
      "loss: 0.361198  [  368/  728]\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 0.262392  [   16/  728]\n",
      "loss: 0.247350  [  368/  728]\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 0.198734  [   16/  728]\n",
      "loss: 0.397933  [  368/  728]\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 0.252269  [   16/  728]\n",
      "loss: 0.372907  [  368/  728]\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 0.261377  [   16/  728]\n",
      "loss: 0.351046  [  368/  728]\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.228390  [   16/  728]\n",
      "loss: 0.374461  [  368/  728]\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 0.300890  [   16/  728]\n",
      "loss: 0.252844  [  368/  728]\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 0.229011  [   16/  728]\n",
      "loss: 0.231097  [  368/  728]\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 0.272719  [   16/  728]\n",
      "loss: 0.357351  [  368/  728]\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 0.226359  [   16/  728]\n",
      "loss: 3.431068  [  368/  728]\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 0.169821  [   16/  728]\n",
      "loss: 0.218650  [  368/  728]\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 0.280854  [   16/  728]\n",
      "loss: 0.408140  [  368/  728]\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 0.187735  [   16/  728]\n",
      "loss: 0.308577  [  368/  728]\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 0.310222  [   16/  728]\n",
      "loss: 0.500995  [  368/  728]\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 0.217145  [   16/  728]\n",
      "loss: 0.175246  [  368/  728]\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 0.190663  [   16/  728]\n",
      "loss: 0.343495  [  368/  728]\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 0.279644  [   16/  728]\n",
      "loss: 0.222151  [  368/  728]\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 0.203829  [   16/  728]\n",
      "loss: 0.322465  [  368/  728]\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 0.245547  [   16/  728]\n",
      "loss: 0.218472  [  368/  728]\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 0.309211  [   16/  728]\n",
      "loss: 0.347630  [  368/  728]\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.202890  [   16/  728]\n",
      "loss: 0.397945  [  368/  728]\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 0.293190  [   16/  728]\n",
      "loss: 0.165022  [  368/  728]\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 0.161373  [   16/  728]\n",
      "loss: 2.752568  [  368/  728]\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 0.249768  [   16/  728]\n",
      "loss: 0.266331  [  368/  728]\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 0.242743  [   16/  728]\n",
      "loss: 0.361326  [  368/  728]\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 0.214380  [   16/  728]\n",
      "loss: 0.438012  [  368/  728]\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 0.244403  [   16/  728]\n",
      "loss: 0.228629  [  368/  728]\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 0.195259  [   16/  728]\n",
      "loss: 0.190088  [  368/  728]\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 0.258606  [   16/  728]\n",
      "loss: 0.334336  [  368/  728]\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 0.253214  [   16/  728]\n",
      "loss: 0.239825  [  368/  728]\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 0.237497  [   16/  728]\n",
      "loss: 0.367424  [  368/  728]\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.199193  [   16/  728]\n",
      "loss: 0.297227  [  368/  728]\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 0.151414  [   16/  728]\n",
      "loss: 0.178655  [  368/  728]\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 0.257031  [   16/  728]\n",
      "loss: 0.228585  [  368/  728]\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 0.305605  [   16/  728]\n",
      "loss: 0.283086  [  368/  728]\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 0.296591  [   16/  728]\n",
      "loss: 0.371840  [  368/  728]\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 0.186408  [   16/  728]\n",
      "loss: 0.280519  [  368/  728]\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 0.244329  [   16/  728]\n",
      "loss: 0.203444  [  368/  728]\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 0.351152  [   16/  728]\n",
      "loss: 0.262758  [  368/  728]\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 0.293237  [   16/  728]\n",
      "loss: 0.208858  [  368/  728]\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 0.289363  [   16/  728]\n",
      "loss: 0.329927  [  368/  728]\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 0.279732  [   16/  728]\n",
      "loss: 0.330212  [  368/  728]\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 0.269432  [   16/  728]\n",
      "loss: 0.363305  [  368/  728]\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 0.262200  [   16/  728]\n",
      "loss: 0.176962  [  368/  728]\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 0.248772  [   16/  728]\n",
      "loss: 0.374880  [  368/  728]\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 0.292348  [   16/  728]\n",
      "loss: 0.221889  [  368/  728]\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.258778  [   16/  728]\n",
      "loss: 0.259906  [  368/  728]\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 0.179884  [   16/  728]\n",
      "loss: 0.393751  [  368/  728]\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 0.213778  [   16/  728]\n",
      "loss: 0.192107  [  368/  728]\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 0.174433  [   16/  728]\n",
      "loss: 0.155340  [  368/  728]\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 0.268299  [   16/  728]\n",
      "loss: 0.252205  [  368/  728]\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 0.231321  [   16/  728]\n",
      "loss: 0.293484  [  368/  728]\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 0.238812  [   16/  728]\n",
      "loss: 0.403820  [  368/  728]\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 0.228138  [   16/  728]\n",
      "loss: 0.330512  [  368/  728]\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 0.279195  [   16/  728]\n",
      "loss: 0.291822  [  368/  728]\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 0.218413  [   16/  728]\n",
      "loss: 0.344806  [  368/  728]\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 0.288428  [   16/  728]\n",
      "loss: 0.177752  [  368/  728]\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 0.228887  [   16/  728]\n",
      "loss: 0.272114  [  368/  728]\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 0.305045  [   16/  728]\n",
      "loss: 0.327547  [  368/  728]\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 0.230917  [   16/  728]\n",
      "loss: 0.322478  [  368/  728]\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 0.247402  [   16/  728]\n",
      "loss: 0.138358  [  368/  728]\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 0.227570  [   16/  728]\n",
      "loss: 0.164107  [  368/  728]\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 0.307853  [   16/  728]\n",
      "loss: 0.360706  [  368/  728]\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 0.187395  [   16/  728]\n",
      "loss: 0.246941  [  368/  728]\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 0.265737  [   16/  728]\n",
      "loss: 0.267012  [  368/  728]\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 0.194599  [   16/  728]\n",
      "loss: 0.155983  [  368/  728]\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 0.175238  [   16/  728]\n",
      "loss: 0.339756  [  368/  728]\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 0.179869  [   16/  728]\n",
      "loss: 0.180520  [  368/  728]\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 0.283335  [   16/  728]\n",
      "loss: 0.270410  [  368/  728]\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 0.268841  [   16/  728]\n",
      "loss: 0.235342  [  368/  728]\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 0.270182  [   16/  728]\n",
      "loss: 0.378767  [  368/  728]\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 0.286151  [   16/  728]\n",
      "loss: 0.438142  [  368/  728]\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 0.251023  [   16/  728]\n",
      "loss: 0.143735  [  368/  728]\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 0.206505  [   16/  728]\n",
      "loss: 0.279784  [  368/  728]\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 0.248206  [   16/  728]\n",
      "loss: 0.203501  [  368/  728]\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 0.165614  [   16/  728]\n",
      "loss: 0.115893  [  368/  728]\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.235223  [   16/  728]\n",
      "loss: 0.277701  [  368/  728]\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 0.225429  [   16/  728]\n",
      "loss: 0.253164  [  368/  728]\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 0.361174  [   16/  728]\n",
      "loss: 0.273421  [  368/  728]\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 0.269028  [   16/  728]\n",
      "loss: 0.237815  [  368/  728]\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 0.231074  [   16/  728]\n",
      "loss: 0.360470  [  368/  728]\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 0.141943  [   16/  728]\n",
      "loss: 0.183621  [  368/  728]\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 0.263597  [   16/  728]\n",
      "loss: 0.371440  [  368/  728]\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 0.273917  [   16/  728]\n",
      "loss: 0.181018  [  368/  728]\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 0.250063  [   16/  728]\n",
      "loss: 0.474354  [  368/  728]\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 0.221104  [   16/  728]\n",
      "loss: 0.194206  [  368/  728]\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 0.228485  [   16/  728]\n",
      "loss: 0.349556  [  368/  728]\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 0.202584  [   16/  728]\n",
      "loss: 0.252150  [  368/  728]\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 0.241906  [   16/  728]\n",
      "loss: 0.209540  [  368/  728]\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 0.260492  [   16/  728]\n",
      "loss: 0.241445  [  368/  728]\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 0.206874  [   16/  728]\n",
      "loss: 0.141131  [  368/  728]\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 0.283133  [   16/  728]\n",
      "loss: 0.219815  [  368/  728]\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 0.224997  [   16/  728]\n",
      "loss: 0.209697  [  368/  728]\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 0.237476  [   16/  728]\n",
      "loss: 0.326158  [  368/  728]\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 0.219579  [   16/  728]\n",
      "loss: 0.295839  [  368/  728]\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 0.278857  [   16/  728]\n",
      "loss: 0.227066  [  368/  728]\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 0.255239  [   16/  728]\n",
      "loss: 0.264364  [  368/  728]\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 0.217249  [   16/  728]\n",
      "loss: 0.147753  [  368/  728]\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 0.236649  [   16/  728]\n",
      "loss: 0.343316  [  368/  728]\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 0.201957  [   16/  728]\n",
      "loss: 0.341722  [  368/  728]\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 0.223354  [   16/  728]\n",
      "loss: 0.284416  [  368/  728]\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 0.236961  [   16/  728]\n",
      "loss: 0.234560  [  368/  728]\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 0.290578  [   16/  728]\n",
      "loss: 0.420630  [  368/  728]\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 0.239824  [   16/  728]\n",
      "loss: 0.172214  [  368/  728]\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 0.234104  [   16/  728]\n",
      "loss: 0.189397  [  368/  728]\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 0.246299  [   16/  728]\n",
      "loss: 0.250521  [  368/  728]\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 0.232421  [   16/  728]\n",
      "loss: 0.228376  [  368/  728]\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 0.155643  [   16/  728]\n",
      "loss: 0.346934  [  368/  728]\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 0.213125  [   16/  728]\n",
      "loss: 0.230848  [  368/  728]\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 0.177152  [   16/  728]\n",
      "loss: 0.215355  [  368/  728]\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 0.238936  [   16/  728]\n",
      "loss: 0.165352  [  368/  728]\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 0.330197  [   16/  728]\n",
      "loss: 0.222529  [  368/  728]\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 0.228178  [   16/  728]\n",
      "loss: 0.134552  [  368/  728]\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 0.223577  [   16/  728]\n",
      "loss: 0.536997  [  368/  728]\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 0.266237  [   16/  728]\n",
      "loss: 0.107604  [  368/  728]\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 0.220746  [   16/  728]\n",
      "loss: 0.343409  [  368/  728]\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 0.267032  [   16/  728]\n",
      "loss: 0.258494  [  368/  728]\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 0.197790  [   16/  728]\n",
      "loss: 0.233577  [  368/  728]\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 0.217358  [   16/  728]\n",
      "loss: 0.169786  [  368/  728]\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 0.257370  [   16/  728]\n",
      "loss: 0.590741  [  368/  728]\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 0.290697  [   16/  728]\n",
      "loss: 0.342869  [  368/  728]\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 0.273638  [   16/  728]\n",
      "loss: 0.152544  [  368/  728]\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 0.204096  [   16/  728]\n",
      "loss: 0.287186  [  368/  728]\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 0.185487  [   16/  728]\n",
      "loss: 0.569034  [  368/  728]\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 0.255753  [   16/  728]\n",
      "loss: 0.352579  [  368/  728]\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 0.230527  [   16/  728]\n",
      "loss: 0.232217  [  368/  728]\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 0.297067  [   16/  728]\n",
      "loss: 0.109127  [  368/  728]\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 0.341826  [   16/  728]\n",
      "loss: 0.254053  [  368/  728]\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.185938  [   16/  728]\n",
      "loss: 0.178519  [  368/  728]\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.275652  [   16/  728]\n",
      "loss: 0.269303  [  368/  728]\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 0.282930  [   16/  728]\n",
      "loss: 0.262496  [  368/  728]\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 0.197209  [   16/  728]\n",
      "loss: 0.369996  [  368/  728]\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 0.257793  [   16/  728]\n",
      "loss: 0.284527  [  368/  728]\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.192306  [   16/  728]\n",
      "loss: 0.256750  [  368/  728]\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 0.198504  [   16/  728]\n",
      "loss: 0.264934  [  368/  728]\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 0.196866  [   16/  728]\n",
      "loss: 0.266091  [  368/  728]\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 0.179289  [   16/  728]\n",
      "loss: 0.209930  [  368/  728]\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 0.304314  [   16/  728]\n",
      "loss: 0.194166  [  368/  728]\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 0.293670  [   16/  728]\n",
      "loss: 0.264037  [  368/  728]\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 0.247606  [   16/  728]\n",
      "loss: 0.177530  [  368/  728]\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 0.236341  [   16/  728]\n",
      "loss: 0.303182  [  368/  728]\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 0.193715  [   16/  728]\n",
      "loss: 0.147848  [  368/  728]\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.206370  [   16/  728]\n",
      "loss: 0.300348  [  368/  728]\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 0.239052  [   16/  728]\n",
      "loss: 0.242366  [  368/  728]\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 0.221235  [   16/  728]\n",
      "loss: 0.306930  [  368/  728]\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 0.275466  [   16/  728]\n",
      "loss: 0.189825  [  368/  728]\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 0.262604  [   16/  728]\n",
      "loss: 0.195538  [  368/  728]\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 0.210171  [   16/  728]\n",
      "loss: 0.355340  [  368/  728]\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 0.132895  [   16/  728]\n",
      "loss: 0.175902  [  368/  728]\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.253951  [   16/  728]\n",
      "loss: 0.537346  [  368/  728]\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 0.224521  [   16/  728]\n",
      "loss: 0.388016  [  368/  728]\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 0.150363  [   16/  728]\n",
      "loss: 0.182649  [  368/  728]\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 0.275033  [   16/  728]\n",
      "loss: 0.384280  [  368/  728]\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 0.176884  [   16/  728]\n",
      "loss: 0.292616  [  368/  728]\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 0.284786  [   16/  728]\n",
      "loss: 0.201283  [  368/  728]\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 0.205316  [   16/  728]\n",
      "loss: 0.099218  [  368/  728]\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 0.202460  [   16/  728]\n",
      "loss: 0.266706  [  368/  728]\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 0.212606  [   16/  728]\n",
      "loss: 0.517923  [  368/  728]\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 0.181754  [   16/  728]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|         | 4/5 [01:17<00:19, 19.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.397185  [  368/  728]\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 0.301112  [   16/  728]\n",
      "loss: 0.170771  [  368/  728]\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 0.295820  [   16/  728]\n",
      "loss: 0.166149  [  368/  728]\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.292695  [   16/  728]\n",
      "loss: 0.140882  [  368/  728]\n",
      "Done!\n",
      "Trial 5:\n",
      "-------------------------------\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 5.454250  [   16/  728]\n",
      "loss: 5.728818  [  368/  728]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 4.906533  [   16/  728]\n",
      "loss: 1285.765137  [  368/  728]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.734469  [   16/  728]\n",
      "loss: 2.809154  [  368/  728]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.347260  [   16/  728]\n",
      "loss: 800.098267  [  368/  728]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.157612  [   16/  728]\n",
      "loss: 483.391876  [  368/  728]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.776512  [   16/  728]\n",
      "loss: 556.245178  [  368/  728]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.807143  [   16/  728]\n",
      "loss: 7.640920  [  368/  728]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.794993  [   16/  728]\n",
      "loss: 9.192419  [  368/  728]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.668883  [   16/  728]\n",
      "loss: 3.796868  [  368/  728]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.698867  [   16/  728]\n",
      "loss: 46.215820  [  368/  728]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.552134  [   16/  728]\n",
      "loss: 1.765515  [  368/  728]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.537044  [   16/  728]\n",
      "loss: 2.090992  [  368/  728]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.585174  [   16/  728]\n",
      "loss: 6.497680  [  368/  728]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.587801  [   16/  728]\n",
      "loss: 5.996479  [  368/  728]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.318907  [   16/  728]\n",
      "loss: 7.315283  [  368/  728]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.657267  [   16/  728]\n",
      "loss: 2.878953  [  368/  728]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.426174  [   16/  728]\n",
      "loss: 1.613900  [  368/  728]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.104849  [   16/  728]\n",
      "loss: 1.821155  [  368/  728]\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.310880  [   16/  728]\n",
      "loss: 1.577446  [  368/  728]\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.255254  [   16/  728]\n",
      "loss: 4.437219  [  368/  728]\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.311699  [   16/  728]\n",
      "loss: 1.851675  [  368/  728]\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.897309  [   16/  728]\n",
      "loss: 0.860790  [  368/  728]\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1.355094  [   16/  728]\n",
      "loss: 1.805658  [  368/  728]\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.936757  [   16/  728]\n",
      "loss: 1.798831  [  368/  728]\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1.170205  [   16/  728]\n",
      "loss: 1.348646  [  368/  728]\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 1.343220  [   16/  728]\n",
      "loss: 1.327718  [  368/  728]\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 1.285479  [   16/  728]\n",
      "loss: 3.833733  [  368/  728]\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 1.134244  [   16/  728]\n",
      "loss: 1.484014  [  368/  728]\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 1.242783  [   16/  728]\n",
      "loss: 1.365848  [  368/  728]\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 1.174104  [   16/  728]\n",
      "loss: 1.397961  [  368/  728]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 1.350648  [   16/  728]\n",
      "loss: 1.334203  [  368/  728]\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 1.380708  [   16/  728]\n",
      "loss: 1.493752  [  368/  728]\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 1.128810  [   16/  728]\n",
      "loss: 1.557485  [  368/  728]\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 1.006987  [   16/  728]\n",
      "loss: 42.479660  [  368/  728]\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.926672  [   16/  728]\n",
      "loss: 2.388504  [  368/  728]\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 1.232267  [   16/  728]\n",
      "loss: 38.171654  [  368/  728]\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 1.088796  [   16/  728]\n",
      "loss: 1.973982  [  368/  728]\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 1.078464  [   16/  728]\n",
      "loss: 1.649320  [  368/  728]\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.731050  [   16/  728]\n",
      "loss: 1.700225  [  368/  728]\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 1.216105  [   16/  728]\n",
      "loss: 1.755029  [  368/  728]\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 1.073949  [   16/  728]\n",
      "loss: 1.656833  [  368/  728]\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.888052  [   16/  728]\n",
      "loss: 1.087714  [  368/  728]\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.800522  [   16/  728]\n",
      "loss: 1.468179  [  368/  728]\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.895313  [   16/  728]\n",
      "loss: 1.655770  [  368/  728]\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.965945  [   16/  728]\n",
      "loss: 1.813636  [  368/  728]\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.978460  [   16/  728]\n",
      "loss: 0.954639  [  368/  728]\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.963566  [   16/  728]\n",
      "loss: 1.356161  [  368/  728]\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.938227  [   16/  728]\n",
      "loss: 1.427491  [  368/  728]\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.758535  [   16/  728]\n",
      "loss: 1.407820  [  368/  728]\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.896311  [   16/  728]\n",
      "loss: 1.226731  [  368/  728]\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.952960  [   16/  728]\n",
      "loss: 1.056238  [  368/  728]\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.807205  [   16/  728]\n",
      "loss: 1.286369  [  368/  728]\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.959205  [   16/  728]\n",
      "loss: 1.590701  [  368/  728]\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.970340  [   16/  728]\n",
      "loss: 1.405435  [  368/  728]\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.710473  [   16/  728]\n",
      "loss: 1.256222  [  368/  728]\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.788414  [   16/  728]\n",
      "loss: 1.491798  [  368/  728]\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.703091  [   16/  728]\n",
      "loss: 1.382846  [  368/  728]\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.621426  [   16/  728]\n",
      "loss: 1.323906  [  368/  728]\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.837968  [   16/  728]\n",
      "loss: 39.337250  [  368/  728]\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.896646  [   16/  728]\n",
      "loss: 0.925669  [  368/  728]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 1.088089  [   16/  728]\n",
      "loss: 1.322127  [  368/  728]\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.950507  [   16/  728]\n",
      "loss: 1.078737  [  368/  728]\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.972624  [   16/  728]\n",
      "loss: 0.994300  [  368/  728]\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.946288  [   16/  728]\n",
      "loss: 1.251212  [  368/  728]\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.646589  [   16/  728]\n",
      "loss: 223.200562  [  368/  728]\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.928023  [   16/  728]\n",
      "loss: 1.034759  [  368/  728]\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.919802  [   16/  728]\n",
      "loss: 1.013652  [  368/  728]\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.848592  [   16/  728]\n",
      "loss: 1.099912  [  368/  728]\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.573923  [   16/  728]\n",
      "loss: 1.154854  [  368/  728]\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.666319  [   16/  728]\n",
      "loss: 1.536464  [  368/  728]\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.708657  [   16/  728]\n",
      "loss: 0.670737  [  368/  728]\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.776501  [   16/  728]\n",
      "loss: 1.471617  [  368/  728]\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.704315  [   16/  728]\n",
      "loss: 0.621531  [  368/  728]\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.718630  [   16/  728]\n",
      "loss: 37.213985  [  368/  728]\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.843999  [   16/  728]\n",
      "loss: 0.929654  [  368/  728]\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.668469  [   16/  728]\n",
      "loss: 1.168200  [  368/  728]\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.644599  [   16/  728]\n",
      "loss: 1.155004  [  368/  728]\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.726104  [   16/  728]\n",
      "loss: 1.173265  [  368/  728]\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.486890  [   16/  728]\n",
      "loss: 0.976180  [  368/  728]\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.667451  [   16/  728]\n",
      "loss: 1.262780  [  368/  728]\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.676404  [   16/  728]\n",
      "loss: 0.961701  [  368/  728]\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.577782  [   16/  728]\n",
      "loss: 0.883020  [  368/  728]\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.485461  [   16/  728]\n",
      "loss: 1.298999  [  368/  728]\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.613108  [   16/  728]\n",
      "loss: 0.957625  [  368/  728]\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.781364  [   16/  728]\n",
      "loss: 1.695991  [  368/  728]\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.552058  [   16/  728]\n",
      "loss: 0.993844  [  368/  728]\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.732344  [   16/  728]\n",
      "loss: 1.134114  [  368/  728]\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.554353  [   16/  728]\n",
      "loss: 1.044372  [  368/  728]\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.575291  [   16/  728]\n",
      "loss: 1.057394  [  368/  728]\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.536323  [   16/  728]\n",
      "loss: 1.089119  [  368/  728]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.637299  [   16/  728]\n",
      "loss: 1.102868  [  368/  728]\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.514009  [   16/  728]\n",
      "loss: 0.990608  [  368/  728]\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.619585  [   16/  728]\n",
      "loss: 0.859165  [  368/  728]\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.795775  [   16/  728]\n",
      "loss: 1.145302  [  368/  728]\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.480256  [   16/  728]\n",
      "loss: 0.840921  [  368/  728]\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.445692  [   16/  728]\n",
      "loss: 0.926504  [  368/  728]\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.540727  [   16/  728]\n",
      "loss: 0.875267  [  368/  728]\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.552351  [   16/  728]\n",
      "loss: 0.829416  [  368/  728]\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.520461  [   16/  728]\n",
      "loss: 1.029872  [  368/  728]\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.437671  [   16/  728]\n",
      "loss: 0.840038  [  368/  728]\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.487751  [   16/  728]\n",
      "loss: 1.191365  [  368/  728]\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.375340  [   16/  728]\n",
      "loss: 0.863615  [  368/  728]\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.600238  [   16/  728]\n",
      "loss: 0.808521  [  368/  728]\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.616571  [   16/  728]\n",
      "loss: 0.432555  [  368/  728]\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.591247  [   16/  728]\n",
      "loss: 0.823751  [  368/  728]\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.476333  [   16/  728]\n",
      "loss: 0.842981  [  368/  728]\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.437003  [   16/  728]\n",
      "loss: 0.924241  [  368/  728]\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.297613  [   16/  728]\n",
      "loss: 0.848974  [  368/  728]\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.406049  [   16/  728]\n",
      "loss: 0.754171  [  368/  728]\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.399803  [   16/  728]\n",
      "loss: 0.839409  [  368/  728]\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.434330  [   16/  728]\n",
      "loss: 0.805830  [  368/  728]\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.495469  [   16/  728]\n",
      "loss: 0.924674  [  368/  728]\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.371671  [   16/  728]\n",
      "loss: 1.026951  [  368/  728]\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.440130  [   16/  728]\n",
      "loss: 0.782322  [  368/  728]\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.440895  [   16/  728]\n",
      "loss: 0.647302  [  368/  728]\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.443515  [   16/  728]\n",
      "loss: 0.738118  [  368/  728]\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.345326  [   16/  728]\n",
      "loss: 0.690337  [  368/  728]\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.351545  [   16/  728]\n",
      "loss: 0.626749  [  368/  728]\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.462341  [   16/  728]\n",
      "loss: 0.794130  [  368/  728]\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.627783  [   16/  728]\n",
      "loss: 0.987497  [  368/  728]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.469231  [   16/  728]\n",
      "loss: 0.784576  [  368/  728]\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.502471  [   16/  728]\n",
      "loss: 0.730696  [  368/  728]\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.532891  [   16/  728]\n",
      "loss: 0.765434  [  368/  728]\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.471451  [   16/  728]\n",
      "loss: 1.009706  [  368/  728]\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.458079  [   16/  728]\n",
      "loss: 0.929234  [  368/  728]\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.514729  [   16/  728]\n",
      "loss: 0.662643  [  368/  728]\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.519352  [   16/  728]\n",
      "loss: 0.648287  [  368/  728]\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.483417  [   16/  728]\n",
      "loss: 0.944088  [  368/  728]\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.383210  [   16/  728]\n",
      "loss: 0.689513  [  368/  728]\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.435355  [   16/  728]\n",
      "loss: 0.709352  [  368/  728]\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.264714  [   16/  728]\n",
      "loss: 0.848745  [  368/  728]\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.357343  [   16/  728]\n",
      "loss: 0.361299  [  368/  728]\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.385082  [   16/  728]\n",
      "loss: 0.432049  [  368/  728]\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.408617  [   16/  728]\n",
      "loss: 0.463850  [  368/  728]\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.337931  [   16/  728]\n",
      "loss: 0.552295  [  368/  728]\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.444600  [   16/  728]\n",
      "loss: 0.631558  [  368/  728]\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.434618  [   16/  728]\n",
      "loss: 0.658349  [  368/  728]\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.475930  [   16/  728]\n",
      "loss: 0.545832  [  368/  728]\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.514332  [   16/  728]\n",
      "loss: 0.703667  [  368/  728]\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.302578  [   16/  728]\n",
      "loss: 0.757999  [  368/  728]\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.416269  [   16/  728]\n",
      "loss: 0.662815  [  368/  728]\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.337737  [   16/  728]\n",
      "loss: 0.634150  [  368/  728]\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.393596  [   16/  728]\n",
      "loss: 0.716152  [  368/  728]\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.301932  [   16/  728]\n",
      "loss: 0.687693  [  368/  728]\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.456766  [   16/  728]\n",
      "loss: 0.848193  [  368/  728]\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.350390  [   16/  728]\n",
      "loss: 1.045178  [  368/  728]\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.409991  [   16/  728]\n",
      "loss: 0.417810  [  368/  728]\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.304674  [   16/  728]\n",
      "loss: 0.542553  [  368/  728]\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.352017  [   16/  728]\n",
      "loss: 0.555740  [  368/  728]\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.374753  [   16/  728]\n",
      "loss: 0.768215  [  368/  728]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.411002  [   16/  728]\n",
      "loss: 0.541813  [  368/  728]\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.315203  [   16/  728]\n",
      "loss: 0.488841  [  368/  728]\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.302450  [   16/  728]\n",
      "loss: 0.611651  [  368/  728]\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.406132  [   16/  728]\n",
      "loss: 0.638973  [  368/  728]\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.321248  [   16/  728]\n",
      "loss: 0.455410  [  368/  728]\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.294955  [   16/  728]\n",
      "loss: 0.702474  [  368/  728]\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.270055  [   16/  728]\n",
      "loss: 0.582732  [  368/  728]\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.332211  [   16/  728]\n",
      "loss: 0.624387  [  368/  728]\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.317373  [   16/  728]\n",
      "loss: 0.605733  [  368/  728]\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.327995  [   16/  728]\n",
      "loss: 0.524816  [  368/  728]\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.420710  [   16/  728]\n",
      "loss: 0.455156  [  368/  728]\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.294004  [   16/  728]\n",
      "loss: 0.649482  [  368/  728]\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.376728  [   16/  728]\n",
      "loss: 0.578949  [  368/  728]\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.368470  [   16/  728]\n",
      "loss: 0.518189  [  368/  728]\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.349625  [   16/  728]\n",
      "loss: 0.431318  [  368/  728]\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.340840  [   16/  728]\n",
      "loss: 0.575697  [  368/  728]\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.237133  [   16/  728]\n",
      "loss: 0.561687  [  368/  728]\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.363671  [   16/  728]\n",
      "loss: 0.549405  [  368/  728]\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.366048  [   16/  728]\n",
      "loss: 0.563696  [  368/  728]\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.376231  [   16/  728]\n",
      "loss: 0.504553  [  368/  728]\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.444294  [   16/  728]\n",
      "loss: 0.389978  [  368/  728]\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.259584  [   16/  728]\n",
      "loss: 0.576890  [  368/  728]\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.337079  [   16/  728]\n",
      "loss: 0.488480  [  368/  728]\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.394020  [   16/  728]\n",
      "loss: 0.638170  [  368/  728]\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.349906  [   16/  728]\n",
      "loss: 0.694129  [  368/  728]\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.210962  [   16/  728]\n",
      "loss: 0.631916  [  368/  728]\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.322224  [   16/  728]\n",
      "loss: 0.400109  [  368/  728]\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.408321  [   16/  728]\n",
      "loss: 0.548266  [  368/  728]\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.298428  [   16/  728]\n",
      "loss: 0.585253  [  368/  728]\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.309791  [   16/  728]\n",
      "loss: 0.703916  [  368/  728]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.312256  [   16/  728]\n",
      "loss: 0.375585  [  368/  728]\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.304667  [   16/  728]\n",
      "loss: 0.485241  [  368/  728]\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.326039  [   16/  728]\n",
      "loss: 0.542929  [  368/  728]\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.262330  [   16/  728]\n",
      "loss: 0.418749  [  368/  728]\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.266486  [   16/  728]\n",
      "loss: 0.539679  [  368/  728]\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.268036  [   16/  728]\n",
      "loss: 0.466083  [  368/  728]\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.220558  [   16/  728]\n",
      "loss: 0.523823  [  368/  728]\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.249555  [   16/  728]\n",
      "loss: 0.471450  [  368/  728]\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.314312  [   16/  728]\n",
      "loss: 0.459032  [  368/  728]\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.290226  [   16/  728]\n",
      "loss: 0.664278  [  368/  728]\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.222485  [   16/  728]\n",
      "loss: 0.496585  [  368/  728]\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.291921  [   16/  728]\n",
      "loss: 0.448636  [  368/  728]\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.287336  [   16/  728]\n",
      "loss: 0.713636  [  368/  728]\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.255791  [   16/  728]\n",
      "loss: 0.274507  [  368/  728]\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.289541  [   16/  728]\n",
      "loss: 0.408642  [  368/  728]\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.338499  [   16/  728]\n",
      "loss: 0.581759  [  368/  728]\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.255052  [   16/  728]\n",
      "loss: 0.460097  [  368/  728]\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.185700  [   16/  728]\n",
      "loss: 0.499518  [  368/  728]\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.308298  [   16/  728]\n",
      "loss: 0.625771  [  368/  728]\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.298407  [   16/  728]\n",
      "loss: 0.569437  [  368/  728]\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.293236  [   16/  728]\n",
      "loss: 0.540637  [  368/  728]\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.233276  [   16/  728]\n",
      "loss: 0.522986  [  368/  728]\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.343229  [   16/  728]\n",
      "loss: 0.680791  [  368/  728]\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.205620  [   16/  728]\n",
      "loss: 0.605342  [  368/  728]\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.313321  [   16/  728]\n",
      "loss: 0.482306  [  368/  728]\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.263033  [   16/  728]\n",
      "loss: 0.553571  [  368/  728]\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.255437  [   16/  728]\n",
      "loss: 0.417368  [  368/  728]\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.228915  [   16/  728]\n",
      "loss: 0.466216  [  368/  728]\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.435765  [   16/  728]\n",
      "loss: 0.430295  [  368/  728]\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.299805  [   16/  728]\n",
      "loss: 0.471913  [  368/  728]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.244781  [   16/  728]\n",
      "loss: 0.674753  [  368/  728]\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.243743  [   16/  728]\n",
      "loss: 0.411128  [  368/  728]\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.343165  [   16/  728]\n",
      "loss: 0.581594  [  368/  728]\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.311883  [   16/  728]\n",
      "loss: 0.539797  [  368/  728]\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.248737  [   16/  728]\n",
      "loss: 0.643458  [  368/  728]\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.341853  [   16/  728]\n",
      "loss: 0.376295  [  368/  728]\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.325234  [   16/  728]\n",
      "loss: 0.232840  [  368/  728]\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.210978  [   16/  728]\n",
      "loss: 0.360632  [  368/  728]\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.252784  [   16/  728]\n",
      "loss: 0.371614  [  368/  728]\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.286574  [   16/  728]\n",
      "loss: 0.420863  [  368/  728]\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.283249  [   16/  728]\n",
      "loss: 0.531308  [  368/  728]\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.291032  [   16/  728]\n",
      "loss: 0.553906  [  368/  728]\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.335443  [   16/  728]\n",
      "loss: 0.532914  [  368/  728]\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.304615  [   16/  728]\n",
      "loss: 0.656686  [  368/  728]\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.215073  [   16/  728]\n",
      "loss: 0.683957  [  368/  728]\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.203054  [   16/  728]\n",
      "loss: 0.383185  [  368/  728]\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.378079  [   16/  728]\n",
      "loss: 0.485775  [  368/  728]\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.295708  [   16/  728]\n",
      "loss: 0.322972  [  368/  728]\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.271785  [   16/  728]\n",
      "loss: 0.371065  [  368/  728]\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.255642  [   16/  728]\n",
      "loss: 0.261415  [  368/  728]\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.279191  [   16/  728]\n",
      "loss: 0.390479  [  368/  728]\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.296600  [   16/  728]\n",
      "loss: 0.492691  [  368/  728]\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.246435  [   16/  728]\n",
      "loss: 0.305222  [  368/  728]\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.231254  [   16/  728]\n",
      "loss: 0.299605  [  368/  728]\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.242063  [   16/  728]\n",
      "loss: 0.443607  [  368/  728]\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.257272  [   16/  728]\n",
      "loss: 0.445519  [  368/  728]\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.199367  [   16/  728]\n",
      "loss: 0.441954  [  368/  728]\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.191545  [   16/  728]\n",
      "loss: 0.316438  [  368/  728]\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.266310  [   16/  728]\n",
      "loss: 0.501264  [  368/  728]\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.275107  [   16/  728]\n",
      "loss: 0.233883  [  368/  728]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.184466  [   16/  728]\n",
      "loss: 0.335683  [  368/  728]\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.232870  [   16/  728]\n",
      "loss: 0.449549  [  368/  728]\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.269315  [   16/  728]\n",
      "loss: 0.490979  [  368/  728]\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.275518  [   16/  728]\n",
      "loss: 0.407068  [  368/  728]\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.272818  [   16/  728]\n",
      "loss: 0.479799  [  368/  728]\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.259257  [   16/  728]\n",
      "loss: 0.477271  [  368/  728]\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.243967  [   16/  728]\n",
      "loss: 0.342254  [  368/  728]\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.244967  [   16/  728]\n",
      "loss: 0.330211  [  368/  728]\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.260338  [   16/  728]\n",
      "loss: 0.351832  [  368/  728]\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.321791  [   16/  728]\n",
      "loss: 0.295875  [  368/  728]\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.252759  [   16/  728]\n",
      "loss: 0.513672  [  368/  728]\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.326080  [   16/  728]\n",
      "loss: 0.550317  [  368/  728]\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.351576  [   16/  728]\n",
      "loss: 0.449097  [  368/  728]\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.296276  [   16/  728]\n",
      "loss: 0.352806  [  368/  728]\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.227207  [   16/  728]\n",
      "loss: 0.317993  [  368/  728]\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.232376  [   16/  728]\n",
      "loss: 0.338926  [  368/  728]\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.299255  [   16/  728]\n",
      "loss: 0.794865  [  368/  728]\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.317030  [   16/  728]\n",
      "loss: 0.415284  [  368/  728]\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.370239  [   16/  728]\n",
      "loss: 0.461791  [  368/  728]\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.221463  [   16/  728]\n",
      "loss: 0.655054  [  368/  728]\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.340295  [   16/  728]\n",
      "loss: 0.433412  [  368/  728]\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.328868  [   16/  728]\n",
      "loss: 0.283394  [  368/  728]\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.231284  [   16/  728]\n",
      "loss: 0.330849  [  368/  728]\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.359134  [   16/  728]\n",
      "loss: 0.508238  [  368/  728]\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.294746  [   16/  728]\n",
      "loss: 0.372538  [  368/  728]\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.327259  [   16/  728]\n",
      "loss: 0.414333  [  368/  728]\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.238131  [   16/  728]\n",
      "loss: 0.373870  [  368/  728]\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.264834  [   16/  728]\n",
      "loss: 0.287182  [  368/  728]\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.245613  [   16/  728]\n",
      "loss: 0.546110  [  368/  728]\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.360893  [   16/  728]\n",
      "loss: 0.480567  [  368/  728]\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.279563  [   16/  728]\n",
      "loss: 0.469490  [  368/  728]\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.283154  [   16/  728]\n",
      "loss: 0.509594  [  368/  728]\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.256849  [   16/  728]\n",
      "loss: 0.375153  [  368/  728]\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.289816  [   16/  728]\n",
      "loss: 0.357320  [  368/  728]\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.250544  [   16/  728]\n",
      "loss: 0.519017  [  368/  728]\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.295477  [   16/  728]\n",
      "loss: 0.461327  [  368/  728]\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.253379  [   16/  728]\n",
      "loss: 0.237979  [  368/  728]\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.308570  [   16/  728]\n",
      "loss: 0.465091  [  368/  728]\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.385034  [   16/  728]\n",
      "loss: 0.397308  [  368/  728]\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.286138  [   16/  728]\n",
      "loss: 0.458055  [  368/  728]\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.276184  [   16/  728]\n",
      "loss: 0.581986  [  368/  728]\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.191373  [   16/  728]\n",
      "loss: 0.283763  [  368/  728]\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.314743  [   16/  728]\n",
      "loss: 0.420936  [  368/  728]\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.289966  [   16/  728]\n",
      "loss: 0.531875  [  368/  728]\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.252245  [   16/  728]\n",
      "loss: 0.384937  [  368/  728]\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.254338  [   16/  728]\n",
      "loss: 0.438004  [  368/  728]\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.251858  [   16/  728]\n",
      "loss: 0.419771  [  368/  728]\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.288367  [   16/  728]\n",
      "loss: 0.533451  [  368/  728]\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.326127  [   16/  728]\n",
      "loss: 0.366280  [  368/  728]\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.238779  [   16/  728]\n",
      "loss: 0.431770  [  368/  728]\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.313683  [   16/  728]\n",
      "loss: 0.556633  [  368/  728]\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.325478  [   16/  728]\n",
      "loss: 0.474854  [  368/  728]\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.261523  [   16/  728]\n",
      "loss: 0.441127  [  368/  728]\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.262906  [   16/  728]\n",
      "loss: 0.375202  [  368/  728]\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.233844  [   16/  728]\n",
      "loss: 0.265073  [  368/  728]\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.277293  [   16/  728]\n",
      "loss: 0.246601  [  368/  728]\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.256570  [   16/  728]\n",
      "loss: 0.526520  [  368/  728]\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.268015  [   16/  728]\n",
      "loss: 0.367292  [  368/  728]\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.238957  [   16/  728]\n",
      "loss: 0.288560  [  368/  728]\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.212860  [   16/  728]\n",
      "loss: 328.676361  [  368/  728]\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 0.235603  [   16/  728]\n",
      "loss: 0.366796  [  368/  728]\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 0.225310  [   16/  728]\n",
      "loss: 0.245738  [  368/  728]\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 0.278236  [   16/  728]\n",
      "loss: 0.389054  [  368/  728]\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 0.335102  [   16/  728]\n",
      "loss: 0.410676  [  368/  728]\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 0.271453  [   16/  728]\n",
      "loss: 0.379080  [  368/  728]\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 0.221894  [   16/  728]\n",
      "loss: 0.255764  [  368/  728]\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 0.186899  [   16/  728]\n",
      "loss: 0.411397  [  368/  728]\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 0.218909  [   16/  728]\n",
      "loss: 0.294306  [  368/  728]\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 0.242861  [   16/  728]\n",
      "loss: 0.398484  [  368/  728]\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 0.315541  [   16/  728]\n",
      "loss: 0.433302  [  368/  728]\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 0.259053  [   16/  728]\n",
      "loss: 0.478900  [  368/  728]\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 0.302322  [   16/  728]\n",
      "loss: 0.422825  [  368/  728]\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 0.300815  [   16/  728]\n",
      "loss: 0.460927  [  368/  728]\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 0.248411  [   16/  728]\n",
      "loss: 0.331997  [  368/  728]\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 0.305043  [   16/  728]\n",
      "loss: 0.292897  [  368/  728]\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 0.258177  [   16/  728]\n",
      "loss: 0.270628  [  368/  728]\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 0.186548  [   16/  728]\n",
      "loss: 0.368117  [  368/  728]\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 0.260225  [   16/  728]\n",
      "loss: 0.263175  [  368/  728]\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 0.186315  [   16/  728]\n",
      "loss: 0.349474  [  368/  728]\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 0.238897  [   16/  728]\n",
      "loss: 0.347361  [  368/  728]\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 0.263610  [   16/  728]\n",
      "loss: 0.383678  [  368/  728]\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 0.218471  [   16/  728]\n",
      "loss: 0.432014  [  368/  728]\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 0.250890  [   16/  728]\n",
      "loss: 0.422276  [  368/  728]\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 0.190347  [   16/  728]\n",
      "loss: 0.378195  [  368/  728]\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 0.322592  [   16/  728]\n",
      "loss: 0.382098  [  368/  728]\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 0.257388  [   16/  728]\n",
      "loss: 0.513859  [  368/  728]\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 0.272056  [   16/  728]\n",
      "loss: 0.354327  [  368/  728]\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 0.245262  [   16/  728]\n",
      "loss: 0.329645  [  368/  728]\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 0.251779  [   16/  728]\n",
      "loss: 0.446541  [  368/  728]\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 0.278436  [   16/  728]\n",
      "loss: 0.232190  [  368/  728]\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 0.215094  [   16/  728]\n",
      "loss: 0.332369  [  368/  728]\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 0.234808  [   16/  728]\n",
      "loss: 0.344607  [  368/  728]\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 0.204691  [   16/  728]\n",
      "loss: 0.367399  [  368/  728]\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 0.231444  [   16/  728]\n",
      "loss: 0.409608  [  368/  728]\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 0.266614  [   16/  728]\n",
      "loss: 0.419088  [  368/  728]\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 0.191732  [   16/  728]\n",
      "loss: 0.365318  [  368/  728]\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 0.229454  [   16/  728]\n",
      "loss: 0.354967  [  368/  728]\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 0.269545  [   16/  728]\n",
      "loss: 0.513179  [  368/  728]\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 0.250762  [   16/  728]\n",
      "loss: 0.393874  [  368/  728]\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 0.271311  [   16/  728]\n",
      "loss: 0.322947  [  368/  728]\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 0.217397  [   16/  728]\n",
      "loss: 0.394220  [  368/  728]\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 0.260458  [   16/  728]\n",
      "loss: 0.395926  [  368/  728]\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 0.210189  [   16/  728]\n",
      "loss: 0.426147  [  368/  728]\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.200278  [   16/  728]\n",
      "loss: 0.332931  [  368/  728]\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 0.233684  [   16/  728]\n",
      "loss: 0.380240  [  368/  728]\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 0.267339  [   16/  728]\n",
      "loss: 0.244189  [  368/  728]\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 0.323977  [   16/  728]\n",
      "loss: 0.304991  [  368/  728]\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 0.248173  [   16/  728]\n",
      "loss: 0.335176  [  368/  728]\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 0.258169  [   16/  728]\n",
      "loss: 0.282055  [  368/  728]\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 0.290310  [   16/  728]\n",
      "loss: 0.216211  [  368/  728]\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 0.229006  [   16/  728]\n",
      "loss: 0.366885  [  368/  728]\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 0.246741  [   16/  728]\n",
      "loss: 0.317165  [  368/  728]\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 0.284355  [   16/  728]\n",
      "loss: 0.328248  [  368/  728]\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 0.254798  [   16/  728]\n",
      "loss: 0.384100  [  368/  728]\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 0.218752  [   16/  728]\n",
      "loss: 0.349584  [  368/  728]\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 0.253136  [   16/  728]\n",
      "loss: 0.284719  [  368/  728]\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 0.330328  [   16/  728]\n",
      "loss: 0.245462  [  368/  728]\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 0.229395  [   16/  728]\n",
      "loss: 0.352857  [  368/  728]\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.243477  [   16/  728]\n",
      "loss: 0.249410  [  368/  728]\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 0.330495  [   16/  728]\n",
      "loss: 0.351254  [  368/  728]\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 0.229613  [   16/  728]\n",
      "loss: 0.503451  [  368/  728]\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 0.254701  [   16/  728]\n",
      "loss: 0.351221  [  368/  728]\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 0.203161  [   16/  728]\n",
      "loss: 0.315671  [  368/  728]\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 0.267282  [   16/  728]\n",
      "loss: 0.273448  [  368/  728]\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 0.222056  [   16/  728]\n",
      "loss: 0.503566  [  368/  728]\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 0.266521  [   16/  728]\n",
      "loss: 0.439569  [  368/  728]\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 0.307846  [   16/  728]\n",
      "loss: 0.298113  [  368/  728]\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 0.224680  [   16/  728]\n",
      "loss: 0.317061  [  368/  728]\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 0.298986  [   16/  728]\n",
      "loss: 0.357816  [  368/  728]\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.270334  [   16/  728]\n",
      "loss: 0.417646  [  368/  728]\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 0.266003  [   16/  728]\n",
      "loss: 0.324241  [  368/  728]\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 0.284321  [   16/  728]\n",
      "loss: 0.381256  [  368/  728]\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 0.186557  [   16/  728]\n",
      "loss: 0.312419  [  368/  728]\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 0.232502  [   16/  728]\n",
      "loss: 0.369679  [  368/  728]\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 0.260267  [   16/  728]\n",
      "loss: 0.357188  [  368/  728]\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 0.269473  [   16/  728]\n",
      "loss: 0.272216  [  368/  728]\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 0.230915  [   16/  728]\n",
      "loss: 0.309131  [  368/  728]\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 0.291245  [   16/  728]\n",
      "loss: 0.382993  [  368/  728]\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 0.258036  [   16/  728]\n",
      "loss: 0.290706  [  368/  728]\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 0.265655  [   16/  728]\n",
      "loss: 0.347027  [  368/  728]\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 0.198572  [   16/  728]\n",
      "loss: 0.306454  [  368/  728]\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 0.222110  [   16/  728]\n",
      "loss: 0.390232  [  368/  728]\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 0.282270  [   16/  728]\n",
      "loss: 0.367916  [  368/  728]\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 0.274011  [   16/  728]\n",
      "loss: 0.319474  [  368/  728]\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.213549  [   16/  728]\n",
      "loss: 0.314287  [  368/  728]\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 0.358991  [   16/  728]\n",
      "loss: 0.257604  [  368/  728]\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 0.228449  [   16/  728]\n",
      "loss: 0.302516  [  368/  728]\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 0.224308  [   16/  728]\n",
      "loss: 0.230106  [  368/  728]\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 0.206797  [   16/  728]\n",
      "loss: 0.295661  [  368/  728]\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 0.209221  [   16/  728]\n",
      "loss: 0.212577  [  368/  728]\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 0.162782  [   16/  728]\n",
      "loss: 0.264469  [  368/  728]\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 0.249720  [   16/  728]\n",
      "loss: 0.248809  [  368/  728]\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 0.181086  [   16/  728]\n",
      "loss: 0.194119  [  368/  728]\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 0.240446  [   16/  728]\n",
      "loss: 0.166470  [  368/  728]\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 0.286296  [   16/  728]\n",
      "loss: 0.388818  [  368/  728]\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 0.203497  [   16/  728]\n",
      "loss: 0.341019  [  368/  728]\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 0.282016  [   16/  728]\n",
      "loss: 0.335373  [  368/  728]\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 0.233812  [   16/  728]\n",
      "loss: 0.199763  [  368/  728]\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 0.155456  [   16/  728]\n",
      "loss: 0.369209  [  368/  728]\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 0.290660  [   16/  728]\n",
      "loss: 0.270662  [  368/  728]\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 0.299650  [   16/  728]\n",
      "loss: 0.247613  [  368/  728]\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 0.188013  [   16/  728]\n",
      "loss: 0.328747  [  368/  728]\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 0.184731  [   16/  728]\n",
      "loss: 0.372000  [  368/  728]\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 0.306150  [   16/  728]\n",
      "loss: 0.290062  [  368/  728]\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 0.235663  [   16/  728]\n",
      "loss: 0.304018  [  368/  728]\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 0.250376  [   16/  728]\n",
      "loss: 0.286221  [  368/  728]\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 0.283909  [   16/  728]\n",
      "loss: 0.507088  [  368/  728]\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 0.232088  [   16/  728]\n",
      "loss: 0.402216  [  368/  728]\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 0.207828  [   16/  728]\n",
      "loss: 0.426216  [  368/  728]\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 0.269633  [   16/  728]\n",
      "loss: 0.421046  [  368/  728]\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 0.203484  [   16/  728]\n",
      "loss: 0.276888  [  368/  728]\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 0.227386  [   16/  728]\n",
      "loss: 0.216524  [  368/  728]\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 0.190244  [   16/  728]\n",
      "loss: 0.308476  [  368/  728]\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 0.218183  [   16/  728]\n",
      "loss: 0.551798  [  368/  728]\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.203915  [   16/  728]\n",
      "loss: 0.223393  [  368/  728]\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 0.219936  [   16/  728]\n",
      "loss: 0.213148  [  368/  728]\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 0.268043  [   16/  728]\n",
      "loss: 0.281368  [  368/  728]\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 0.184141  [   16/  728]\n",
      "loss: 0.443331  [  368/  728]\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 0.175224  [   16/  728]\n",
      "loss: 0.318154  [  368/  728]\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 0.184744  [   16/  728]\n",
      "loss: 0.264218  [  368/  728]\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 0.200459  [   16/  728]\n",
      "loss: 0.326819  [  368/  728]\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 0.203203  [   16/  728]\n",
      "loss: 0.265306  [  368/  728]\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 0.196953  [   16/  728]\n",
      "loss: 0.273584  [  368/  728]\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 0.231592  [   16/  728]\n",
      "loss: 0.223614  [  368/  728]\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 0.262578  [   16/  728]\n",
      "loss: 0.399028  [  368/  728]\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 0.277222  [   16/  728]\n",
      "loss: 0.473587  [  368/  728]\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 0.254629  [   16/  728]\n",
      "loss: 0.179466  [  368/  728]\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 0.262923  [   16/  728]\n",
      "loss: 0.434511  [  368/  728]\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 0.139734  [   16/  728]\n",
      "loss: 0.333393  [  368/  728]\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 0.212656  [   16/  728]\n",
      "loss: 0.303816  [  368/  728]\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 0.209418  [   16/  728]\n",
      "loss: 0.436077  [  368/  728]\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 0.302970  [   16/  728]\n",
      "loss: 0.335461  [  368/  728]\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 0.260619  [   16/  728]\n",
      "loss: 0.402573  [  368/  728]\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 0.266951  [   16/  728]\n",
      "loss: 0.285320  [  368/  728]\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 0.271437  [   16/  728]\n",
      "loss: 0.380534  [  368/  728]\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 0.295147  [   16/  728]\n",
      "loss: 0.316504  [  368/  728]\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 0.212570  [   16/  728]\n",
      "loss: 0.334652  [  368/  728]\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 0.170739  [   16/  728]\n",
      "loss: 0.338126  [  368/  728]\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 0.186891  [   16/  728]\n",
      "loss: 0.300832  [  368/  728]\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 0.245437  [   16/  728]\n",
      "loss: 0.391518  [  368/  728]\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 0.207994  [   16/  728]\n",
      "loss: 0.281682  [  368/  728]\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 0.220502  [   16/  728]\n",
      "loss: 0.460742  [  368/  728]\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 0.188829  [   16/  728]\n",
      "loss: 0.353985  [  368/  728]\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 0.239929  [   16/  728]\n",
      "loss: 0.418175  [  368/  728]\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 0.298516  [   16/  728]\n",
      "loss: 0.294209  [  368/  728]\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 0.198231  [   16/  728]\n",
      "loss: 0.269257  [  368/  728]\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 0.295891  [   16/  728]\n",
      "loss: 0.314124  [  368/  728]\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 0.263476  [   16/  728]\n",
      "loss: 0.260233  [  368/  728]\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 0.230059  [   16/  728]\n",
      "loss: 0.228693  [  368/  728]\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 0.276918  [   16/  728]\n",
      "loss: 0.420357  [  368/  728]\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 0.245503  [   16/  728]\n",
      "loss: 0.261513  [  368/  728]\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 0.269316  [   16/  728]\n",
      "loss: 0.314486  [  368/  728]\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 0.230408  [   16/  728]\n",
      "loss: 0.309001  [  368/  728]\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 0.169138  [   16/  728]\n",
      "loss: 0.345962  [  368/  728]\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 0.159818  [   16/  728]\n",
      "loss: 0.457395  [  368/  728]\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 0.228121  [   16/  728]\n",
      "loss: 0.362754  [  368/  728]\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 0.197591  [   16/  728]\n",
      "loss: 0.327006  [  368/  728]\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 0.255726  [   16/  728]\n",
      "loss: 0.234270  [  368/  728]\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 0.205690  [   16/  728]\n",
      "loss: 0.381572  [  368/  728]\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 0.199782  [   16/  728]\n",
      "loss: 0.262169  [  368/  728]\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 0.300708  [   16/  728]\n",
      "loss: 0.353018  [  368/  728]\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 0.249881  [   16/  728]\n",
      "loss: 0.341168  [  368/  728]\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 0.267064  [   16/  728]\n",
      "loss: 0.342170  [  368/  728]\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 0.218889  [   16/  728]\n",
      "loss: 0.313722  [  368/  728]\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 0.119455  [   16/  728]\n",
      "loss: 0.365667  [  368/  728]\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 0.294003  [   16/  728]\n",
      "loss: 0.348172  [  368/  728]\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.300790  [   16/  728]\n",
      "loss: 0.465720  [  368/  728]\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.192521  [   16/  728]\n",
      "loss: 0.214711  [  368/  728]\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 0.232764  [   16/  728]\n",
      "loss: 0.311240  [  368/  728]\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 0.279007  [   16/  728]\n",
      "loss: 0.478647  [  368/  728]\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 0.203939  [   16/  728]\n",
      "loss: 0.179710  [  368/  728]\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.209369  [   16/  728]\n",
      "loss: 0.223592  [  368/  728]\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 0.262146  [   16/  728]\n",
      "loss: 0.277668  [  368/  728]\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 0.257867  [   16/  728]\n",
      "loss: 0.284324  [  368/  728]\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 0.207466  [   16/  728]\n",
      "loss: 0.327618  [  368/  728]\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 0.229450  [   16/  728]\n",
      "loss: 0.386042  [  368/  728]\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 0.148982  [   16/  728]\n",
      "loss: 0.252782  [  368/  728]\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 0.228950  [   16/  728]\n",
      "loss: 0.393582  [  368/  728]\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 0.276002  [   16/  728]\n",
      "loss: 0.314895  [  368/  728]\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 0.307258  [   16/  728]\n",
      "loss: 0.212945  [  368/  728]\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.217533  [   16/  728]\n",
      "loss: 0.328506  [  368/  728]\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 0.274058  [   16/  728]\n",
      "loss: 0.471605  [  368/  728]\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 0.274049  [   16/  728]\n",
      "loss: 0.404848  [  368/  728]\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 0.117837  [   16/  728]\n",
      "loss: 0.236790  [  368/  728]\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 0.269596  [   16/  728]\n",
      "loss: 0.256110  [  368/  728]\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 0.261537  [   16/  728]\n",
      "loss: 0.237090  [  368/  728]\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 0.304431  [   16/  728]\n",
      "loss: 0.248555  [  368/  728]\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.164719  [   16/  728]\n",
      "loss: 0.283971  [  368/  728]\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 0.241701  [   16/  728]\n",
      "loss: 0.275161  [  368/  728]\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 0.254433  [   16/  728]\n",
      "loss: 0.259563  [  368/  728]\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 0.239289  [   16/  728]\n",
      "loss: 0.353226  [  368/  728]\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 0.176604  [   16/  728]\n",
      "loss: 0.162304  [  368/  728]\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 0.253547  [   16/  728]\n",
      "loss: 0.373981  [  368/  728]\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 0.262127  [   16/  728]\n",
      "loss: 0.335095  [  368/  728]\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 0.191846  [   16/  728]\n",
      "loss: 0.336453  [  368/  728]\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 0.275158  [   16/  728]\n",
      "loss: 0.262138  [  368/  728]\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 0.237837  [   16/  728]\n",
      "loss: 0.385841  [  368/  728]\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 0.283706  [   16/  728]\n",
      "loss: 0.324463  [  368/  728]\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 0.271433  [   16/  728]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [01:39<00:00, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.253100  [  368/  728]\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.198855  [   16/  728]\n",
      "loss: 0.266451  [  368/  728]\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_list = []\n",
    "importances_lists = []\n",
    "\n",
    "for trial in tqdm.tqdm([1, 2, 3, 4, 5]):\n",
    "    print(f\"Trial {trial}:\\n-------------------------------\")\n",
    "    \n",
    "    model = NeuralNetwork().to(device)\n",
    "    loss_fn = torch.nn.L1Loss() # MAE\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    epochs = 500\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(train_dataloader, model, loss_fn, optimizer)\n",
    "    print(\"Done!\")\n",
    "\n",
    "    y_pred_test = model.forward(features_test)\n",
    "    y_pred_test = y_pred_test.detach().numpy()\n",
    "\n",
    "    predictions = {}\n",
    "    predictions[name] = y_pred_test\n",
    "    predictions_list.append(predictions)\n",
    "\n",
    "results = group.evaluate_many(predictions_list)\n",
    "# {'caco2_wang': [6.328, 0.101]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea6f122b-8c7a-4ac6-8579-f428ef747442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'caco2_wang': [0.383, 0.023]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab8858c-f838-4c43-9566-3379213a0256",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- regularization\n",
    "- early stopping"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
